{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934b705b-68f4-4ae8-968b-2fb89ec8005c",
   "metadata": {},
   "source": [
    "### Capstone Function Optimisation\n",
    "\n",
    "There are comments below, but the main description of the techniques is in the accompanying README file.\n",
    "\n",
    "To run analysis on a given Capstone function, the key function is:\n",
    "\n",
    "**run_func(func_num, use_features=True, input_dir=\"Functions/Source_Data\", output_dir=\"Functions/Visualisations\")**\n",
    "\n",
    "where\n",
    "- **func_num** is the desired Capstone function number (1 to 8)\n",
    "- **use_features** controls whether to turn on feature engineering (True/False)\n",
    "- **input_dir** specifies where to find the source data, which should be in files **function_n_inputs.npy** and **function_n_outputs.npy** (where n is func_num)\n",
    "- **output_dir** specifies where to put the visualisations, which can most easily be accessed through the **index.html** file generated; a subdirectory will be created for each run\n",
    "\n",
    "At a high level, the approach is as follows:\n",
    "- Load input & output data for the relevant Capstone function\n",
    "- Apply a shift to the output if necessary (so that transforms such as logs can be applied later)\n",
    "- Initialise a Bayesian Optimiser class with the data\n",
    "- Optionally, include feature engineering, i.e. pre-processing to add new feature dimensions which are bespoke functions of the inputs\n",
    "- Fit a Gaussian Process (GP) with a variety of kernels, with and without log-transforming the outputs and with and without warping; use cross-validation to assess the fit and choose the best kernel\n",
    "- Fit a BoTorch model to the same data\n",
    "- Apply a variety of techniques to find the best candidate input to try next, including Expected Improvement (EI), Upper Confidene Bound (UCB) & Potential Improvement (PI) with both the GP model and the BoTorch model (the latter with and without feature engineering), but also various Monte-Carlo methods, Knowledge Gradient, Maximum Entropy Search, Thompson Sampling, Bootstrapping and Cross-Validation\n",
    "- Compare the candidates in terms of predicted mean and EI\n",
    "- Produce a range of visualisations to help choose the best candidate, including Parallel Coordinates (which helps identify patterns of promising inputs across multiple dimensions); the Prediction Surface (showing the predicted mean and uncertainty); the Acquisition Landscape of some of the standard acquisition functions; Dimensional Importance (including the feature dimensions, if used); Partial Dependence plots (showing fit vs observations for each dimension separately); Expected Improvement Landscapes (for various combinations of dimensions); Decision Boundary plots (for various combinations of dimensions and percentiles); various Dimensional Reduction Projections to analyse clustering (t-SNE, UMAP and MDS); SHAP analysis (showing the effect of each input dimension separately); a Dimension Interaction Heatmap; and some plots showing Model Fits\n",
    "- Apply human judgement to choose the best candidate, bearing in mind the expected mean and EI but also the knowledge gained from the visualisations, including the position of the various candidates in the input space.\n",
    "\n",
    "The Bayesian Optimiser class also contains functionality which was not used in the final analysis:\n",
    "- Deep Kernels: these were expensive to fit and performed worse than standard or warped kernels so were disabled\n",
    "- Historical Optimisation Analysis: this was designed to track the performance of the various techniques, saving and loading state each week and feeding the information into the decision for the next candidate, but this did not prove particularly helpful\n",
    "- Reverse Engineering History: this was designed to look back at the data as it was at each decision point in the past and to reverse engineer which type of acquisition function must have been used to choose the next candidate; the idea was to fill in the \"gaps\" in memory as the historical optimisation analysis was only implemented some time after the start of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c0ca00-fa5a-4fa4-958e-129146ffb2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# - include standard libraries such as numpy and pandas\n",
    "# - include Bayesian Optimisation libraries such as BoTorch and scikit-learn\n",
    "# - include visualisation libraries such as matplotlib and plotly\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import shap\n",
    "import umap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, ConstantKernel, WhiteKernel, RationalQuadratic, ExpSineSquared, DotProduct\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize, fmin_l_bfgs_b\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from torch.autograd import Function\n",
    "from torch import Tensor\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.kernels import Kernel, MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition import ExpectedImprovement, LogExpectedImprovement, UpperConfidenceBound, ProbabilityOfImprovement\n",
    "from botorch.acquisition import qExpectedImprovement, qLogExpectedImprovement, qLogNoisyExpectedImprovement, qKnowledgeGradient, qMaxValueEntropy\n",
    "from botorch.acquisition import MCAcquisitionFunction\n",
    "from botorch.acquisition.acquisition import AcquisitionFunction\n",
    "from botorch.acquisition.objective import MCAcquisitionObjective\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch.models.transforms.input import InputTransform\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.posteriors.gpytorch import GPyTorchPosterior\n",
    "from botorch.sampling import SobolQMCNormalSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86532a50-8f4d-46cb-8182-c911e7f82930",
   "metadata": {},
   "source": [
    "The following section implements feature engineering for the specific Imperial ML/AI Capstone Competition functions, to keep this separate from the general Bayesian Optimisation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f8fe8e-f051-418f-862b-9c971d4baf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransformer(ABC):\n",
    "    \"\"\"Abstract base class for feature transformers.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform input features X.\"\"\"\n",
    "        pass\n",
    "\n",
    "class IdentityTransformer(FeatureTransformer):\n",
    "    \"\"\"Default transformer that returns original features.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "class Function2Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 2.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        \n",
    "        # Feature 1: Distance from optimal x0 region\n",
    "        x0_optimal = 0.72\n",
    "        x0_penalty = np.square(X[:, 0] - x0_optimal).reshape(-1, 1)\n",
    "        features.append(x0_penalty)\n",
    "        \n",
    "        # Feature 2: Multi-modal x1 activation\n",
    "        x1_mode1 = np.exp(-50 * np.square(X[:, 1] - 0.0)).reshape(-1, 1)\n",
    "        x1_mode2 = np.exp(-50 * np.square(X[:, 1] - 0.4)).reshape(-1, 1)\n",
    "        x1_mode3 = np.exp(-25 * np.square(X[:, 1] - 0.95)).reshape(-1, 1)\n",
    "        x1_multimodal = np.maximum(np.maximum(x1_mode1, x1_mode2), x1_mode3)\n",
    "        features.append(x1_multimodal)\n",
    "        \n",
    "        # Feature 3: Interaction term\n",
    "        x0_good = np.exp(-25 * np.square(X[:, 0] - 0.72))\n",
    "        interaction = (x0_good * x1_multimodal.flatten()).reshape(-1, 1)\n",
    "        features.append(interaction)\n",
    "        \n",
    "        # Feature 4: RBF around best known point\n",
    "        best_point = np.array([0.723, 0.438])\n",
    "        distances_to_best = np.sqrt(np.sum(np.square(X - best_point), axis=1))\n",
    "        rbf_best = np.exp(-10 * np.square(distances_to_best)).reshape(-1, 1)\n",
    "        features.append(rbf_best)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "class Function3Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 3.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        optimal_point = np.array([0.407, 0.574, 0.428])\n",
    "        \n",
    "        # Feature 1: Tight Gaussian around optimum\n",
    "        sigma = 0.05\n",
    "        gaussian_tight = np.exp(-np.sum(np.square(X - optimal_point), axis=1) / \n",
    "                               (2 * sigma**2)).reshape(-1, 1)\n",
    "        features.append(gaussian_tight)\n",
    "        \n",
    "        # Feature 2: X2 sweet spot penalty\n",
    "        x2_optimal = 0.428\n",
    "        x2_tolerance = 0.02\n",
    "        x2_penalty = np.maximum(0, np.abs(X[:, 2] - x2_optimal) - x2_tolerance).reshape(-1, 1)\n",
    "        features.append(x2_penalty)\n",
    "        \n",
    "        # Feature 3: Ellipsoidal distance\n",
    "        weights = np.array([1.5, 1., 2.0])\n",
    "        ellipsoid_dist = np.sqrt(np.sum(\n",
    "            weights * np.square(X - optimal_point), axis=1\n",
    "        )).reshape(-1, 1)\n",
    "        features.append(ellipsoid_dist)\n",
    "        \n",
    "        # Feature 4: Binary indicator for proven optimal region\n",
    "        proven_region = (\n",
    "            (X[:, 0] >= 0.40) & (X[:, 0] <= 0.53) &\n",
    "            (X[:, 1] >= 0.51) & (X[:, 1] <= 0.64) &\n",
    "            (X[:, 2] >= 0.40) & (X[:, 2] <= 0.48)\n",
    "        ).astype(float).reshape(-1, 1)\n",
    "        features.append(proven_region)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "class Function4Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 4.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        optimal_point = np.array([0.420, 0.418, 0.373, 0.413])\n",
    "        \n",
    "        # Feature 1: Very tight Gaussian around global optimum\n",
    "        sigma = 0.04\n",
    "        gaussian_tight = np.exp(-np.sum(np.square(X - optimal_point), axis=1) / \n",
    "                               (2 * sigma**2)).reshape(-1, 1)\n",
    "        features.append(gaussian_tight)\n",
    "        \n",
    "        # Feature 2: Distance to optimal\n",
    "        dist_to_optimal = np.sqrt(np.sum(np.square(X - optimal_point), axis=1)).reshape(-1, 1)\n",
    "        features.append(dist_to_optimal)\n",
    "        \n",
    "        # Feature 3: Sum penalty (optimal sum around 1.625)\n",
    "        optimal_sum = 1.625\n",
    "        sum_penalty = np.abs(np.sum(X, axis=1) - optimal_sum).reshape(-1, 1)\n",
    "        features.append(sum_penalty)\n",
    "        \n",
    "        # Feature 4: Edge penalty\n",
    "        edge_penalty = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[1]):\n",
    "            edge_penalty += np.maximum(0, 0.35 - X[:, i])**2 + np.maximum(0, X[:, i] - 0.45)**2\n",
    "        edge_penalty = edge_penalty.reshape(-1, 1)\n",
    "        features.append(edge_penalty)\n",
    "        \n",
    "        # Feature 5: Binary indicator for ultra-tight optimal region\n",
    "        ultra_tight_region = (\n",
    "            (np.abs(X[:, 0] - 0.420) < 0.025) &\n",
    "            (np.abs(X[:, 1] - 0.418) < 0.025) &\n",
    "            (np.abs(X[:, 2] - 0.373) < 0.025) &\n",
    "            (np.abs(X[:, 3] - 0.413) < 0.025)\n",
    "        ).astype(float).reshape(-1, 1)\n",
    "        features.append(ultra_tight_region)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "class Function5Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 5.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        \n",
    "        # Feature 1: Full product (strongest predictor)\n",
    "        full_product = np.prod(X, axis=1).reshape(-1, 1)\n",
    "        features.append(full_product)\n",
    "        \n",
    "        # Feature 2: Core triple product x1 * x2 * x3\n",
    "        triple_product = (X[:, 1] * X[:, 2] * X[:, 3]).reshape(-1, 1)\n",
    "        features.append(triple_product)\n",
    "        \n",
    "        # Feature 3: Log of products (helps with extreme scaling)\n",
    "        epsilon = 1e-8\n",
    "        log_full_product = np.log(full_product + epsilon)\n",
    "        features.append(log_full_product)\n",
    "        \n",
    "        # Feature 4: \"Weak link\" penalty - minimum of x1,x2,x3\n",
    "        weak_link = np.minimum(np.minimum(X[:, 1], X[:, 2]), X[:, 3]).reshape(-1, 1)\n",
    "        features.append(weak_link)\n",
    "        \n",
    "        # Feature 5: High-performance region indicator\n",
    "        high_region = ((X[:, 1] > 0.8) & (X[:, 2] > 0.8) & (X[:, 3] > 0.8)).astype(float).reshape(-1, 1)\n",
    "        features.append(high_region)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "class Function6Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 6.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        optimal_point = np.array([0.463, 0.368, 0.640, 0.727, 0.046])\n",
    "        \n",
    "        # Feature 1: Distance to refined optimal point\n",
    "        dist_to_optimal = np.sqrt(np.sum(np.square(X - optimal_point), axis=1)).reshape(-1, 1)\n",
    "        features.append(dist_to_optimal)\n",
    "        \n",
    "        # Feature 2: X3*(1-X4) interaction\n",
    "        x3_x4inv = (X[:, 3] * (1 - X[:, 4])).reshape(-1, 1)\n",
    "        features.append(x3_x4inv)\n",
    "        \n",
    "        # Feature 3: X4 \"sweet spot\" penalty\n",
    "        x4_optimal = 0.045\n",
    "        x4_tolerance = 0.015\n",
    "        x4_penalty = np.maximum(0, np.abs(X[:, 4] - x4_optimal) - x4_tolerance).reshape(-1, 1)\n",
    "        features.append(x4_penalty)\n",
    "        \n",
    "        # Feature 4: X3 \"must be high\" constraint\n",
    "        x3_threshold = 0.7\n",
    "        x3_goodness = np.maximum(0, X[:, 3] - x3_threshold).reshape(-1, 1)\n",
    "        features.append(x3_goodness)\n",
    "        \n",
    "        # Feature 5: Tight Gaussian around refined optimal\n",
    "        sigma = 0.06\n",
    "        gaussian_tight = np.exp(-np.sum(np.square(X - optimal_point), axis=1) / \n",
    "                               (2 * sigma**2)).reshape(-1, 1)\n",
    "        features.append(gaussian_tight)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "class Function7Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 7.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        optimal_point = np.array([0.142, 0.133, 0.447, 0.303, 0.319, 0.698])\n",
    "        \n",
    "        # Feature 1: Distance to refined optimal point\n",
    "        dist_to_optimal = np.sqrt(np.sum(np.square(X - optimal_point), axis=1)).reshape(-1, 1)\n",
    "        features.append(dist_to_optimal)\n",
    "        \n",
    "        # Feature 2: X0 \"sweet spot\" penalty\n",
    "        x0_optimal = 0.13\n",
    "        x0_penalty = np.abs(X[:, 0] - x0_optimal).reshape(-1, 1)\n",
    "        features.append(x0_penalty)\n",
    "        \n",
    "        # Feature 3: Refined X0-X3-X5 interaction\n",
    "        x0_factor = np.exp(-50 * np.square(X[:, 0] - 0.13))\n",
    "        x3_factor = np.exp(-100 * np.square(X[:, 3] - 0.303))\n",
    "        x5_factor = np.exp(-20 * np.square(X[:, 5] - 0.698))\n",
    "        x0_x3_x5_optimal = (x0_factor * x3_factor * x5_factor).reshape(-1, 1)\n",
    "        features.append(x0_x3_x5_optimal)\n",
    "        \n",
    "        # Feature 4: X4 optimal constraint\n",
    "        x4_goodness = np.exp(-100 * np.square(X[:, 4] - 0.318)).reshape(-1, 1)\n",
    "        features.append(x4_goodness)\n",
    "        \n",
    "        # Feature 5: Tight Gaussian around refined optimal\n",
    "        sigma = 0.06\n",
    "        gaussian_tight = np.exp(-np.sum(np.square(X - optimal_point), axis=1) / \n",
    "                               (2 * sigma**2)).reshape(-1, 1)\n",
    "        features.append(gaussian_tight)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "class Function8Transformer(FeatureTransformer):\n",
    "    \"\"\"Feature transformer for function 8.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = [X]\n",
    "        optimal_point = np.array([0.130, 0.167, 0.146, 0.169, 0.815, 0.487, 0.209, 0.606])\n",
    "        \n",
    "        # Feature 1: Distance to refined optimal point\n",
    "        dist_to_optimal = np.sqrt(np.sum(np.square(X - optimal_point), axis=1)).reshape(-1, 1)\n",
    "        features.append(dist_to_optimal)\n",
    "        \n",
    "        # Feature 2: Refined key indicator\n",
    "        refined_key_indicator = ((X[:, 0] < 0.19) &\n",
    "                                (X[:, 4] > 0.70) &\n",
    "                                (X[:, 5] > 0.43) &\n",
    "                                (X[:, 5] < 0.59)).astype(float).reshape(-1, 1)\n",
    "        features.append(refined_key_indicator)\n",
    "        \n",
    "        # Feature 3: X4-X0 difference\n",
    "        x4_minus_x0 = (X[:, 4] - X[:, 0]).reshape(-1, 1)\n",
    "        features.append(x4_minus_x0)\n",
    "        \n",
    "        # Feature 4: X4-X0 \"sweet spot\" indicator\n",
    "        x4x0_good = ((X[:, 4] - X[:, 0]) >= 0.55) & ((X[:, 4] - X[:, 0]) <= 0.86)\n",
    "        x4x0_indicator = x4x0_good.astype(float).reshape(-1, 1)\n",
    "        features.append(x4x0_indicator)\n",
    "        \n",
    "        # Feature 5: Tight Gaussian around optimal\n",
    "        sigma = 0.05\n",
    "        gaussian_tight = np.exp(-np.sum(np.square(X - optimal_point), axis=1) / \n",
    "                               (2 * sigma**2)).reshape(-1, 1)\n",
    "        features.append(gaussian_tight)\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "# Factory for creating transformers\n",
    "class TransformerFactory:\n",
    "    \"\"\"Factory for creating feature transformers.\"\"\"\n",
    "    \n",
    "    _transformers = {\n",
    "        1: IdentityTransformer,\n",
    "        2: Function2Transformer,\n",
    "        3: Function3Transformer,\n",
    "        4: Function4Transformer,\n",
    "        5: Function5Transformer,\n",
    "        6: Function6Transformer,\n",
    "        7: Function7Transformer,\n",
    "        8: Function8Transformer,\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def create_transformer(cls, func_num):\n",
    "        \"\"\"Create appropriate transformer for function number.\"\"\"\n",
    "        transformer_class = cls._transformers.get(func_num, IdentityTransformer)\n",
    "        return transformer_class()\n",
    "    \n",
    "    @classmethod\n",
    "    def register_transformer(cls, func_num, transformer_class):\n",
    "        \"\"\"Register a new transformer for a function number.\"\"\"\n",
    "        cls._transformers[func_num] = transformer_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21381274-1adf-4398-8835-a21933957870",
   "metadata": {},
   "source": [
    "The following sections set up some classes and helper functions to implement warped kernels and deep kernels, for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359697a5-3914-4a01-804e-1ba9fa81bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assorted classes and functions to implement warped kernels\n",
    "\n",
    "class WarpedGP(ExactGP, GPyTorchModel):\n",
    "    \"\"\"Gaussian Process with input warping for non-stationary functions.\"\"\"\n",
    "    \n",
    "    _num_outputs = 1  # Single output for standard GP\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        train_X, \n",
    "        train_Y, \n",
    "        likelihood=None,\n",
    "        kernel_type=\"matern\",\n",
    "        nu=2.5,\n",
    "        ard=True,\n",
    "        warp_type=\"kumaraswamy\",\n",
    "        min_noise=1e-4\n",
    "    ):\n",
    "        # Initialize likelihood if not provided\n",
    "        if likelihood is None:\n",
    "            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "            \n",
    "        # Add minimum noise constraint for numerical stability\n",
    "        likelihood.noise_covar.register_constraint(\n",
    "            \"raw_noise\", \n",
    "            gpytorch.constraints.GreaterThan(min_noise)\n",
    "        )\n",
    "        \n",
    "        # Flatten train_Y if needed to avoid shape issues\n",
    "        if train_Y.ndim > 1 and train_Y.shape[1] == 1:\n",
    "            train_Y = train_Y.squeeze(-1)\n",
    "            \n",
    "        # Initialize the ExactGP parent class\n",
    "        super(WarpedGP, self).__init__(train_X, train_Y, likelihood)\n",
    "        \n",
    "        # BoTorch compatibility attributes\n",
    "        self.train_inputs = (train_X,)\n",
    "        self.train_targets = train_Y\n",
    "        self._input_batch_shape = train_X.shape[:-1]\n",
    "        self._aug_batch_shape = self._input_batch_shape\n",
    "        \n",
    "        # Input warping transform\n",
    "        self.input_dim = train_X.shape[-1]\n",
    "        self.warp_transform = WarpedInputTransform(self.input_dim, warp_type)\n",
    "        \n",
    "        # Mean and covariance modules\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        \n",
    "        # Set up kernel\n",
    "        if kernel_type == \"matern\":\n",
    "            base_kernel = gpytorch.kernels.MaternKernel(\n",
    "                nu=nu, ard_num_dims=self.input_dim if ard else None\n",
    "            )\n",
    "        elif kernel_type == \"rbf\":\n",
    "            base_kernel = gpytorch.kernels.RBFKernel(\n",
    "                ard_num_dims=self.input_dim if ard else None\n",
    "            )\n",
    "        elif kernel_type == \"rational_quadratic\":\n",
    "            base_kernel = gpytorch.kernels.RQKernel(\n",
    "                ard_num_dims=self.input_dim if ard else None\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown kernel type: {kernel_type}\")\n",
    "        \n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
    "        \n",
    "        # Initialize parameters to reasonable values\n",
    "        self._initialize_parameters()\n",
    "    \n",
    "    def _initialize_parameters(self):\n",
    "        \"\"\"Initialize model parameters to reasonable values.\"\"\"\n",
    "        # Initialize warping parameters to small values to prevent extreme warping initially\n",
    "        if hasattr(self.warp_transform, 'warp_params'):\n",
    "            self.warp_transform.warp_params.data.fill_(0.5)\n",
    "            # Add small noise to break symmetry\n",
    "            self.warp_transform.warp_params.data += torch.randn_like(self.warp_transform.warp_params.data) * 0.1\n",
    "        \n",
    "        # Initialize kernel parameters\n",
    "        if hasattr(self.covar_module, 'outputscale'):\n",
    "            self.covar_module.outputscale = torch.tensor(1.0)\n",
    "        \n",
    "        if hasattr(self.covar_module.base_kernel, 'lengthscale'):\n",
    "            self.covar_module.base_kernel.lengthscale = torch.tensor(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass with input warping.\"\"\"\n",
    "        # Apply input warping\n",
    "        x_warped = self.warp_transform.transform(x)\n",
    "        \n",
    "        # Pass through GP\n",
    "        mean_x = self.mean_module(x_warped)\n",
    "        covar_x = self.covar_module(x_warped)\n",
    "        \n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class WarpedInputTransform(InputTransform):\n",
    "    \"\"\"Input warping transformation using parameterized functions.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, warp_type=\"kumaraswamy\"):\n",
    "        \"\"\"\n",
    "        Initialize input warping transform.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Number of input dimensions\n",
    "            warp_type: Type of warping function to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.warp_type = warp_type\n",
    "        self._is_trained = False\n",
    "        \n",
    "        # Initialize warping parameters (3 per dimension)\n",
    "        # Use smaller initial values\n",
    "        if warp_type == \"kumaraswamy\":\n",
    "            # a, b, c parameters - a & b control shape, c controls direction\n",
    "            self.register_parameter(\n",
    "                \"warp_params\",\n",
    "                torch.nn.Parameter(torch.ones(input_dim, 3) * 0.5)\n",
    "            )\n",
    "        elif warp_type == \"tanh\":\n",
    "            # scale, shift, direction parameters\n",
    "            self.register_parameter(\n",
    "                \"warp_params\",\n",
    "                torch.nn.Parameter(torch.ones(input_dim, 3) * 0.5)\n",
    "            )\n",
    "        elif warp_type == \"sigmoid\":\n",
    "            # scale, shift, direction parameters\n",
    "            self.register_parameter(\n",
    "                \"warp_params\",\n",
    "                torch.nn.Parameter(torch.ones(input_dim, 3) * 0.5)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown warp type: {warp_type}\")\n",
    "        \n",
    "        # Initialize bounds - will be set during transform\n",
    "        self.register_buffer(\"mins\", torch.zeros(input_dim))\n",
    "        self.register_buffer(\"ranges\", torch.ones(input_dim))\n",
    "        self._has_initialized_bounds = False\n",
    "    \n",
    "    def _update_bounds(self, X):\n",
    "        \"\"\"Update bounds for normalization.\"\"\"\n",
    "        if not self._has_initialized_bounds:\n",
    "            with torch.no_grad():\n",
    "                self.mins = X.min(dim=0)[0].clone()\n",
    "                self.ranges = (X.max(dim=0)[0] - X.min(dim=0)[0]).clone()\n",
    "                self.ranges[self.ranges < 1e-6] = 1.0  # Avoid division by zero\n",
    "                self._has_initialized_bounds = True\n",
    "    \n",
    "    def _normalize(self, X):\n",
    "        \"\"\"Normalize inputs to [0, 1] range.\"\"\"\n",
    "        self._update_bounds(X)\n",
    "        # Use torch.clamp to ensure numerical stability\n",
    "        return torch.clamp((X - self.mins) / self.ranges, 0.0, 1.0)\n",
    "    \n",
    "    def _warp_kumaraswamy(self, X_norm):\n",
    "        \"\"\"Apply Kumaraswamy warping function with numerical stability.\"\"\"\n",
    "        # Get parameters and ensure a, b > 0 without getting too large\n",
    "        a = torch.exp(self.warp_params[:, 0].unsqueeze(0)) + 0.5  # Less extreme than abs()\n",
    "        b = torch.exp(self.warp_params[:, 1].unsqueeze(0)) + 0.5\n",
    "        c = torch.tanh(self.warp_params[:, 2].unsqueeze(0)) * 0.5 + 0.5  # Bound to [0, 1]\n",
    "        \n",
    "        # Add small epsilon to prevent issues at boundaries\n",
    "        X_norm_safe = torch.clamp(X_norm, 1e-6, 1.0 - 1e-6)\n",
    "        \n",
    "        # Apply Kumaraswamy transformation with numerical stability\n",
    "        warped = 1 - (1 - X_norm_safe.pow(a)).pow(b)\n",
    "        \n",
    "        # Linear combination for directional control\n",
    "        result = warped * c + X_norm_safe * (1 - c)\n",
    "        \n",
    "        # Ensure result is in [0, 1]\n",
    "        return torch.clamp(result, 0.0, 1.0)\n",
    "    \n",
    "    def _warp_tanh(self, X_norm):\n",
    "        \"\"\"Apply hyperbolic tangent warping with numerical stability.\"\"\"\n",
    "        # Get parameters with bounded magnitudes\n",
    "        scale = torch.exp(self.warp_params[:, 0].unsqueeze(0))  # Positive\n",
    "        shift = torch.tanh(self.warp_params[:, 1].unsqueeze(0)) * 2  # Between -2 and 2\n",
    "        direction = torch.sigmoid(self.warp_params[:, 2].unsqueeze(0))  # Between 0 and 1\n",
    "        \n",
    "        # Apply tanh warping\n",
    "        centered = X_norm * 2 - 1  # Map [0,1] to [-1,1]\n",
    "        warped = torch.tanh(scale * (centered + shift))  # Apply tanh\n",
    "        warped = (warped + 1) / 2  # Map back to [0,1]\n",
    "        \n",
    "        # Linear combination\n",
    "        result = warped * direction + X_norm * (1 - direction)\n",
    "        \n",
    "        return torch.clamp(result, 0.0, 1.0)\n",
    "    \n",
    "    def _warp_sigmoid(self, X_norm):\n",
    "        \"\"\"Apply sigmoid warping with numerical stability.\"\"\"\n",
    "        # Get parameters with bounded magnitudes\n",
    "        scale = torch.exp(self.warp_params[:, 0].unsqueeze(0)) + 1.0  # > 1.0\n",
    "        shift = torch.tanh(self.warp_params[:, 1].unsqueeze(0)) * 2  # Between -2 and 2\n",
    "        direction = torch.sigmoid(self.warp_params[:, 2].unsqueeze(0))  # Between 0 and 1\n",
    "        \n",
    "        # Apply sigmoid warping\n",
    "        centered = X_norm * 2 - 1  # Map [0,1] to [-1,1]\n",
    "        warped = torch.sigmoid(scale * (centered + shift))  # Apply sigmoid\n",
    "        \n",
    "        # Linear combination\n",
    "        result = warped * direction + X_norm * (1 - direction)\n",
    "        \n",
    "        return torch.clamp(result, 0.0, 1.0)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform the inputs using the selected warping function.\"\"\"\n",
    "        if torch.isnan(X).any():\n",
    "            raise ValueError(\"Input contains NaN values\")\n",
    "        \n",
    "        # Normalize to [0,1]\n",
    "        X_norm = self._normalize(X)\n",
    "        \n",
    "        if torch.isnan(X_norm).any():\n",
    "            raise ValueError(\"Normalized input contains NaN values\")\n",
    "        \n",
    "        # Apply appropriate warping\n",
    "        if self.warp_type == \"kumaraswamy\":\n",
    "            X_warped = self._warp_kumaraswamy(X_norm)\n",
    "        elif self.warp_type == \"tanh\":\n",
    "            X_warped = self._warp_tanh(X_norm)\n",
    "        elif self.warp_type == \"sigmoid\":\n",
    "            X_warped = self._warp_sigmoid(X_norm)\n",
    "        \n",
    "        # Check for NaNs in the output\n",
    "        if torch.isnan(X_warped).any():\n",
    "            # Fall back to identity transform in case of NaNs\n",
    "            print(\"Warning: NaN detected in warped output. Falling back to identity transform.\")\n",
    "            return X_norm\n",
    "        \n",
    "        return X_warped\n",
    "\n",
    "def fit_warped_gp_model(model, training_iterations=300, early_stopping=True):\n",
    "    \"\"\"Train warped GP model with robust error handling.\"\"\"\n",
    "    model.train()\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    \n",
    "    # Create optimizer with reasonable learning rates\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.warp_transform.parameters(), 'lr': 0.01},  # Lower learning rate\n",
    "        {'params': model.covar_module.parameters(), 'lr': 0.01},\n",
    "        {'params': model.mean_module.parameters(), 'lr': 0.01},\n",
    "        {'params': model.likelihood.parameters(), 'lr': 0.01},\n",
    "    ])\n",
    "    \n",
    "    # Learning rate scheduler with less aggressive decay\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "    \n",
    "    # Training loop with robust error handling\n",
    "    losses = []\n",
    "    best_loss = float('inf')\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    nan_counter = 0\n",
    "    \n",
    "    # Try multiple initializations if needed\n",
    "    max_reinits = 3\n",
    "    reinit_counter = 0\n",
    "    \n",
    "    while reinit_counter < max_reinits:\n",
    "        try:\n",
    "            # Main training loop\n",
    "            for i in range(training_iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                try:\n",
    "                    # Forward pass with error checking\n",
    "                    output = model(model.train_inputs[0])\n",
    "                    \n",
    "                    # Check for NaNs in output\n",
    "                    if torch.isnan(output.mean).any() or torch.isnan(output.variance).any():\n",
    "                        print(f\"NaN detected in model output at iteration {i+1}\")\n",
    "                        nan_counter += 1\n",
    "                        if nan_counter > 5:\n",
    "                            raise ValueError(\"Too many NaN outputs\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate loss with robust error handling\n",
    "                    try:\n",
    "                        loss = -mll(output, model.train_targets)\n",
    "                        if torch.isnan(loss) or torch.isinf(loss):\n",
    "                            print(f\"NaN/Inf loss at iteration {i+1}\")\n",
    "                            nan_counter += 1\n",
    "                            if nan_counter > 5:\n",
    "                                raise ValueError(\"Too many NaN losses\")\n",
    "                            continue\n",
    "                            \n",
    "                        if loss.numel() > 1:\n",
    "                            loss = loss.mean()\n",
    "                            \n",
    "                        current_loss = loss.item()\n",
    "                        losses.append(current_loss)\n",
    "                        \n",
    "                    except RuntimeError as e:\n",
    "                        if \"cholesky\" in str(e).lower():\n",
    "                            print(f\"Cholesky error at iteration {i+1}: {e}\")\n",
    "                            # Add jitter to the model's covariance matrix\n",
    "                            if hasattr(model.likelihood, 'noise'):\n",
    "                                # Increase noise level\n",
    "                                with torch.no_grad():\n",
    "                                    current_noise = model.likelihood.noise.item()\n",
    "                                    model.likelihood.noise = torch.tensor(current_noise + 1e-3)\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise e\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Gradient clipping to prevent extreme parameter updates\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Step the scheduler\n",
    "                    if (i + 1) % 20 == 0:\n",
    "                        scheduler.step()\n",
    "                    \n",
    "                    # Early stopping logic\n",
    "                    if early_stopping:\n",
    "                        if current_loss < best_loss:\n",
    "                            best_loss = current_loss\n",
    "                            patience_counter = 0\n",
    "                        else:\n",
    "                            patience_counter += 1\n",
    "                            \n",
    "                        if patience_counter >= patience:\n",
    "                            print(f\"Early stopping at iteration {i+1}\")\n",
    "                            break\n",
    "                        \n",
    "                    # Print progress\n",
    "#                    if (i + 1) % 50 == 0:\n",
    "#                        print(f\"Iteration {i+1}/{training_iterations} - Loss: {current_loss:.6f}\")\n",
    "                \n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Runtime error at iteration {i+1}: {e}\")\n",
    "                    if \"cholesky\" in str(e).lower() or \"nan\" in str(e).lower():\n",
    "                        nan_counter += 1\n",
    "                        if nan_counter > 5:\n",
    "                            break\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "            \n",
    "            # If we completed at least some iterations successfully, return the model\n",
    "            if len(losses) > 0:\n",
    "#                print(f\"Training completed with final loss: {losses[-1]:.6f}\")\n",
    "                model.eval()\n",
    "                return model\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Exception during training: {e}\")\n",
    "            print(f\"Reinitializing model parameters (attempt {reinit_counter+1}/{max_reinits})\")\n",
    "        \n",
    "        # If we reached here, training failed - reinitialize and try again\n",
    "        reinit_counter += 1\n",
    "        \n",
    "        # Reinitialize model parameters\n",
    "        if reinit_counter < max_reinits:\n",
    "            with torch.no_grad():\n",
    "                # Reset warping parameters to small values\n",
    "                if hasattr(model.warp_transform, 'warp_params'):\n",
    "                    model.warp_transform.warp_params.data.fill_(0.0)\n",
    "                    model.warp_transform.warp_params.data += torch.randn_like(model.warp_transform.warp_params.data) * 0.1\n",
    "                \n",
    "                # Reset kernel parameters\n",
    "                if hasattr(model.covar_module, 'outputscale'):\n",
    "                    model.covar_module.outputscale = torch.tensor(1.0)\n",
    "                \n",
    "                if hasattr(model.covar_module.base_kernel, 'lengthscale'):\n",
    "                    model.covar_module.base_kernel.lengthscale = torch.tensor(1.0)\n",
    "                \n",
    "                # Increase noise for stability\n",
    "                model.likelihood.noise = torch.tensor(1e-3 * (reinit_counter + 1))\n",
    "            \n",
    "            # Create new optimizer\n",
    "            optimizer = torch.optim.Adam([\n",
    "                {'params': model.warp_transform.parameters(), 'lr': 0.01 / (reinit_counter + 1)},\n",
    "                {'params': model.covar_module.parameters(), 'lr': 0.01 / (reinit_counter + 1)},\n",
    "                {'params': model.mean_module.parameters(), 'lr': 0.01 / (reinit_counter + 1)},\n",
    "                {'params': model.likelihood.parameters(), 'lr': 0.01 / (reinit_counter + 1)},\n",
    "            ])\n",
    "            \n",
    "            # Reset counters\n",
    "            losses = []\n",
    "            best_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            nan_counter = 0\n",
    "    \n",
    "    # If all training attempts failed, return a simple GP model\n",
    "    print(\"Warning: Could not train warped GP model. Falling back to simple GP.\")\n",
    "    return create_fallback_model(model.train_inputs[0], model.train_targets)\n",
    "\n",
    "def create_fallback_model(train_X, train_Y):\n",
    "    \"\"\"Create a simple GP model as fallback.\"\"\"\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    \n",
    "    class SimpleGP(gpytorch.models.ExactGP, GPyTorchModel):\n",
    "        _num_outputs = 1\n",
    "        \n",
    "        def __init__(self, train_X, train_Y, likelihood):\n",
    "            super().__init__(train_X, train_Y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "            \n",
    "            # BoTorch compatibility\n",
    "            self.train_inputs = (train_X,)\n",
    "            self.train_targets = train_Y\n",
    "            self._input_batch_shape = train_X.shape[:-1]\n",
    "            self._aug_batch_shape = self._input_batch_shape\n",
    "        \n",
    "        def forward(self, x):\n",
    "            mean = self.mean_module(x)\n",
    "            covar = self.covar_module(x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
    "        \n",
    "        @property\n",
    "        def num_outputs(self):\n",
    "            return self._num_outputs\n",
    "            \n",
    "        @property\n",
    "        def batch_shape(self):\n",
    "            return torch.Size(self._aug_batch_shape)\n",
    "        \n",
    "        def posterior(self, X, observation_noise=False, **kwargs):\n",
    "            self.eval()\n",
    "            dist = self(X)\n",
    "            if observation_noise:\n",
    "                dist = self.likelihood(dist)\n",
    "            from botorch.posteriors.gpytorch import GPyTorchPosterior\n",
    "            return GPyTorchPosterior(distribution=dist)\n",
    "    \n",
    "    # Create and train a simple model\n",
    "    model = SimpleGP(train_X, train_Y, likelihood)\n",
    "    \n",
    "    # Simple training loop\n",
    "    model.train()\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    \n",
    "    for i in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_X)\n",
    "        loss = -mll(output, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "class WarpedGPWrapper:\n",
    "    \"\"\"Enhanced wrapper for warped GP model with support for kernel analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, warped_gp_model, X_train=None, y_train=None):\n",
    "        \"\"\"\n",
    "        Initialize with a trained warped GP model.\n",
    "        \n",
    "        Args:\n",
    "            warped_gp_model: A trained WarpedGP or RobustWarpedGP model\n",
    "            X_train: Training inputs (needed for refitting)\n",
    "            y_train: Training outputs (needed for refitting)\n",
    "        \"\"\"\n",
    "        self.model = deepcopy(warped_gp_model)  # Make a deep copy\n",
    "        self.model.eval()  # Ensure model is in evaluation mode\n",
    "        \n",
    "        # Store training data for refitting if provided\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        # Extract kernel parameters for compatibility\n",
    "        self._extract_kernel_params()\n",
    "        \n",
    "        # Create a kernel attribute that mimics scikit-learn's kernel\n",
    "        self._create_kernel_attribute()\n",
    "    \n",
    "    def _extract_kernel_params(self):\n",
    "        \"\"\"Extract kernel parameters from the warped GP model.\"\"\"\n",
    "        # Extract lengthscale\n",
    "        if hasattr(self.model.covar_module, 'base_kernel') and hasattr(self.model.covar_module.base_kernel, 'lengthscale'):\n",
    "            self.length_scale_ = self.model.covar_module.base_kernel.lengthscale.detach().cpu().numpy()\n",
    "            if len(self.length_scale_.shape) > 1:\n",
    "                self.length_scale_ = self.length_scale_.squeeze()\n",
    "        else:\n",
    "            self.length_scale_ = np.ones(1)\n",
    "        \n",
    "        # Extract output scale (constant kernel parameter in sklearn)\n",
    "        if hasattr(self.model.covar_module, 'outputscale'):\n",
    "            self.constant_ = self.model.covar_module.outputscale.detach().cpu().numpy()\n",
    "        else:\n",
    "            self.constant_ = 1.0\n",
    "            \n",
    "        # Extract noise level\n",
    "        if hasattr(self.model, 'likelihood') and hasattr(self.model.likelihood, 'noise'):\n",
    "            self.alpha = self.model.likelihood.noise.detach().cpu().numpy()\n",
    "        else:\n",
    "            self.alpha = 0.01\n",
    "            \n",
    "        # Determine kernel type\n",
    "        if hasattr(self.model.covar_module, 'base_kernel'):\n",
    "            kernel_type = self.model.covar_module.base_kernel.__class__.__name__\n",
    "            if 'Matern' in kernel_type:\n",
    "                self.kernel_type = 'Matern'\n",
    "                # Extract nu parameter if available\n",
    "                if hasattr(self.model.covar_module.base_kernel, 'nu'):\n",
    "                    self.nu = self.model.covar_module.base_kernel.nu\n",
    "                else:\n",
    "                    self.nu = 2.5  # Default value\n",
    "            elif 'RBF' in kernel_type:\n",
    "                self.kernel_type = 'RBF'\n",
    "            elif 'RQ' in kernel_type or 'RationalQuadratic' in kernel_type:\n",
    "                self.kernel_type = 'RationalQuadratic'\n",
    "            else:\n",
    "                self.kernel_type = 'Generic'\n",
    "        else:\n",
    "            self.kernel_type = 'Unknown'\n",
    "        \n",
    "        # Input dimension\n",
    "        if hasattr(self.model, 'input_dim'):\n",
    "            self.n_dims = self.model.input_dim\n",
    "        elif hasattr(self.length_scale_, '__len__'):\n",
    "            self.n_dims = len(self.length_scale_)\n",
    "        else:\n",
    "            self.n_dims = 1\n",
    "    \n",
    "    def _create_kernel_attribute(self):\n",
    "        \"\"\"Create a kernel attribute that behaves similarly to sklearn's kernels.\"\"\"\n",
    "        from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel, RationalQuadratic\n",
    "        \n",
    "        # Create base kernel\n",
    "        if self.kernel_type == 'Matern':\n",
    "            base_kernel = Matern(length_scale=self.length_scale_, nu=self.nu)\n",
    "        elif self.kernel_type == 'RationalQuadratic':\n",
    "            base_kernel = RationalQuadratic(length_scale=self.length_scale_, alpha=1.0)\n",
    "        else:  # Default to RBF\n",
    "            base_kernel = RBF(length_scale=self.length_scale_)\n",
    "        \n",
    "        # Create compound kernel with constant\n",
    "        self.kernel_ = ConstantKernel(constant_value=self.constant_) * base_kernel\n",
    "        \n",
    "        # Add kernel name for display\n",
    "        if hasattr(self.model, 'warp_transform'):\n",
    "            warp_type = getattr(self.model.warp_transform, 'warp_type', 'unknown')\n",
    "            self.kernel_name = f\"Warped ({warp_type}) {self.kernel_type}\"\n",
    "        else:\n",
    "            self.kernel_name = f\"Warped {self.kernel_type}\"\n",
    "    \n",
    "    def predict(self, X, return_std=False, return_cov=False):\n",
    "        \"\"\"Predict using the warped GP model.\"\"\"\n",
    "        # Convert input to tensor\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                posterior = self.model(X_tensor)\n",
    "                mean = posterior.mean.cpu().numpy()\n",
    "                \n",
    "                if return_std or return_cov:\n",
    "                    # Get variance/covariance\n",
    "                    if hasattr(posterior, 'variance'):\n",
    "                        variance = posterior.variance.cpu().numpy()\n",
    "                    else:\n",
    "                        # Calculate from confidence region\n",
    "                        lower, upper = posterior.confidence_region()\n",
    "                        variance = ((upper - lower) / 4.0).cpu().numpy() ** 2\n",
    "                    \n",
    "                    if return_cov:\n",
    "                        # Create full covariance matrix (diagonal for simplicity)\n",
    "                        cov = np.diag(variance)\n",
    "                        return mean, cov\n",
    "                    else:\n",
    "                        std = np.sqrt(variance)\n",
    "                        return mean, std\n",
    "                else:\n",
    "                    return mean\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Prediction error: {e}\")\n",
    "                # Fallback prediction\n",
    "                if return_std:\n",
    "                    return np.zeros(len(X)), np.ones(len(X))\n",
    "                elif return_cov:\n",
    "                    return np.zeros(len(X)), np.eye(len(X))\n",
    "                else:\n",
    "                    return np.zeros(len(X))\n",
    "    \n",
    "    def sample_y(self, X, n_samples=1, random_state=None):\n",
    "        \"\"\"Sample from the GP posterior at X.\"\"\"\n",
    "        # Set random seed if provided\n",
    "        if random_state is not None:\n",
    "            torch.manual_seed(random_state)\n",
    "            \n",
    "        # Convert input to tensor\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        # Get posterior\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                posterior = self.model(X_tensor)\n",
    "                \n",
    "                # Sample from posterior\n",
    "                samples = posterior.sample(sample_shape=torch.Size([n_samples])).cpu().numpy()\n",
    "                \n",
    "                # Transpose to match scikit-learn's output format\n",
    "                return samples.T\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Sampling error: {e}\")\n",
    "                # Fallback: return zeros\n",
    "                return np.zeros((len(X), n_samples))\n",
    "    \n",
    "    def log_marginal_likelihood(self, theta=None):\n",
    "        \"\"\"Return log marginal likelihood.\"\"\"\n",
    "        # If no theta is provided, return the current model's LML\n",
    "        if theta is None:\n",
    "            # We need the training data to compute this\n",
    "            if self.X_train is not None and self.y_train is not None:\n",
    "                # Convert to tensors\n",
    "                X_tensor = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "                y_tensor = torch.tensor(self.y_train, dtype=torch.float32)\n",
    "                \n",
    "                # Compute LML\n",
    "                from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "                mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "                with torch.no_grad():\n",
    "                    output = self.model(X_tensor)\n",
    "                    lml = mll(output, y_tensor).item()\n",
    "                return lml\n",
    "            return 0.0\n",
    "        \n",
    "        # If theta is provided, this is typically used for optimization\n",
    "        # We don't support this directly in the wrapper\n",
    "        return 0.0\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return R^2 score.\"\"\"\n",
    "        from sklearn.metrics import r2_score\n",
    "        \n",
    "        # Convert input to tensor\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                posterior = self.model(X_tensor)\n",
    "                mean = posterior.mean.cpu().numpy()\n",
    "                return r2_score(y, mean)\n",
    "            except Exception as e:\n",
    "                print(f\"Scoring error: {e}\")\n",
    "                return -1.0  # Fallback score\n",
    "                \n",
    "    def fit(self, X=None, y=None):\n",
    "        \"\"\"\n",
    "        Provide a fit method that mimics sklearn's fit.\n",
    "        This doesn't actually refit the model but provides compatibility.\n",
    "        \"\"\"\n",
    "        # Store the data if provided\n",
    "        if X is not None:\n",
    "            self.X_train = X\n",
    "        if y is not None:\n",
    "            self.y_train = y\n",
    "            \n",
    "        # Return self for chaining\n",
    "        return self\n",
    "        \n",
    "    def clone_and_set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Create a clone of this wrapper with modified parameters.\n",
    "        This is used for dimension analysis.\n",
    "        \"\"\"\n",
    "        # Create a new wrapper\n",
    "        new_wrapper = deepcopy(self)\n",
    "        \n",
    "        # If we're modifying kernel parameters\n",
    "        if 'kernel' in params:\n",
    "            # Here we would need to modify the underlying warped GP\n",
    "            # This is challenging to do generically\n",
    "            # Let's implement a simplified version for common cases\n",
    "            \n",
    "            # Extract the parameter changes\n",
    "            kernel = params['kernel']\n",
    "            \n",
    "            # Check if we're modifying the lengthscales\n",
    "            if hasattr(kernel, 'k2') and hasattr(kernel.k2, 'length_scale'):\n",
    "                new_lengthscales = kernel.k2.length_scale\n",
    "                \n",
    "                # Update the model's lengthscales\n",
    "                if hasattr(new_wrapper.model.covar_module, 'base_kernel') and hasattr(new_wrapper.model.covar_module.base_kernel, 'lengthscale'):\n",
    "                    with torch.no_grad():\n",
    "                        new_wrapper.model.covar_module.base_kernel.lengthscale = torch.tensor(new_lengthscales, dtype=torch.float32)\n",
    "                        \n",
    "                # Update stored lengthscales\n",
    "                new_wrapper.length_scale_ = new_lengthscales\n",
    "            \n",
    "            # Check if we're modifying the constant\n",
    "            if hasattr(kernel, 'k1') and hasattr(kernel.k1, 'constant_value'):\n",
    "                new_constant = kernel.k1.constant_value\n",
    "                \n",
    "                # Update the model's outputscale\n",
    "                if hasattr(new_wrapper.model.covar_module, 'outputscale'):\n",
    "                    with torch.no_grad():\n",
    "                        new_wrapper.model.covar_module.outputscale = torch.tensor(new_constant, dtype=torch.float32)\n",
    "                        \n",
    "                # Update stored constant\n",
    "                new_wrapper.constant_ = new_constant\n",
    "                \n",
    "            # Update the kernel attribute\n",
    "            new_wrapper._create_kernel_attribute()\n",
    "        \n",
    "        return new_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76a0b46-2c31-4bf7-8f11-c68c152b14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assorted classes and functions to implement deep kernels\n",
    "\n",
    "class DeepKernelGP(gpytorch.models.ExactGP, GPyTorchModel):\n",
    "    \"\"\"GP model with a deep kernel feature extractor and BoTorch compatibility.\"\"\"\n",
    "    \n",
    "    # Class attribute required by BoTorch\n",
    "    _num_outputs = 1\n",
    "    \n",
    "    def __init__(self, train_X, train_Y, likelihood=None, input_dim=None, \n",
    "                hidden_dims=[50, 20], output_dim=None):\n",
    "        if likelihood is None:\n",
    "            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        \n",
    "        # Ensure tensors have the right type and shape\n",
    "        if train_Y.ndim > 1 and train_Y.shape[1] == 1:\n",
    "            train_Y = train_Y.squeeze(-1)\n",
    "        \n",
    "        # Initialize the ExactGP parent class\n",
    "        super(DeepKernelGP, self).__init__(train_X, train_Y, likelihood)\n",
    "        \n",
    "        # BoTorch compatibility attributes\n",
    "        self._is_trained = True\n",
    "        self._input_batch_shape = train_X.shape[:-1]\n",
    "        self._aug_batch_shape = self._input_batch_shape\n",
    "        \n",
    "        self.input_dim = input_dim or train_X.shape[-1]\n",
    "        self.output_dim = output_dim or max(3, self.input_dim)\n",
    "        \n",
    "        # Feature extractor\n",
    "        layers = []\n",
    "        prev_dim = self.input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, self.output_dim))\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "        # GP components\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.base_covar_module = gpytorch.kernels.MaternKernel(\n",
    "            nu=1.5, ard_num_dims=self.output_dim)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(self.base_covar_module)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.feature_extractor:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the model.\"\"\"\n",
    "        # Ensure x has the correct data type\n",
    "        x = x.to(self.feature_extractor[0].weight.dtype)\n",
    "        projected_x = self.feature_extractor(x)\n",
    "        mean_x = self.mean_module(projected_x)\n",
    "        covar_x = self.covar_module(projected_x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    # Required properties and methods for BoTorch compatibility\n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        \"\"\"The number of outputs of the model.\"\"\"\n",
    "        return self._num_outputs\n",
    "    \n",
    "    @property\n",
    "    def batch_shape(self):\n",
    "        \"\"\"The batch shape of the model.\"\"\"\n",
    "        return torch.Size(self._aug_batch_shape)\n",
    "    \n",
    "    def posterior(self, X, observation_noise=False, **kwargs):\n",
    "        \"\"\"Get posterior distribution at test points.\"\"\"\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        # Ensure inputs require gradients for optimization\n",
    "        X_input = X\n",
    "        if X.requires_grad == False and X.is_leaf:\n",
    "            X_input = X.detach().clone().requires_grad_(True)\n",
    "            \n",
    "        # Convert input dtype if needed\n",
    "        X_input = X_input.to(self.feature_extractor[0].weight.dtype)\n",
    "        \n",
    "        # Get the predictive distribution\n",
    "        dist = self(X_input)\n",
    "        if observation_noise:\n",
    "            dist = self.likelihood(dist)\n",
    "            \n",
    "        # Create GPyTorchPosterior\n",
    "        return GPyTorchPosterior(distribution=dist)\n",
    "\n",
    "def fit_deep_kernel_model(model, training_iterations=500, early_stopping=True, min_loss_threshold=0.2):\n",
    "    \"\"\"Train deep kernel GP model with regularization and early stopping.\"\"\"\n",
    "    model.train()\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    '''\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.feature_extractor.parameters(), 'lr': 0.05, 'weight_decay': 1e-4},\n",
    "        {'params': model.mean_module.parameters(), 'lr': 0.01, 'weight_decay': 1e-6},\n",
    "        {'params': model.covar_module.parameters(), 'lr': 0.01, 'weight_decay': 1e-6},\n",
    "        {'params': model.likelihood.parameters(), 'lr': 0.01, 'weight_decay': 1e-6},\n",
    "    ])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)  # Faster decay\n",
    "    '''\n",
    "    \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.feature_extractor.parameters(), 'lr': 0.01, 'weight_decay': 1e-2}, # was 1e-4\n",
    "        {'params': model.mean_module.parameters(), 'weight_decay': 1e-4}, # all these were 1e-6\n",
    "        {'params': model.covar_module.parameters(), 'weight_decay': 1e-4},\n",
    "        {'params': model.likelihood.parameters(), 'weight_decay': 1e-4},\n",
    "    ])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    \n",
    "\n",
    "    # Training loop\n",
    "    losses = []\n",
    "    best_loss = float('inf')\n",
    "    patience = 20  # Early stopping patience\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(model.train_inputs[0])\n",
    "        \n",
    "        try:\n",
    "            # Calculate loss - ensure it's scalar\n",
    "            loss = -mll(output, model.train_targets)\n",
    "            if loss.numel() > 1:\n",
    "                loss = loss.mean()\n",
    "            current_loss = loss.item()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {e}. Using alternative loss calculation.\")\n",
    "            # Alternative approach if we encounter issues\n",
    "            loss = -mll(output, model.train_targets)\n",
    "            if isinstance(loss, torch.Tensor) and loss.numel() > 1:\n",
    "                loss = loss.mean()\n",
    "            current_loss = float(loss.detach().cpu().numpy().mean())\n",
    "            \n",
    "        losses.append(current_loss)\n",
    "        \n",
    "        # Stop if loss is too small (potential overfitting)\n",
    "        if current_loss < min_loss_threshold:\n",
    "            print(f\"Loss below threshold ({current_loss:.6f} < {min_loss_threshold:.6f}), stopping early\")\n",
    "            break\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Step the scheduler every 10 iterations\n",
    "        if (i + 1) % 10 == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if early_stopping:\n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at iteration {i+1}\")\n",
    "                break\n",
    "            \n",
    "        # Print progress\n",
    "#        if (i + 1) % 50 == 0:\n",
    "#            print(f\"Iteration {i+1}/{training_iterations} - Loss: {current_loss:.6f}\")\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d53b2a-7603-42e3-93e6-9fc48b52bc2c",
   "metadata": {},
   "source": [
    "The following sections set up some helper classes for logging, tensor manipulation and optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e3ef80-5a0e-4599-b6a6-6a747146b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for logging\n",
    "\n",
    "class OptimizationLogger:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, parameters, result):\n",
    "        self.history.append({\n",
    "            \"parameters\": {k: deepcopy(v.numpy(force=True)) for k, v in parameters.items()},\n",
    "            \"result\": result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a855cf-ea17-4f0f-b9c8-3c455ded88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to help with tensor shapes when adding feature engineering to BoTorch through an input transformation\n",
    "\n",
    "class CustomInputTransform(InputTransform):\n",
    "    def __init__(self, preprocess_func):\n",
    "        super().__init__()\n",
    "        self.preprocess_func = preprocess_func\n",
    "        # Initialize the transform properties\n",
    "        self._transform_on_train = True \n",
    "        self._transform_on_eval = True\n",
    "        self._transform_on_fantasize = True\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform inputs while preserving gradients and batch dimensions\"\"\"\n",
    "        # Get the original shape for reference\n",
    "        original_shape = X.shape\n",
    "        original_ndim = X.dim()\n",
    "        \n",
    "        try:\n",
    "            # Make sure X is contiguous in memory before reshaping\n",
    "            if not X.is_contiguous():\n",
    "                X = X.contiguous()\n",
    "            \n",
    "            # Handle different tensor shapes based on dimensionality\n",
    "            if original_ndim > 3:  # Complex batch structure like [num_fantasies, batch, q, dim]\n",
    "                # Extract key dimensions\n",
    "                fantasy_batch = original_shape[:-3]  # Fantasy and other leading batch dims\n",
    "                t_batch = original_shape[-3]         # t-batch dimension\n",
    "                q_batch = original_shape[-2]         # q-batch dimension\n",
    "                feat_dim = original_shape[-1]        # Feature dimension\n",
    "                \n",
    "                # Flatten to 2D for preprocessing\n",
    "                # Combine all batch dimensions into one\n",
    "                total_batch = np.prod(fantasy_batch) * t_batch * q_batch\n",
    "                X_flat = X.reshape(total_batch, feat_dim)\n",
    "                \n",
    "                # Convert to numpy for preprocessing\n",
    "                X_np = X_flat.detach().cpu().numpy()\n",
    "                X_processed_np = self.preprocess_func(X_np)\n",
    "                \n",
    "                # Get the processed feature dimension\n",
    "                processed_feat_dim = X_processed_np.shape[1] if X_processed_np.ndim > 1 else 1\n",
    "                \n",
    "                # Create tensor and reshape back to original batch dimensions\n",
    "                X_processed = torch.tensor(\n",
    "                    X_processed_np, \n",
    "                    dtype=X.dtype, \n",
    "                    device=X.device\n",
    "                )\n",
    "                \n",
    "                # Reshape back to match the original batch structure\n",
    "                new_shape = fantasy_batch + (t_batch, q_batch, processed_feat_dim)\n",
    "                X_processed = X_processed.reshape(new_shape)\n",
    "                \n",
    "            elif original_ndim == 3:  # Standard batched input [batch, q, dim]\n",
    "                batch_size, q, feat_dim = original_shape\n",
    "                \n",
    "                # Reshape to 2D for preprocessing\n",
    "                X_flat = X.reshape(batch_size * q, feat_dim)\n",
    "                \n",
    "                # Convert to numpy for preprocessing\n",
    "                X_np = X_flat.detach().cpu().numpy()\n",
    "                X_processed_np = self.preprocess_func(X_np)\n",
    "                \n",
    "                # Get the processed feature dimension\n",
    "                processed_feat_dim = X_processed_np.shape[1] if X_processed_np.ndim > 1 else 1\n",
    "                \n",
    "                # Create tensor and reshape back to original batch dimensions\n",
    "                X_processed = torch.tensor(\n",
    "                    X_processed_np, \n",
    "                    dtype=X.dtype, \n",
    "                    device=X.device\n",
    "                )\n",
    "                \n",
    "                # Reshape back to [batch, q, processed_feat_dim]\n",
    "                X_processed = X_processed.reshape(batch_size, q, processed_feat_dim)\n",
    "                \n",
    "            else:  # Simple 2D input [batch, dim] or 1D input [dim]\n",
    "                # Just process normally\n",
    "                X_np = X.detach().cpu().numpy()\n",
    "                X_processed_np = self.preprocess_func(X_np)\n",
    "                X_processed = torch.tensor(\n",
    "                    X_processed_np, \n",
    "                    dtype=X.dtype, \n",
    "                    device=X.device\n",
    "                )\n",
    "            \n",
    "            # Add dummy computation to preserve gradients\n",
    "            dummy = torch.sum(X) * 0.0\n",
    "            X_processed = X_processed + dummy\n",
    "            \n",
    "            return X_processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in transform: {str(e)}. X shape: {X.shape}. Falling back to original X.\")\n",
    "            print(f\"Input shape was: {original_shape}\")\n",
    "            if original_ndim > 2:\n",
    "                print(f\"First slice: {X[(0,) * (original_ndim-2)]}\")\n",
    "            return X\n",
    "    \n",
    "    def untransform(self, X):\n",
    "        \"\"\"Convert transformed points back to the original space\"\"\"\n",
    "        # If we've added features, return just the original features\n",
    "        return X\n",
    "    \n",
    "    @property\n",
    "    def transform_on_train(self):\n",
    "        return self._transform_on_train\n",
    "        \n",
    "    @property\n",
    "    def transform_on_eval(self):\n",
    "        return self._transform_on_eval\n",
    "        \n",
    "    @property\n",
    "    def transform_on_fantasize(self):\n",
    "        return self._transform_on_fantasize\n",
    "    \n",
    "    # Fix the to() method to handle the case where a tensor is passed\n",
    "    def to(self, *args, **kwargs):\n",
    "        # Check if the first argument is a tensor\n",
    "        if args and isinstance(args[0], torch.Tensor):\n",
    "            # This is the case from model.py:214\n",
    "            # We don't need to do anything here, just return self\n",
    "            return self\n",
    "        \n",
    "        # Otherwise, delegate to the parent class's to method\n",
    "        return super().to(*args, **kwargs)\n",
    "        \n",
    "    # Make the class hashable\n",
    "    def __hash__(self):\n",
    "        return hash(id(self))\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            type(self) is type(other) and\n",
    "            self.transform_on_train == other.transform_on_train and\n",
    "            self.transform_on_eval == other.transform_on_eval and \n",
    "            self.transform_on_fantasize == other.transform_on_fantasize\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78a01e0-52b3-44be-a006-67636eb2b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom optimiser function with increased iterations\n",
    "\n",
    "def custom_optimizer(obj_func, initial_theta, bounds):\n",
    "    # The scipy optimizer returns (theta_opt, func_min, info_dict)\n",
    "    # But scikit-learn only expects (theta_opt, func_min)\n",
    "    opt_result = fmin_l_bfgs_b(obj_func, initial_theta, bounds=bounds, \n",
    "                              maxiter=200, \n",
    "                              factr=1e7,   # Increase tolerance\n",
    "                              pgtol=1e-5)  # Increase gradient tolerance\n",
    "    \n",
    "    # Only return the first two values\n",
    "    return opt_result[0], opt_result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab84fd-c6f6-4158-8a3e-8e1886866c1c",
   "metadata": {},
   "source": [
    "This is the main workhorse: the Bayesian Optimisation class.\n",
    "\n",
    "It is initialised with the input (X) and output (y) data, together with bounds for the input dimensions and the function number, which is solely used for (optional) feature engineering.\n",
    "\n",
    "The _preprocess_X function implements (optional) function-specific feature engineering by calling a transformer if supplied.\n",
    "\n",
    "The init_models function fits a BoTorch model and a scikit-learn GP regression model, selecting the best kernel to use with the latter by a process of cross-validation, using the cross_validate_models function and its helpers.\n",
    "\n",
    "The _acquisition... functions implement standard metrics such as Expected Improvement (EI).\n",
    "\n",
    "The get_next_candidate_... functions implement various methodologies for suggesting the next candidate input to try. The main get_next_candidate function uses those to get all the suggestions and then produces metrics by which to assess them.\n",
    "\n",
    "The plot... functions generate a variety of  visualisations.\n",
    "\n",
    "Other functions deal with historical and ongoing analysis of optimisation techniques and saving/loading of the optimiser state, but are not currently used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c32f50-d231-4b7f-b27d-df427b31b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Bayesian Optimisation class\n",
    "    \n",
    "class BayesianOptimizer:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for black-box functions.\n",
    "    Supports various acquisition functions, feature engineering, and multiple\n",
    "    optimization strategies including botorch, hyperopt, bootstrapping, and CV.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, bounds, feature_transformer=None, random_state=1, load_from=None):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian optimizer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Initial input points, shape (n_samples, n_dim)\n",
    "        y : numpy.ndarray\n",
    "            Function values at the initial points, shape (n_samples,)\n",
    "        bounds : numpy.ndarray\n",
    "            Bounds for each dimension, shape (n_dim, 2)\n",
    "        feature_transformer : FeatureTransformer, optional\n",
    "            Class implementing feature engineering\n",
    "        random_state : int, optional\n",
    "            Random seed for reproducibility\n",
    "        load_from : str, optional\n",
    "            Path to load a saved optimizer state\n",
    "        \"\"\"\n",
    "        print(\"Initialising Bayesian Optimiser\")\n",
    "        \n",
    "        if load_from is not None:\n",
    "            self.load_state(load_from)\n",
    "        else:\n",
    "            self.X = np.array(X)\n",
    "            self.y = np.array(y)\n",
    "            self.bounds = np.array(bounds)\n",
    "            self.n_dim = X.shape[1]\n",
    "            self.random_state = random_state\n",
    "            \n",
    "            # Shift y into the positive, if necessary, to allow log kernels\n",
    "            if(min(self.y)<=-1.0):\n",
    "                shift = abs(min(self.y)) + 1.0\n",
    "                print(f\"Shifting y values by {shift} to facilitate log transformsations\")\n",
    "                self.y = self.y + shift\n",
    "\n",
    "            # Set random seed\n",
    "            np.random.seed(random_state)\n",
    "            torch.manual_seed(random_state)\n",
    "            \n",
    "            # Initialize history\n",
    "            self.history = {\n",
    "                'iterations': [],\n",
    "                'best_value': [],\n",
    "                'candidate_points': [],\n",
    "                'method_used': [],\n",
    "                'predicted_values': [],\n",
    "                'acquisition_values': []\n",
    "            }\n",
    "            \n",
    "            # Initialize device for PyTorch\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            # Initialize hyperopt space\n",
    "            self.hyperopt_space = {f'x{i}': hp.uniform(f'x{i}', self.bounds[i, 0], self.bounds[i, 1]) \n",
    "                                 for i in range(self.n_dim)}\n",
    "            \n",
    "            # Initialize models\n",
    "#            self._init_models()\n",
    "            \n",
    "            # Find initial best observation\n",
    "            self.best_idx = np.argmax(self.y)\n",
    "            self.best_x = self.X[self.best_idx]\n",
    "            self.best_y = self.y[self.best_idx]\n",
    "\n",
    "            colnames = []\n",
    "            for i in range(self.n_dim):\n",
    "                colnames.append('x'+str(i))\n",
    "            colnames.append('y')\n",
    "    \n",
    "            self.df = pd.DataFrame(np.column_stack((self.X, self.y)),columns=colnames)\n",
    "\n",
    "            if feature_transformer is None:\n",
    "                self.use_features = False\n",
    "                self.feature_transformer = IdentityTransformer()\n",
    "            else:\n",
    "                self.use_features = True\n",
    "                self.feature_transformer = feature_transformer\n",
    "\n",
    "            self.verbose = True\n",
    "                \n",
    "    def print_data(self):\n",
    "        pd.options.display.max_rows = 200\n",
    "        pd.options.display.float_format = \"{:,.5f}\".format\n",
    "        print(self.df)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    def _preprocess_X(self, X):\n",
    "        X_orig = X.copy()\n",
    "\n",
    "        if not self.use_features:\n",
    "            return X_orig\n",
    "        \n",
    "        original_shape = X_orig.shape\n",
    "\n",
    "        # Check if we have a 3D tensor with a singleton dimension in the middle\n",
    "        # Shape [batch_size, 1, feature_dim] -> reshape to [batch_size, feature_dim]\n",
    "        if len(X_orig.shape) == 3 and X_orig.shape[1] == 1:\n",
    "            X_orig = X_orig.reshape(X_orig.shape[0], X_orig.shape[2])\n",
    "\n",
    "        # Check dimensions and reshape if needed\n",
    "        was_3d = False\n",
    "        was_4d = False\n",
    "        \n",
    "        if X_orig.ndim == 4:\n",
    "            # For 4D inputs (fantasy_batch, batch, q, dim) -> flatten to 2D\n",
    "            X_orig = X_orig.reshape(-1, X_orig.shape[-1])\n",
    "            was_4d = True\n",
    "        elif X_orig.ndim == 3:\n",
    "            # For 3D inputs (batch, q, dim) -> flatten to 2D\n",
    "            X_orig = X_orig.reshape(-1, X_orig.shape[-1])\n",
    "            was_3d = True\n",
    "\n",
    "        # Apply feature transformation\n",
    "        X_processed = self.feature_transformer.transform(X_orig)\n",
    "        \n",
    "        # Reshape back to original dimensions\n",
    "        if was_4d:\n",
    "            # Calculate new feature dimension\n",
    "            new_feat_dim = X_processed.shape[1]\n",
    "            # Reshape back to (fantasy_batch, batch, q, new_dim)\n",
    "            X_processed = X_processed.reshape(original_shape[0], original_shape[1], \n",
    "                                            original_shape[2], new_feat_dim)\n",
    "        elif was_3d:\n",
    "            # Calculate new feature dimension\n",
    "            new_feat_dim = X_processed.shape[1]\n",
    "            # Reshape back to (batch, q, new_dim)\n",
    "            X_processed = X_processed.reshape(original_shape[0], original_shape[1], new_feat_dim)\n",
    "\n",
    "        return X_processed\n",
    "\n",
    "    def init_models(self):\n",
    "        \"\"\"Initialize Gaussian Process models with various kernels and BoTorch model.\"\"\"\n",
    "        # Define a variety of kernels to try\n",
    "        \n",
    "        # Preprocess features\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        self.n_dim_processed = X_processed.shape[-1]\n",
    "\n",
    "#        self.kernels = {\n",
    "#            \"RBF (default)\": ConstantKernel(1.0) * RBF(length_scale=1.0),\n",
    "#        }\n",
    "\n",
    "        self.kernels = {\n",
    "            \"RBF (default)\": ConstantKernel(1.0) * RBF(length_scale=1.0),\n",
    "            \"RBF (short)\": ConstantKernel(1.0) * RBF(length_scale=0.1),\n",
    "            \"Matern (default)\": ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5),\n",
    "            \"Matern (short)\": ConstantKernel(1.0) * Matern(length_scale=0.1, nu=2.5),\n",
    "            \"Matern (nu=0.5)\": ConstantKernel(1.0) * Matern(length_scale=0.1, nu=0.5),\n",
    "            \"Matern (nu=1.5)\": ConstantKernel(1.0) * Matern(length_scale=0.1, nu=1.5),\n",
    "            \"RationalQuadratic\": ConstantKernel(1.0) * RationalQuadratic(length_scale=0.1, alpha=0.1),\n",
    "            \"RationalQuadratic (alpha=1.0)\": ConstantKernel(1.0) * RationalQuadratic(length_scale=0.1, alpha=1.0),\n",
    "            \"RationalQuadratic (large)\": ConstantKernel(1000.0) * RationalQuadratic(length_scale=0.5, alpha=0.1),\n",
    "            \"Combo\": ConstantKernel(1.0) * (0.5 * Matern(length_scale=0.5, nu=1.5) + 0.5 * RationalQuadratic(length_scale=1.0, alpha=0.1)),\n",
    "            \"Combo (large)\": ConstantKernel(1000.0) * (0.5 * Matern(length_scale=0.5, nu=1.5) + 0.5 * RationalQuadratic(length_scale=1.0, alpha=0.1)),\n",
    "            \"Periodic\": ConstantKernel(1.0) * ExpSineSquared(length_scale=0.1, periodicity=0.5),\n",
    "            \"RBF + Periodic\": ConstantKernel(1.0) * (RBF(length_scale=0.2) + ExpSineSquared(length_scale=0.1, periodicity=0.5)),\n",
    "            \"With Noise\": ConstantKernel(1.0) * RBF(length_scale=0.1) + WhiteKernel(noise_level=0.01),\n",
    "            \"With Linear Trend\": ConstantKernel(1.0) * RBF(length_scale=0.1) + DotProduct(sigma_0=1.0),\n",
    "            \"ARD RBF (default)\": ConstantKernel(1.0) * RBF(length_scale=[1.0] * self.n_dim_processed),\n",
    "            \"ARD RBF (short)\": ConstantKernel(1.0) * RBF(length_scale=[0.1] * self.n_dim_processed),\n",
    "            \"ARD Matern (default)\": ConstantKernel(1.0) * Matern(length_scale=[1.0] * self.n_dim_processed, nu=2.5),\n",
    "            \"ARD Matern (short)\": ConstantKernel(1.0) * Matern(length_scale=[0.1] * self.n_dim_processed, nu=2.5),\n",
    "            \"Simple\": ConstantKernel(1.0) * RBF(length_scale=0.05) + WhiteKernel(noise_level=0.05),\n",
    "            \"Noise\": ConstantKernel(1.0) + WhiteKernel(noise_level=0.05),\n",
    "            \"Noisy RBF\": ConstantKernel(1.0, (1e-3, 1e3)) * RBF(length_scale=[0.1] * self.n_dim_processed, length_scale_bounds=(1e-2, 1e1)) + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-5, 1e0)),\n",
    "            \"Noisy Matern\": ConstantKernel(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.1] * self.n_dim_processed, length_scale_bounds=(1e-2, 1e1), nu=2.5) + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-5, 1e0))\n",
    "        }\n",
    "\n",
    "        '''\n",
    "        # Add deep kernel options\n",
    "        self.deep_kernels = {\n",
    "            \"Deep Kernel (small)\": {\n",
    "                \"hidden_dims\": [32, 16],\n",
    "                \"output_dim\": 5,\n",
    "                \"min_lengthscale\": 0.05\n",
    "            },\n",
    "            \"Deep Kernel (medium)\": {\n",
    "                \"hidden_dims\": [64, 32],\n",
    "                \"output_dim\": 8,\n",
    "                \"min_lengthscale\": 0.05\n",
    "            },\n",
    "            \"Deep Kernel (large)\": {\n",
    "                \"hidden_dims\": [128, 64, 32],\n",
    "                \"output_dim\": 10,\n",
    "                \"min_lengthscale\": 0.05\n",
    "            },\n",
    "            \"Deep Kernel (residual)\": {\n",
    "                \"hidden_dims\": [64, 64],\n",
    "                \"output_dim\": 8,\n",
    "                \"min_lengthscale\": 0.05,\n",
    "                \"residual\": True\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "        '''\n",
    "        # Try much simpler networks\n",
    "        self.deep_kernels = {\n",
    "            \"Deep Kernel (tiny)\": {\n",
    "                \"hidden_dims\": [8],  # Single hidden layer with just 8 neurons\n",
    "                \"output_dim\": 3,     # Very small output dimension\n",
    "                \"min_lengthscale\": 0.1\n",
    "            },\n",
    "            \"Deep Kernel (small)\": {\n",
    "                \"hidden_dims\": [16, 8],\n",
    "                \"output_dim\": 4,\n",
    "                \"min_lengthscale\": 0.1\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "\n",
    "        # Add warped GP configurations\n",
    "        self.warped_configs = {\n",
    "            \"Warped Matern (Kumaraswamy)\": {\n",
    "                \"kernel_type\": \"matern\",\n",
    "                \"nu\": 2.5,\n",
    "                \"ard\": True,\n",
    "                \"warp_type\": \"kumaraswamy\"\n",
    "            },\n",
    "            \"Warped RBF (Kumaraswamy)\": {\n",
    "                \"kernel_type\": \"rbf\",\n",
    "                \"ard\": True,\n",
    "                \"warp_type\": \"kumaraswamy\"\n",
    "            },\n",
    "            \"Warped Matern (Tanh)\": {\n",
    "                \"kernel_type\": \"matern\",\n",
    "                \"nu\": 2.5,\n",
    "                \"ard\": True,\n",
    "                \"warp_type\": \"tanh\"\n",
    "            },\n",
    "            \"Warped RQ (Kumaraswamy)\": {\n",
    "                \"kernel_type\": \"rational_quadratic\",\n",
    "                \"ard\": True,\n",
    "                \"warp_type\": \"kumaraswamy\"\n",
    "            },\n",
    "            \"Warped Matern 1.5 (Kumaraswamy)\": {\n",
    "                \"kernel_type\": \"matern\",\n",
    "                \"nu\": 1.5,\n",
    "                \"ard\": True,\n",
    "                \"warp_type\": \"kumaraswamy\"\n",
    "            }\n",
    "        }\n",
    "            \n",
    "        '''\n",
    "        # Check if we should use log transformation\n",
    "        self.use_log_y = self._check_log_transform()\n",
    "        \n",
    "        # Prepare y data based on log transform decision\n",
    "        if self.use_log_y:\n",
    "            self.y_log = np.log1p(self.y)  # log(1+y) to handle zeros/small values\n",
    "            y_for_cv = self.y_log\n",
    "            print(\"Using log transformation for y values\")\n",
    "        else:\n",
    "            y_for_cv = self.y\n",
    "        '''\n",
    "\n",
    "        # Cross-validate the kernels to compare R^2\n",
    "        print(\"\\nCross-validating standard kernels\")\n",
    "        self.use_log_y = False\n",
    "        cv_results = self.cross_validate_models('standard', n_splits=5)\n",
    "\n",
    "        print(\"\\nCross-validating log kernels\")\n",
    "        self.use_log_y = True\n",
    "        self.y_log = np.log1p(self.y)  # log(1+y) to handle zeros/small values\n",
    "        cvl_results = self.cross_validate_models('standard', n_splits=5)\n",
    "\n",
    "        '''\n",
    "        # Cross-validate deep kernels\n",
    "        print(\"\\nCross-validating deep kernels\")\n",
    "        self.use_log_y = False\n",
    "        cv_deep_results = self.cross_validate_models('deep', n_splits=5)\n",
    "        \n",
    "        # Cross-validate deep kernels with log transform\n",
    "        print(\"\\nCross-validating deep kernels with log transform\")\n",
    "        self.use_log_y = True\n",
    "        cv_deep_log_results = self.cross_validate_models('deep', n_splits=5)\n",
    "        '''\n",
    "        \n",
    "        # Cross-validate warped kernels\n",
    "        print(\"\\nCross-validating warped kernels\")\n",
    "        self.use_log_y = False\n",
    "        cv_warped_results = self.cross_validate_models('warped', n_splits=5)\n",
    "        \n",
    "        # Cross-validate warped kernels with log transform\n",
    "        print(\"\\nCross-validating warped kernels with log transform\")\n",
    "        self.use_log_y = True\n",
    "        cv_warped_log_results = self.cross_validate_models('warped', n_splits=5)\n",
    "        \n",
    "        '''\n",
    "        # Combine standard results and select best model\n",
    "        all_results = {}\n",
    "        all_results.update(cv_results['r2_mean'])\n",
    "        all_results.update({f\"log_{k}\": v for k, v in cvl_results['r2_mean'].items()})\n",
    "\n",
    "        self.best_model_name = max(all_results.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "        # Set appropriate flags based on best model\n",
    "        if self.best_model_name.startswith(\"log_\"):\n",
    "            self.use_log_y = True\n",
    "            self.is_deep_kernel = False\n",
    "            self.best_kernel_name = self.best_model_name[4:]  # Remove \"log_\" prefix\n",
    "            y_for_fit = self.y_log\n",
    "        else:\n",
    "            self.use_log_y = False\n",
    "            self.is_deep_kernel = False\n",
    "            self.best_kernel_name = self.best_model_name\n",
    "            y_for_fit = self.y\n",
    "\n",
    "        print(f\"Selected best model: {self.best_model_name}\")\n",
    "        print(f\"Using standard kernel: {self.best_kernel_name}\")\n",
    "        self.init_standard_kernel_model(self.best_kernel_name, y_for_fit)\n",
    "\n",
    "        all_results = {}\n",
    "        all_results.update({f\"deep_{k}\": v for k, v in cv_deep_results['r2_mean'].items()})\n",
    "        all_results.update({f\"deep_log_{k}\": v for k, v in cv_deep_log_results['r2_mean'].items()})\n",
    "    \n",
    "        self.best_model_name = max(all_results.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "        # Select best model\n",
    "        if self.best_model_name.startswith(\"deep_log_\"):\n",
    "            self.use_log_y = True\n",
    "            self.is_deep_kernel = True\n",
    "            self.best_deep_kernel_name = self.best_model_name[9:]  # Remove \"deep_log_\" prefix\n",
    "            y_for_fit = self.y_log\n",
    "        else:\n",
    "            self.use_log_y = False\n",
    "            self.is_deep_kernel = True\n",
    "            self.best_deep_kernel_name = self.best_model_name[5:]  # Remove \"deep_\" prefix\n",
    "            y_for_fit = self.y\n",
    "        \n",
    "        print(f\"Selected best deep model: {self.best_model_name}\")   \n",
    "        print(f\"Using deep kernel: {self.best_deep_kernel_name}\")\n",
    "        self.init_deep_kernel_model(self.best_deep_kernel_name, y_for_fit)\n",
    "        '''\n",
    "        \n",
    "        # Combine all results and select best model\n",
    "        all_results = {}\n",
    "        all_results.update(cv_results['r2_mean'])\n",
    "        all_results.update({f\"log_{k}\": v for k, v in cvl_results['r2_mean'].items()})\n",
    "        all_results.update({f\"warped_{k}\": v for k, v in cv_warped_results['r2_mean'].items()})\n",
    "        all_results.update({f\"warped_log_{k}\": v for k, v in cv_warped_log_results['r2_mean'].items()})\n",
    "        \n",
    "        # Select best model\n",
    "        self.best_model_name = max(all_results.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Set appropriate flags based on best model\n",
    "        if self.best_model_name.startswith(\"log_\"):\n",
    "            self.use_log_y = True\n",
    "            self.is_warped = False\n",
    "            self.best_kernel_name = self.best_model_name[4:]  # Remove \"log_\" prefix\n",
    "            y_for_fit = self.y_log\n",
    "        elif self.best_model_name.startswith(\"warped_log_\"):\n",
    "            self.use_log_y = True\n",
    "            self.is_warped = True\n",
    "            self.best_warped_name = self.best_model_name[11:]  # Remove \"warped_log_\" prefix\n",
    "            y_for_fit = self.y_log\n",
    "        elif self.best_model_name.startswith(\"warped_\"):\n",
    "            self.use_log_y = False\n",
    "            self.is_warped = True\n",
    "            self.best_warped_name = self.best_model_name[7:]  # Remove \"warped_\" prefix\n",
    "            y_for_fit = self.y\n",
    "        else:\n",
    "            self.use_log_y = False\n",
    "            self.is_warped = False\n",
    "            self.best_kernel_name = self.best_model_name\n",
    "            y_for_fit = self.y\n",
    "        \n",
    "        print(f\"Selected best model: {self.best_model_name}\")\n",
    "\n",
    "        # Initialize appropriate model based on selection\n",
    "        if self.is_warped:\n",
    "            print(f\"Using warped kernel: {self.best_warped_name}\"+(\" (with logs)\" if self.use_log_y else \"\"))\n",
    "            self.init_warped_gp_model(self.best_warped_name, y_for_fit)\n",
    "        else:\n",
    "            print(f\"Using standard kernel: {self.best_kernel_name}\"+(\" (with logs)\" if self.use_log_y else \"\"))\n",
    "            self.init_standard_kernel_model(self.best_kernel_name, y_for_fit)\n",
    "        \n",
    "        # Initialize BoTorch model\n",
    "        self.X_torch = torch.tensor(self.X, dtype=torch.float64, device=self.device)\n",
    "        self.y_torch = torch.tensor(self.y.reshape(-1, 1), dtype=torch.float64, device=self.device)\n",
    "\n",
    "        # If train_Y is 1D, fix it:\n",
    "        if self.y_torch.dim() == 1:\n",
    "            self.y_torch = self.y_torch.unsqueeze(-1)\n",
    "            print(f\"Fixed train_Y shape: {self.y_torch.shape}\")\n",
    "\n",
    "        \n",
    "        self.botorch_gp = SingleTaskGP(self.X_torch, self.y_torch)\n",
    "\n",
    "        self.mll = ExactMarginalLogLikelihood(self.botorch_gp.likelihood, self.botorch_gp)\n",
    "        logger = OptimizationLogger()\n",
    "        fit_gpytorch_mll(self.mll, optimizer_kwargs={'callback':logger})\n",
    "#        print(logger.history)\n",
    "        \n",
    "    def _check_log_transform(self):\n",
    "        \"\"\"\n",
    "        Check if log transformation should be applied to y values.\n",
    "        Returns True if log transformation improves model fit.\n",
    "        \"\"\"\n",
    "        # If y range spans multiple orders of magnitude, try log transform\n",
    "        y_range = self.y.max() - self.y.min()\n",
    "        y_min = self.y.min()\n",
    "        y_max = self.y.max()\n",
    "        \n",
    "        # Check if there are negative values (can't use log)\n",
    "        if y_min < 0:\n",
    "            return False\n",
    "        \n",
    "        # If range is larger than 2 orders of magnitude, or values are very large\n",
    "        if y_max / max(y_min, 1e-10) > 100 or y_max > 1000:\n",
    "            # Transform y\n",
    "            y_log = np.log1p(self.y)\n",
    "            \n",
    "            # Preprocess features\n",
    "            X_processed = self._preprocess_X(self.X)\n",
    "            \n",
    "            # Simple 2-fold cross-validation to test which is better\n",
    "            kf = KFold(n_splits=2, shuffle=True, random_state=self.random_state)\n",
    "            \n",
    "            # Use simple kernel for testing\n",
    "            kernel = ConstantKernel(1.0) * Matern(length_scale=np.ones(self.n_dim), nu=2.5)\n",
    "            \n",
    "            r2_original = []\n",
    "            r2_log = []\n",
    "            \n",
    "            for train_idx, test_idx in kf.split(X_processed):\n",
    "                X_train, X_test = X_processed[train_idx], X_processed[test_idx]\n",
    "                y_train, y_test = self.y[train_idx], self.y[test_idx]\n",
    "                y_log_train, y_log_test = y_log[train_idx], y_log[test_idx]\n",
    "                \n",
    "                # Fit model on original data\n",
    "                gp_orig = GaussianProcessRegressor(kernel=clone(kernel), normalize_y=True, random_state=self.random_state, optimizer=custom_optimizer)\n",
    "                gp_orig.fit(X_train, y_train)\n",
    "                y_pred_orig = gp_orig.predict(X_test)\n",
    "                r2_orig = 1 - np.sum((y_test - y_pred_orig)**2) / np.sum((y_test - y_train.mean())**2)\n",
    "                r2_original.append(r2_orig)\n",
    "                \n",
    "                # Fit model on log data\n",
    "                gp_log = GaussianProcessRegressor(kernel=clone(kernel), normalize_y=True, random_state=self.random_state, optimizer=custom_optimizer)\n",
    "                gp_log.fit(X_train, y_log_train)\n",
    "                y_pred_log = gp_log.predict(X_test)\n",
    "                y_pred_orig_from_log = np.expm1(y_pred_log)\n",
    "                r2_log_transform = 1 - np.sum((y_test - y_pred_orig_from_log)**2) / np.sum((y_test - y_train.mean())**2)\n",
    "                r2_log.append(r2_log_transform)\n",
    "            \n",
    "            # Compare average R scores\n",
    "            mean_r2_orig = np.mean(r2_original)\n",
    "            mean_r2_log = np.mean(r2_log)\n",
    "            \n",
    "            print(f\"R original: {mean_r2_orig:.4f}, R log-transformed: {mean_r2_log:.4f}\")\n",
    "            \n",
    "            # Return True if log transform improves R\n",
    "            return mean_r2_log > mean_r2_orig\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    def _update_models(self):\n",
    "        \"\"\"Update all GP models with the current data.\"\"\"\n",
    "        # Preprocess data\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        \n",
    "        # Prepare y data based on log transform decision\n",
    "        if self.use_log_y:\n",
    "            self.y_log = np.log1p(self.y)\n",
    "            y_for_fitting = self.y_log\n",
    "        else:\n",
    "            y_for_fitting = self.y\n",
    "        \n",
    "        # Update best GP model\n",
    "        self.gp_best.fit(X_processed, y_for_fitting)\n",
    "                \n",
    "        # Update BoTorch model\n",
    "        self.X_torch = torch.tensor(X_processed, dtype=torch.float64, device=self.device)\n",
    "        self.y_torch = torch.tensor(y_for_fitting.reshape(-1, 1), dtype=torch.float64, device=self.device)\n",
    "        \n",
    "        # Create the input transform - only once!\n",
    "        input_transform = CustomInputTransform(self._preprocess_X)\n",
    "        \n",
    "        # Store the original input dimension\n",
    "        input_transform.input_dim = self.n_dim\n",
    "        \n",
    "        self.botorch_gp = SingleTaskGP(self.X_torch, self.y_torch, input_transform=input_transform)\n",
    "        self.mll = ExactMarginalLogLikelihood(self.botorch_gp.likelihood, self.botorch_gp)\n",
    "        fit_gpytorch_mll(self.mll)\n",
    "\n",
    "        # Update best observation\n",
    "        self.best_idx = np.argmax(self.y)\n",
    "        self.best_x = self.X[self.best_idx]\n",
    "        self.best_y = self.y[self.best_idx]\n",
    "        \n",
    "    def update(self, x_next, y_next, method_used=None):\n",
    "        \"\"\"\n",
    "        Update the model with a new observation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x_next : numpy.ndarray\n",
    "            The input point that was evaluated, shape (n_dim,)\n",
    "        y_next : float\n",
    "            The observed function value at x_next\n",
    "        method_used : str, optional\n",
    "            The method used to generate x_next\n",
    "        \"\"\"\n",
    "        # Add the new observation to the dataset\n",
    "        self.X = np.vstack([self.X, x_next.reshape(1, -1)])\n",
    "        self.y = np.append(self.y, y_next)\n",
    "        \n",
    "        # Update models\n",
    "        self._update_models()\n",
    "        \n",
    "        # Get the method used - either provided or from last call to get_next_candidate\n",
    "        if method_used is None:\n",
    "            if hasattr(self, '_last_method_used'):\n",
    "                method_used = self._last_method_used\n",
    "            else:\n",
    "                method_used = \"unknown\"\n",
    "        \n",
    "        # Update history\n",
    "        self.history['iterations'].append(len(self.y))\n",
    "        self.history['best_value'].append(self.best_y)\n",
    "        self.history['candidate_points'].append(x_next)\n",
    "        self.history['method_used'].append(method_used)\n",
    "        \n",
    "        # Get predictions for the new point\n",
    "        X_processed = self._preprocess_X(x_next.reshape(1, -1))\n",
    "        \n",
    "        # Use best GP for prediction\n",
    "        mu, sigma = self.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # If using log transform, convert prediction back to original scale\n",
    "        if self.use_log_y:\n",
    "            mu_orig = np.expm1(mu)\n",
    "            self.history['predicted_values'].append(mu_orig[0])\n",
    "        else:\n",
    "            self.history['predicted_values'].append(mu[0])\n",
    "        \n",
    "        # Calculate acquisition value (using EI)\n",
    "        acq_value = self._acquisition_ei(x_next.reshape(1, -1))[0]\n",
    "        self.history['acquisition_values'].append(acq_value)\n",
    "    \n",
    "    # ==================== Acquisition Functions ====================\n",
    "    \n",
    "    def _acquisition_ei(self, X):\n",
    "        \"\"\"\n",
    "        Expected Improvement acquisition function with log transform support.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Points at which to evaluate the acquisition function\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        ei : numpy.ndarray\n",
    "            Expected improvement at each point\n",
    "        \"\"\"\n",
    "        # Preprocess input\n",
    "        X_processed = self._preprocess_X(X)\n",
    "        \n",
    "        X_processed = X_processed.reshape(1, -1) if X_processed.ndim == 1 else X_processed\n",
    "        \n",
    "        # Get predictions from best GP model\n",
    "        mu, sigma = self.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # Handle case where sigma is very small\n",
    "        sigma = np.maximum(sigma, 1e-10)\n",
    "        \n",
    "        # Convert predictions if using log transform\n",
    "        if self.use_log_y:\n",
    "            # Convert mu from log space to original space\n",
    "            mu_orig = np.expm1(mu)\n",
    "            \n",
    "            # Convert sigma to original space (approximately)\n",
    "            # Using delta method for variance of transformed random variables\n",
    "            sigma_orig = mu_orig * sigma\n",
    "            \n",
    "            # Calculate improvement in original space\n",
    "            best_y_orig = float(self.best_y)\n",
    "            imp = mu_orig - best_y_orig\n",
    "            \n",
    "            # Calculate Z-score\n",
    "            Z = imp / np.maximum(sigma_orig, 1e-10)\n",
    "        else:\n",
    "            # Standard EI calculation\n",
    "            best_y = float(self.best_y)\n",
    "            imp = mu - best_y\n",
    "            Z = imp / sigma\n",
    "        \n",
    "        # Calculate expected improvement\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        \n",
    "        return ei\n",
    "    \n",
    "    def _acquisition_log_ei(self, X):\n",
    "        \"\"\"\n",
    "        Log Expected Improvement acquisition function with log transform support.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Points at which to evaluate the acquisition function\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        log_ei : numpy.ndarray\n",
    "            Log expected improvement at each point\n",
    "        \"\"\"\n",
    "        # Get regular EI values\n",
    "        ei_values = self._acquisition_ei(X)\n",
    "        \n",
    "        # Apply log transformation (with safety for small values)\n",
    "        log_ei = np.log(np.maximum(ei_values, 1e-10))\n",
    "        \n",
    "        return log_ei\n",
    "    \n",
    "    def _acquisition_ucb(self, X, beta=2.0):\n",
    "        \"\"\"\n",
    "        Upper Confidence Bound acquisition function with log transform support.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Points at which to evaluate the acquisition function\n",
    "        beta : float\n",
    "            Exploration-exploitation trade-off parameter\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        ucb : numpy.ndarray\n",
    "            UCB values at each point\n",
    "        \"\"\"\n",
    "        # Preprocess input\n",
    "        X_processed = self._preprocess_X(X)\n",
    "        \n",
    "        X_processed = X_processed.reshape(1, -1) if X_processed.ndim == 1 else X_processed\n",
    "        \n",
    "        # Get predictions from best GP model\n",
    "        mu, sigma = self.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # Convert predictions if using log transform\n",
    "        if self.use_log_y:\n",
    "            # Convert mu from log space to original space\n",
    "            mu_orig = np.expm1(mu)\n",
    "            \n",
    "            # Convert sigma to original space (approximately)\n",
    "            sigma_orig = mu_orig * sigma\n",
    "            \n",
    "            # Calculate UCB in original space\n",
    "            ucb = mu_orig + beta * sigma_orig\n",
    "        else:\n",
    "            # Standard UCB calculation\n",
    "            ucb = mu + beta * sigma\n",
    "        \n",
    "        return ucb\n",
    "    \n",
    "    def _acquisition_pi(self, X, xi=0.01):\n",
    "        \"\"\"\n",
    "        Probability of Improvement acquisition function with log transform support.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Points at which to evaluate the acquisition function\n",
    "        xi : float\n",
    "            Exploration parameter\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pi : numpy.ndarray\n",
    "            PI values at each point\n",
    "        \"\"\"\n",
    "        # Preprocess input\n",
    "        X_processed = self._preprocess_X(X)\n",
    "        \n",
    "        X_processed = X_processed.reshape(1, -1) if X_processed.ndim == 1 else X_processed\n",
    "        \n",
    "        # Get predictions from best GP model\n",
    "        mu, sigma = self.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # Handle case where sigma is very small\n",
    "        sigma = np.maximum(sigma, 1e-10)\n",
    "        \n",
    "        # Calculate probability of improvement based on log transform setting\n",
    "        if self.use_log_y:\n",
    "            # For log transform, we need to compare in log space\n",
    "            best_y_log = np.log1p(float(self.best_y))\n",
    "            \n",
    "            # Here we're directly using mu (log space) and sigma from the GP\n",
    "            Z = (mu - best_y_log - xi) / sigma\n",
    "        else:\n",
    "            # Standard PI calculation\n",
    "            best_y = float(self.best_y)\n",
    "            Z = (mu - best_y - xi) / sigma\n",
    "        \n",
    "        # Calculate probability\n",
    "        pi = norm.cdf(Z)\n",
    "        \n",
    "        return pi\n",
    "    \n",
    "    # ==================== BoTorch Integration ====================\n",
    "    \n",
    "    def get_next_candidate_botorch_advanced(self, acq_function_type=\"ei\", beta=2.0, num_fantasies=128, num_mc_samples=512):\n",
    "        \"\"\"\n",
    "        Get next candidate using BoTorch with native input transformations (feature engineering)\n",
    "        and log transformation support.\n",
    "        \"\"\"\n",
    "            \n",
    "        # Choose a consistent data type for the entire process\n",
    "        dtype = torch.float64  # or torch.float32 if memory is a concern\n",
    "\n",
    "        # Convert data to torch tensors\n",
    "        X_torch = torch.tensor(self.X, dtype=dtype, device=self.device)\n",
    "        y_torch = torch.tensor(self.y.reshape(-1, 1), dtype=dtype, device=self.device)\n",
    "\n",
    "        # Create the input transform - only once!\n",
    "        input_transform = CustomInputTransform(self._preprocess_X)\n",
    "        \n",
    "        # Store the original input dimension\n",
    "        input_transform.input_dim = self.n_dim\n",
    "        \n",
    "        # Debug the shapes before the model is created\n",
    "        X_transformed = input_transform.transform(X_torch)\n",
    "    \n",
    "        # Create the appropriate model based on acquisition function type\n",
    "        if acq_function_type.startswith(\"deep_kernel_\"):\n",
    "            # Parse configuration from acq_function_type\n",
    "            parts = acq_function_type.split('_')\n",
    "            base_acq = parts[2] if len(parts) > 2 else \"ei\"  # Default to EI\n",
    "            \n",
    "            # Set default values\n",
    "            hidden_dims = [64, 32]\n",
    "            output_dim = self.n_dim * 2  # Default to 2x input dimensions\n",
    "            \n",
    "            # Parse hidden dimensions if provided\n",
    "            if len(parts) > 3 and parts[3]:\n",
    "                try:\n",
    "                    hidden_dims = [int(dim) for dim in parts[3].split('-')]\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            # Parse output dimension if provided\n",
    "            if len(parts) > 4 and parts[4]:\n",
    "                try:\n",
    "                    output_dim = int(parts[4])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            model = self.deep_kernel_model\n",
    "\n",
    "            '''\n",
    "            # Create the deep kernel GP model\n",
    "            model = DeepKernelGP(\n",
    "                train_X=X_torch,\n",
    "                train_Y=y_torch,\n",
    "                input_dim=self.n_dim,\n",
    "                hidden_dims=hidden_dims,\n",
    "                output_dim=output_dim\n",
    "            )\n",
    "            \n",
    "            # Train the model with our custom training function\n",
    "            model = fit_deep_kernel_model(model, training_iterations=1000) # was 500\n",
    "            '''\n",
    "            \n",
    "            # Set the acquisition function type for later use\n",
    "            actual_acq_type = base_acq\n",
    "        elif acq_function_type in [\"ei_fe\", \"log_ei_fe\", \"ucb_fe\", \"pi_fe\"]:\n",
    "            model = SingleTaskGP(X_torch, y_torch, input_transform=input_transform)\n",
    "            actual_acq_type = acq_function_type\n",
    "        else:\n",
    "            model = SingleTaskGP(X_torch, y_torch)\n",
    "            actual_acq_type = acq_function_type\n",
    "\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_mll(mll)\n",
    "                \n",
    "        # Get bounds for original dimensions (unchanged)\n",
    "        bounds = torch.tensor([\n",
    "            [self.bounds[i, 0] for i in range(self.n_dim)],\n",
    "            [self.bounds[i, 1] for i in range(self.n_dim)]\n",
    "        ], dtype=torch.float64, device=self.device)\n",
    "        \n",
    "        best_f = y_torch.max().item()\n",
    "        \n",
    "        # Standard acquisition functions\n",
    "        if actual_acq_type in [\"ei\",\"ei_fe\"]:\n",
    "            acq_func = ExpectedImprovement(model, best_f=best_f)\n",
    "        elif actual_acq_type in [\"log_ei\",\"log_ei_fe\"]:\n",
    "            acq_func = LogExpectedImprovement(model, best_f=best_f)\n",
    "        elif actual_acq_type in [\"ucb\",\"ucb_fe\"]:\n",
    "            acq_func = UpperConfidenceBound(model, beta=beta)\n",
    "        elif actual_acq_type in [\"pi\",\"pi_fe\"]:\n",
    "            acq_func = ProbabilityOfImprovement(model, best_f=best_f)\n",
    "        # Monte Carlo Expected Improvement\n",
    "        elif actual_acq_type == \"mc_ei\":\n",
    "            sampler = SobolQMCNormalSampler(sample_shape=torch.Size([num_mc_samples]), seed=1) # collapse_batch_dims=True in dev botorch\n",
    "            acq_func = qExpectedImprovement(model=model, best_f=best_f, sampler=sampler)\n",
    "        # Noisy Expected Improvement\n",
    "        elif actual_acq_type == \"noisy_ei\":\n",
    "            X_train = torch.tensor(self.X, dtype=torch.float64, device=self.device)\n",
    "            sampler = SobolQMCNormalSampler(sample_shape=torch.Size([num_mc_samples]), seed=1) #, collapse_batch_dims=True)\n",
    "            acq_func = qLogNoisyExpectedImprovement(model=model, X_baseline=X_train, sampler=sampler) #, objective=objective)\n",
    "        # Knowledge Gradient\n",
    "        elif actual_acq_type == \"kg\":\n",
    "            # Use custom initialization samples for the fantasy model\n",
    "            # This helps avoid the sampling error\n",
    "            fantasy_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([num_fantasies]), seed=1) #, collapse_batch_dims=True)\n",
    "            acq_func = qKnowledgeGradient(model=model, num_fantasies=num_fantasies, sampler=fantasy_sampler)#, objective=objective)\n",
    "        # Max-value Entropy Search\n",
    "        elif actual_acq_type == \"mes\":\n",
    "            X_train = torch.tensor(self.X, dtype=torch.float64, device=self.device)\n",
    "            # Use a different candidate set approach\n",
    "            # Instead of using all training points, sample a subset\n",
    "            if len(X_train) > 10:  # If we have many training points\n",
    "                # Sample a smaller candidate set\n",
    "                indices = torch.randperm(len(X_train))[:10]\n",
    "                candidate_set = X_train[indices]\n",
    "            else:\n",
    "                candidate_set = X_train\n",
    "            acq_func = qMaxValueEntropy(model=model, candidate_set=candidate_set)  # Reduce number of samples\n",
    "        # Thompson Sampling\n",
    "        elif actual_acq_type == \"thompson\":\n",
    "            return self._thompson_sampling_with_preprocessing(model)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown acquisition function type: {actual_acq_type}\")\n",
    "\n",
    "        # Try to use BoTorch's optimization\n",
    "        try:\n",
    "            if actual_acq_type == \"kg\":\n",
    "                candidate, _ = optimize_acqf(\n",
    "                    acq_function=acq_func,\n",
    "                    bounds=bounds,\n",
    "                    q=1,#num_fantasies+1,\n",
    "                    num_restarts=20, # was 10\n",
    "                    raw_samples=1024, # was 512\n",
    "                    options={\"batch_limit\": 1, \"maxiter\": 1000, \"allow_unused\": True}\n",
    "                )\n",
    "                best_idx = 0  # or select based on some criterion\n",
    "                return candidate[best_idx].detach().cpu().numpy().flatten()\n",
    "            else:\n",
    "                candidate, _ = optimize_acqf(\n",
    "                    acq_function=acq_func,\n",
    "                    bounds=bounds,\n",
    "                    q=1,\n",
    "                    num_restarts=100, # was 10\n",
    "                    raw_samples=1000, # was 512\n",
    "                    options={\"batch_limit\": 1, \"maxiter\": 10000, \"allow_unused\": True} # , \"sample_around_best\": True}\n",
    "                )\n",
    "                return candidate.detach().cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"BoTorch optimization failed with error: {e}\")\n",
    "            print(\"Falling back to sampling-based optimization...\")\n",
    "            return self._get_next_via_sampling_with_model(model, actual_acq_type)\n",
    "\n",
    "    def _thompson_sampling_with_preprocessing(self, model):\n",
    "        \"\"\"Thompson sampling with preprocessing model and log transform support.\"\"\"\n",
    "        # Generate random candidates\n",
    "        n_samples = 10000 # was 1000\n",
    "        X_samples = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_samples, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Convert to tensor\n",
    "        X_samples_torch = torch.tensor(X_samples, dtype=torch.float64, device=self.device)\n",
    "        \n",
    "        # Sample from posterior\n",
    "        with torch.no_grad():\n",
    "            posterior = model.posterior(X_samples_torch)\n",
    "            samples = posterior.rsample().cpu().numpy().flatten()\n",
    "        \n",
    "        # If using log transform, convert samples back to original scale\n",
    "        if self.use_log_y:\n",
    "            samples = np.expm1(samples)\n",
    "        \n",
    "        # Return point with highest sampled value\n",
    "        best_idx = np.argmax(samples)\n",
    "        return X_samples[best_idx]\n",
    "\n",
    "    def _get_next_via_sampling_with_model(self, model, acq_function_type):\n",
    "        \"\"\"\n",
    "        Fallback method that uses sampling with the preprocessing model.\n",
    "        Supports log transformation.\n",
    "        \"\"\"\n",
    "        # Generate random candidates\n",
    "        n_samples = 10000\n",
    "        X_samples = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_samples, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Convert to tensor\n",
    "        X_samples_torch = torch.tensor(X_samples, dtype=torch.float64, device=self.device)\n",
    "        \n",
    "        # Get mean and variance from model\n",
    "        with torch.no_grad():\n",
    "            posterior = model.posterior(X_samples_torch)\n",
    "            mean = posterior.mean.cpu().numpy().flatten()\n",
    "            variance = posterior.variance.cpu().numpy().flatten()\n",
    "            std = np.sqrt(variance)\n",
    "        \n",
    "        # Handle log transform if needed\n",
    "        if self.use_log_y:\n",
    "            # Convert mean from log space to original space\n",
    "            mean_orig = np.expm1(mean)\n",
    "            \n",
    "            # Convert std to original space (approximately)\n",
    "            std_orig = mean_orig * std\n",
    "            \n",
    "            # Use transformed values for calculations\n",
    "            mean = mean_orig\n",
    "            std = std_orig\n",
    "            best_f = float(self.best_y)  # Original scale\n",
    "        else:\n",
    "            best_f = float(self.best_y)\n",
    "        \n",
    "        # Different acquisition functions\n",
    "        if acq_function_type == \"ei\":\n",
    "            # Expected Improvement\n",
    "            imp = mean - best_f\n",
    "            Z = imp / np.maximum(std, 1e-10)\n",
    "            ei = imp * norm.cdf(Z) + std * norm.pdf(Z)\n",
    "            scores = ei\n",
    "        elif acq_function_type == \"log_ei\":\n",
    "            # Log Expected Improvement\n",
    "            imp = mean - best_f\n",
    "            Z = imp / np.maximum(std, 1e-10)\n",
    "            ei = imp * norm.cdf(Z) + std * norm.pdf(Z)\n",
    "            scores = np.log(np.maximum(ei, 1e-10))\n",
    "        elif acq_function_type == \"ucb\":\n",
    "            # Upper Confidence Bound\n",
    "            scores = mean + 2.0 * std\n",
    "        elif acq_function_type == \"pi\":\n",
    "            # Probability of Improvement\n",
    "            Z = (mean - best_f) / np.maximum(std, 1e-10)\n",
    "            scores = norm.cdf(Z)\n",
    "        elif acq_function_type in [\"mc_ei\", \"noisy_ei\"]:\n",
    "            # Monte Carlo or Noisy EI (approximated)\n",
    "            imp = mean - best_f\n",
    "            Z = imp / np.maximum(std, 1e-10)\n",
    "            ei = imp * norm.cdf(Z) + std * norm.pdf(Z)\n",
    "            scores = ei\n",
    "        elif acq_function_type in [\"kg\", \"mes\"]:\n",
    "            # Knowledge Gradient or Max Entropy (approximated as UCB with high beta)\n",
    "            scores = mean + 3.0 * std\n",
    "        else:\n",
    "            # Default to UCB\n",
    "            scores = mean + 2.0 * std\n",
    "        \n",
    "        # Return best candidate\n",
    "        best_idx = np.argmax(scores)\n",
    "        return X_samples[best_idx]\n",
    "    \n",
    "    # ==================== Traditional Acquisition Method Implementations ====================\n",
    "    \n",
    "    def get_next_candidate_ei(self, n_restarts=10, n_samples=1000):\n",
    "        \"\"\"Get next candidate using Expected Improvement (EI).\"\"\"\n",
    "        # Generate random candidates\n",
    "        X_samples = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_samples, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Evaluate acquisition function at random points\n",
    "        ei_values = self._acquisition_ei(X_samples)\n",
    "        \n",
    "        # Pick top points as starting points for optimization\n",
    "        top_indices = np.argsort(ei_values.ravel())[-n_restarts:]\n",
    "        X_starts = X_samples[top_indices]\n",
    "        \n",
    "        # Optimize from each starting point\n",
    "        best_x = None\n",
    "        best_ei = -np.inf\n",
    "        \n",
    "        for x_start in X_starts:\n",
    "            # Define objective function (negative EI for minimization)\n",
    "            def objective(x):\n",
    "                x = x.reshape(1, -1)\n",
    "                return -float(self._acquisition_ei(x)[0])\n",
    "            \n",
    "            # Run optimization with bounds\n",
    "            bounds = [(low, high) for low, high in self.bounds]\n",
    "            result = minimize(\n",
    "                objective,\n",
    "                x_start,\n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds\n",
    "            )\n",
    "            \n",
    "            # Check if this is better than previous\n",
    "            if result.success and -result.fun > best_ei:\n",
    "                best_ei = -result.fun\n",
    "                best_x = result.x\n",
    "        \n",
    "        # If optimization failed, return best random sample\n",
    "        if best_x is None:\n",
    "            best_idx = np.argmax(ei_values)\n",
    "            best_x = X_samples[best_idx]\n",
    "        \n",
    "        return best_x\n",
    "    \n",
    "    def get_next_candidate_log_ei(self, n_restarts=10, n_samples=1000):\n",
    "        \"\"\"Get next candidate using Log Expected Improvement (LogEI).\"\"\"\n",
    "        # Generate random candidates\n",
    "        X_samples = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_samples, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Evaluate acquisition function at random points\n",
    "        log_ei_values = self._acquisition_log_ei(X_samples)\n",
    "        \n",
    "        # Pick top points as starting points for optimization\n",
    "        top_indices = np.argsort(log_ei_values.ravel())[-n_restarts:]\n",
    "        X_starts = X_samples[top_indices]\n",
    "        \n",
    "        # Optimize from each starting point\n",
    "        best_x = None\n",
    "        best_log_ei = -np.inf\n",
    "        \n",
    "        for x_start in X_starts:\n",
    "            # Define objective function (negative LogEI for minimization)\n",
    "            def objective(x):\n",
    "                x = x.reshape(1, -1)\n",
    "                return -float(self._acquisition_log_ei(x)[0])\n",
    "            \n",
    "            # Run optimization with bounds\n",
    "            bounds = [(low, high) for low, high in self.bounds]\n",
    "            result = minimize(\n",
    "                objective,\n",
    "                x_start,\n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds\n",
    "            )\n",
    "            \n",
    "            # Check if this is better than previous\n",
    "            if result.success and -result.fun > best_log_ei:\n",
    "                best_log_ei = -result.fun\n",
    "                best_x = result.x\n",
    "        \n",
    "        # If optimization failed, return best random sample\n",
    "        if best_x is None:\n",
    "            best_idx = np.argmax(log_ei_values)\n",
    "            best_x = X_samples[best_idx]\n",
    "        \n",
    "        return best_x\n",
    "    \n",
    "    def get_next_candidate_ucb(self, beta=2.0, n_restarts=100, n_samples=10000): # was 10, 1000\n",
    "        \"\"\"Get next candidate using Upper Confidence Bound (UCB).\"\"\"\n",
    "        # Generate random candidates\n",
    "        X_samples = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_samples, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Evaluate acquisition function at random points\n",
    "        ucb_values = self._acquisition_ucb(X_samples, beta=beta)\n",
    "        \n",
    "        # Pick top points as starting points for optimization\n",
    "        top_indices = np.argsort(ucb_values.ravel())[-n_restarts:]\n",
    "        X_starts = X_samples[top_indices]\n",
    "        \n",
    "        # Optimize from each starting point\n",
    "        best_x = None\n",
    "        best_ucb = -np.inf\n",
    "        \n",
    "        for x_start in X_starts:\n",
    "            # Define objective function (negative UCB for minimization)\n",
    "            def objective(x):\n",
    "                x = x.reshape(1, -1)\n",
    "                return -float(self._acquisition_ucb(x, beta=beta)[0])\n",
    "            \n",
    "            # Run optimization with bounds\n",
    "            bounds = [(low, high) for low, high in self.bounds]\n",
    "            result = minimize(\n",
    "                objective,\n",
    "                x_start,\n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds\n",
    "            )\n",
    "            \n",
    "            # Check if this is better than previous\n",
    "            if result.success and -result.fun > best_ucb:\n",
    "                best_ucb = -result.fun\n",
    "                best_x = result.x\n",
    "        \n",
    "        # If optimization failed, return best random sample\n",
    "        if best_x is None:\n",
    "            best_idx = np.argmax(ucb_values)\n",
    "            best_x = X_samples[best_idx]\n",
    "        \n",
    "        return best_x\n",
    "    \n",
    "    def get_next_candidate_pi(self, xi=0.01, n_restarts=10, n_samples=1000):\n",
    "        \"\"\"Get next candidate using Probability of Improvement (PI).\"\"\"\n",
    "        # Generate random candidates\n",
    "        X_samples = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_samples, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Evaluate acquisition function at random points\n",
    "        pi_values = self._acquisition_pi(X_samples, xi=xi)\n",
    "        \n",
    "        # Pick top points as starting points for optimization\n",
    "        top_indices = np.argsort(pi_values.ravel())[-n_restarts:]\n",
    "        X_starts = X_samples[top_indices]\n",
    "        \n",
    "        # Optimize from each starting point\n",
    "        best_x = None\n",
    "        best_pi = -np.inf\n",
    "        \n",
    "        for x_start in X_starts:\n",
    "            # Define objective function (negative PI for minimization)\n",
    "            def objective(x):\n",
    "                x = x.reshape(1, -1)\n",
    "                return -float(self._acquisition_pi(x, xi=xi)[0])\n",
    "            \n",
    "            # Run optimization with bounds\n",
    "            bounds = [(low, high) for low, high in self.bounds]\n",
    "            result = minimize(\n",
    "                objective,\n",
    "                x_start,\n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds\n",
    "            )\n",
    "            \n",
    "            # Check if this is better than previous\n",
    "            if result.success and -result.fun > best_pi:\n",
    "                best_pi = -result.fun\n",
    "                best_x = result.x\n",
    "        \n",
    "        # If optimization failed, return best random sample\n",
    "        if best_x is None:\n",
    "            best_idx = np.argmax(pi_values)\n",
    "            best_x = X_samples[best_idx]\n",
    "        \n",
    "        return best_x\n",
    "    \n",
    "    # ==================== Hyperopt Method ====================\n",
    "    \n",
    "    def get_next_candidate_hyperopt(self, max_evals=1000): # was 100\n",
    "        \"\"\"Get next candidate using HyperOpt.\"\"\"\n",
    "        from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "        \n",
    "        # Define objective function for hyperopt\n",
    "        def objective(params):\n",
    "            x = np.array([params[f'x{i}'] for i in range(self.n_dim)])\n",
    "            x = x.reshape(1, -1)\n",
    "            \n",
    "            # Apply feature engineering for prediction\n",
    "            x_processed = self._preprocess_X(x)\n",
    "            \n",
    "            # Get predictions from GP\n",
    "            mu, sigma = self.gp_best.predict(x_processed, return_std=True)\n",
    "            \n",
    "            # Convert predictions if using log transform\n",
    "            if self.use_log_y:\n",
    "                # Convert mu from log space to original space\n",
    "                mu = np.expm1(mu)\n",
    "                \n",
    "                # Convert sigma to original space (approximately)\n",
    "                sigma = mu * sigma\n",
    "            \n",
    "            # Calculate EI\n",
    "            best_y = float(self.best_y)\n",
    "            imp = mu - best_y\n",
    "            Z = imp / np.maximum(sigma, 1e-10)\n",
    "            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "            \n",
    "            # We want to maximize EI, but hyperopt minimizes\n",
    "            return {'loss': -float(ei[0]), 'status': STATUS_OK}\n",
    "        \n",
    "        # Create trials object to store results\n",
    "        trials = Trials()\n",
    "        \n",
    "        # Run optimization with seed (not rstate) to avoid the 'integers' attribute error\n",
    "        best = fmin(\n",
    "            fn=objective,\n",
    "            space=self.hyperopt_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(seed=1),\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Extract best parameters\n",
    "        x_next = np.array([best[f'x{i}'] for i in range(self.n_dim)])\n",
    "        return x_next\n",
    "    \n",
    "    # ==================== Bootstrap Method ====================\n",
    "    \n",
    "    def get_next_candidate_bootstrap(self, n_bootstrap=10): # was 10\n",
    "        \"\"\"\n",
    "        Get next candidate by bootstrapping the data and averaging predictions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_bootstrap : int\n",
    "            Number of bootstrap samples to use\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        x_next : numpy.ndarray\n",
    "            The next candidate point to evaluate\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        n_samples = len(self.X)\n",
    "        \n",
    "        # Get X with applied feature engineering\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        \n",
    "        # Get appropriate y values based on log transform\n",
    "        if self.use_log_y:\n",
    "            y_for_bootstrap = self.y_log\n",
    "        else:\n",
    "            y_for_bootstrap = self.y\n",
    "        \n",
    "        for i in range(n_bootstrap):\n",
    "            # Bootstrap the data\n",
    "            indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_boot = X_processed[indices]\n",
    "            y_boot = y_for_bootstrap[indices]\n",
    "            \n",
    "            # Fit GP on bootstrapped data\n",
    "            gp_boot = GaussianProcessRegressor(\n",
    "                kernel=clone(self.best_kernel),  # Use sklearn.base.clone\n",
    "                alpha=1e-6,\n",
    "                normalize_y=True,\n",
    "                n_restarts_optimizer=100, # was 20\n",
    "                random_state=i,\n",
    "                optimizer=custom_optimizer\n",
    "            )\n",
    "            gp_boot.fit(X_boot, y_boot)\n",
    "            \n",
    "            # Use random search to find candidate\n",
    "            X_random = np.random.uniform(\n",
    "                low=self.bounds[:, 0],\n",
    "                high=self.bounds[:, 1],\n",
    "                size=(1000, self.n_dim)\n",
    "            )\n",
    "            \n",
    "            # Process random points\n",
    "            X_random_processed = self._preprocess_X(X_random)\n",
    "            \n",
    "            # Predict\n",
    "            mu, sigma = gp_boot.predict(X_random_processed, return_std=True)\n",
    "            \n",
    "            # Convert predictions if using log transform\n",
    "            if self.use_log_y:\n",
    "                # Convert mu from log space to original space\n",
    "                mu_orig = np.expm1(mu)\n",
    "                \n",
    "                # Convert sigma to original space (approximately)\n",
    "                sigma_orig = mu_orig * sigma\n",
    "                \n",
    "                # Use UCB in original space\n",
    "                ucb = mu_orig + 2.0 * sigma_orig\n",
    "            else:\n",
    "                # Standard UCB\n",
    "                ucb = mu + 2.0 * sigma\n",
    "            \n",
    "            # Find best candidate for this bootstrap sample\n",
    "            best_idx = np.argmax(ucb)\n",
    "            candidates.append(X_random[best_idx])\n",
    "        \n",
    "        # Average candidates\n",
    "        return np.mean(candidates, axis=0)\n",
    "    \n",
    "    # ==================== Cross-Validation Method ====================\n",
    "    \n",
    "    def get_next_candidate_cv(self, n_splits=5):\n",
    "        \"\"\"\n",
    "        Get next candidate using cross-validation to estimate uncertainty.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_splits : int\n",
    "            Number of cross-validation folds\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        x_next : numpy.ndarray\n",
    "            The next candidate point to evaluate\n",
    "        \"\"\"\n",
    "        # Generate random candidates\n",
    "        n_candidates = 1000\n",
    "        X_candidates = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_candidates, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Process candidates\n",
    "        X_candidates_processed = self._preprocess_X(X_candidates)\n",
    "        \n",
    "        # Process training data\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        \n",
    "        # Get appropriate y values based on log transform\n",
    "        if self.use_log_y:\n",
    "            y_for_cv = self.y_log\n",
    "        else:\n",
    "            y_for_cv = self.y\n",
    "        \n",
    "        # Set up cross-validation\n",
    "        kf = KFold(n_splits=min(n_splits, len(self.X)), shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # Initialize arrays to store predictions and uncertainties\n",
    "        pred_mean = np.zeros(n_candidates)\n",
    "        pred_var = np.zeros(n_candidates)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        for train_idx, _ in kf.split(X_processed):\n",
    "            # Get training data for this fold\n",
    "            X_train = X_processed[train_idx]\n",
    "            y_train = y_for_cv[train_idx]\n",
    "            \n",
    "            # Fit GP on training data\n",
    "            gp = GaussianProcessRegressor(\n",
    "                kernel=clone(self.best_kernel),  # Use sklearn.base.clone\n",
    "                alpha=1e-6,\n",
    "                normalize_y=True,\n",
    "                n_restarts_optimizer=20,\n",
    "                random_state=self.random_state,\n",
    "                optimizer=custom_optimizer\n",
    "            )\n",
    "            gp.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict for all candidates\n",
    "            mu, sigma = gp.predict(X_candidates_processed, return_std=True)\n",
    "            \n",
    "            # Accumulate predictions and variances\n",
    "            pred_mean += mu\n",
    "            pred_var += sigma**2\n",
    "        \n",
    "        # Average predictions and convert variance to std\n",
    "        pred_mean /= kf.get_n_splits()\n",
    "        pred_std = np.sqrt(pred_var / kf.get_n_splits())\n",
    "        \n",
    "        # Convert predictions if using log transform\n",
    "        if self.use_log_y:\n",
    "            # Convert mean from log space to original space\n",
    "            pred_mean_orig = np.expm1(pred_mean)\n",
    "            \n",
    "            # Convert std to original space (approximately)\n",
    "            pred_std_orig = pred_mean_orig * pred_std\n",
    "            \n",
    "            # Calculate EI in original space\n",
    "            best_y_orig = float(self.best_y)\n",
    "            imp = pred_mean_orig - best_y_orig\n",
    "            Z = imp / np.maximum(pred_std_orig, 1e-10)\n",
    "            ei = imp * norm.cdf(Z) + pred_std_orig * norm.pdf(Z)\n",
    "        else:\n",
    "            # Standard EI calculation\n",
    "            best_y = float(self.best_y)\n",
    "            imp = pred_mean - best_y\n",
    "            Z = imp / np.maximum(pred_std, 1e-10)\n",
    "            ei = imp * norm.cdf(Z) + pred_std * norm.pdf(Z)\n",
    "        \n",
    "        # Return candidate with highest score\n",
    "        best_idx = np.argmax(ei)\n",
    "        return X_candidates[best_idx]\n",
    "\n",
    "    # ==================== Warped Method ====================\n",
    "    \n",
    "    def get_next_candidate_warped_gp(self, acq_function_type=\"ei\", beta=2.0):\n",
    "        \"\"\"Get next candidate point using warped GP model.\"\"\"\n",
    "        # Create bounds\n",
    "        bounds = torch.tensor([\n",
    "            [self.bounds[i, 0] for i in range(self.n_dim)],\n",
    "            [self.bounds[i, 1] for i in range(self.n_dim)]\n",
    "        ], dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Get the best observed value\n",
    "        y_for_acq = self.y_log if self.use_log_y else self.y\n",
    "        best_f = torch.tensor(np.max(y_for_acq), dtype=torch.float32)\n",
    "        \n",
    "        # Create acquisition function\n",
    "        if acq_function_type == \"ei\":\n",
    "            acq_func = ExpectedImprovement(model=self.warped_gp_model, best_f=best_f)\n",
    "        elif acq_function_type == \"log_ei\":\n",
    "            acq_func = LogExpectedImprovement(model=self.warped_gp_model, best_f=best_f)\n",
    "        elif acq_function_type == \"ucb\":\n",
    "            acq_func = UpperConfidenceBound(model=self.warped_gp_model, beta=beta)\n",
    "        elif acq_function_type == \"pi\":\n",
    "            acq_func = ProbabilityOfImprovement(model=self.warped_gp_model, best_f=best_f)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported acquisition function: {acq_function_type}\")\n",
    "        \n",
    "        # Try using standard optimizer\n",
    "        try:\n",
    "            # Optimize the acquisition function\n",
    "            candidate, _ = optimize_acqf(\n",
    "                acq_function=acq_func,\n",
    "                bounds=bounds,\n",
    "                q=1,\n",
    "                num_restarts=10,\n",
    "                raw_samples=512,\n",
    "                options={\n",
    "                    \"batch_limit\": 5, \n",
    "                    \"maxiter\": 200\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            next_x = candidate.detach().cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed: {e}\")\n",
    "            print(\"Using fallback sampling approach\")\n",
    "            \n",
    "            # Fallback to sampling-based optimization\n",
    "            num_samples = 10000\n",
    "            X_samples = np.random.uniform(\n",
    "                self.bounds[:, 0], \n",
    "                self.bounds[:, 1], \n",
    "                size=(num_samples, self.n_dim)\n",
    "            )\n",
    "            \n",
    "            # Convert to tensor\n",
    "            X_tensor = torch.tensor(X_samples, dtype=torch.float32, device=self.device)\n",
    "            \n",
    "            # Evaluate acquisition function\n",
    "            with torch.no_grad():\n",
    "                acq_values = acq_func(X_tensor)\n",
    "            \n",
    "            # Find best sample\n",
    "            best_idx = torch.argmax(acq_values)\n",
    "            next_x = X_samples[best_idx]\n",
    "        \n",
    "        # Verify the candidate is within bounds\n",
    "        next_x = np.clip(next_x, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        \n",
    "        return next_x\n",
    "    \n",
    "    # ==================== Main Method Selection ====================\n",
    "\n",
    "    def get_next_candidate(self, method=\"blend\"):\n",
    "        \"\"\"\n",
    "        Get the next candidate point to evaluate.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        method : str\n",
    "            Method to use for selecting the next candidate point.\n",
    "            Options: 'ei', 'log_ei', 'ucb', 'pi', 'botorch_ei', 'botorch_log_ei', \n",
    "                    'botorch_ucb', 'botorch_pi', 'botorch_mc_ei', 'botorch_noisy_ei', \n",
    "                    'botorch_kg', 'botorch_mes', 'botorch_thompson', 'hyperopt', \n",
    "                    'bootstrap', 'cv', 'blend', 'auto'\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        x_next : numpy.ndarray\n",
    "            The next candidate point to evaluate\n",
    "        method : str\n",
    "            The method used to generate the candidate\n",
    "        candidates_df : pandas.DataFrame\n",
    "            Dataframe comparing different candidate selection methods\n",
    "        \"\"\"\n",
    "        # If auto mode, decide based on historical performance\n",
    "        if method == \"auto\" and len(self.history['iterations']) > 2:\n",
    "            recommendation = self.recommend_next_method()\n",
    "            \n",
    "            if recommendation.startswith(\"Exploration:\"):\n",
    "                method = recommendation.split(\":\")[1].strip().split(\" \")[0]\n",
    "            elif recommendation.startswith(\"Exploitation:\"):\n",
    "                method = recommendation.split(\":\")[1].strip().split(\" \")[0]\n",
    "            else:\n",
    "                method = \"blend\"  # Fall back to blend if no clear recommendation\n",
    "\n",
    "        '''\n",
    "        # Ensure models are fitted before making predictions\n",
    "        if not hasattr(self.gp_best, 'X_train_'):\n",
    "            # Preprocess features for fitting\n",
    "            X_processed = self._preprocess_X(self.X)\n",
    "            \n",
    "            # Get appropriate y values based on log transform\n",
    "            if self.use_log_y:\n",
    "                y_for_fitting = self.y_log\n",
    "            else:\n",
    "                y_for_fitting = self.y\n",
    "                \n",
    "            self.gp_best.fit(X_processed, y_for_fitting)\n",
    "        '''\n",
    "        \n",
    "        features_added = True if self.n_dim_processed != self.n_dim else False\n",
    "        \n",
    "        # Dictionary to store candidates from different methods\n",
    "        candidates = {}\n",
    "        \n",
    "        # Get candidate based on specified method\n",
    "        if method == \"ei\":\n",
    "            x_next = self.get_next_candidate_warped_gp(method) if self.is_warped else self.get_next_candidate_ei()\n",
    "            candidates['ei'] = x_next\n",
    "        elif method == \"log_ei\":\n",
    "            x_next = self.get_next_candidate_warped_gp(method) if self.is_warped else self.get_next_candidate_log_ei()\n",
    "            candidates['log_ei'] = x_next\n",
    "        elif method == \"ucb\":\n",
    "            if self.is_warped:\n",
    "                x_next = self.get_next_candidate_warped_gp(method)\n",
    "                candidates['ucb'] = x_next\n",
    "            else:\n",
    "                x_next = self.get_next_candidate_ucb(beta=0.2)\n",
    "                candidates['ucb_0.2'] = x_next\n",
    "                x_next = self.get_next_candidate_ucb(beta=2)\n",
    "                candidates['ucb_2'] = x_next\n",
    "                x_next = self.get_next_candidate_ucb(beta=5)\n",
    "                candidates['ucb_5'] = x_next\n",
    "        elif method == \"pi\":\n",
    "            if self.is_warped:\n",
    "                x_next = self.get_next_candidate_warped_gp(method)\n",
    "                candidates['pi'] = x_next\n",
    "            else:\n",
    "                x_next = self.get_next_candidate_pi(xi=0)\n",
    "                candidates['pi_0'] = x_next\n",
    "                x_next = self.get_next_candidate_pi(xi=0.001)\n",
    "                candidates['pi_0.001'] = x_next\n",
    "                x_next = self.get_next_candidate_pi(xi=0.01)\n",
    "                candidates['pi_0.01'] = x_next\n",
    "                x_next = self.get_next_candidate_pi(xi=0.1)\n",
    "                candidates['pi_0.1'] = x_next\n",
    "        elif method == \"botorch_ei\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"ei\")\n",
    "            candidates['bo_ei'] = x_next\n",
    "            if features_added:\n",
    "                x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"ei_fe\")\n",
    "                candidates['bo_ei_fe'] = x_next            \n",
    "        elif method == \"bo_log_ei\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"log_ei\")\n",
    "            candidates['bo_log_ei'] = x_next\n",
    "            if features_added:\n",
    "                x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"log_ei_fe\")\n",
    "                candidates['bo_ei_fe'] = x_next            \n",
    "        elif method == \"botorch_ucb\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"ucb\")\n",
    "            candidates['bo_ucb'] = x_next\n",
    "            if features_added:\n",
    "                x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"ucb_fe\")\n",
    "                candidates['bo_ei_fe'] = x_next            \n",
    "        elif method == \"botorch_pi\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"pi\")\n",
    "            candidates['bo_pi'] = x_next\n",
    "            if features_added:\n",
    "                x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"pi_fe\")\n",
    "                candidates['bo_ei_fe'] = x_next            \n",
    "        elif method == \"botorch_mc_ei\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"mc_ei\")\n",
    "            candidates['bo_mc_ei'] = x_next\n",
    "        elif method == \"botorch_noisy_ei\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"noisy_ei\")\n",
    "            candidates['bo_noisy_ei'] = x_next\n",
    "        elif method == \"botorch_kg\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"kg\")\n",
    "            candidates['bo_kg'] = x_next\n",
    "        elif method == \"botorch_mes\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"mes\")\n",
    "            candidates['bo_mes'] = x_next\n",
    "        elif method == \"botorch_thompson\":\n",
    "            x_next = self.get_next_candidate_botorch_advanced(acq_function_type=\"thompson\")\n",
    "            candidates['bo_thompson'] = x_next\n",
    "        elif method == \"hyperopt\":\n",
    "            x_next = self.get_next_candidate_hyperopt()\n",
    "            candidates['hyperopt'] = x_next\n",
    "        elif method == \"bootstrap\":\n",
    "            x_next = self.get_next_candidate_bootstrap()\n",
    "            candidates['bootstrap'] = x_next\n",
    "        elif method == \"cv\":\n",
    "            x_next = self.get_next_candidate_cv()\n",
    "            candidates['cv'] = x_next\n",
    "        elif method == \"blend\":\n",
    "            # Get candidates from all methods\n",
    "            print(\"Initialising blend of acquisition functions:\")\n",
    "            candidates['bo_mes'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"mes\")\n",
    "            pbar = tqdm(total=20) # update to 24 if using deep as well\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['ei'] = self.get_next_candidate_ei()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['log_ei'] = self.get_next_candidate_log_ei()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                if self.is_warped:\n",
    "                    candidates['ucb_0.2'] = self.get_next_candidate_warped_gp(acq_function_type=='ucb',beta=0.2)\n",
    "                    candidates['ucb_2'] = self.get_next_candidate_warped_gp(acq_function_type=='ucb',beta=2)\n",
    "                    candidates['ucb_5'] = self.get_next_candidate_warped_gp(acq_function_type=='ucb',beta=5)\n",
    "                else:\n",
    "                    candidates['ucb_0.2'] = self.get_next_candidate_ucb(beta=0.2)\n",
    "                    candidates['ucb_2'] = self.get_next_candidate_ucb(beta=2)\n",
    "                    candidates['ucb_5'] = self.get_next_candidate_ucb(beta=5)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                if self.is_warped:\n",
    "                    candidates['pi'] = self.get_next_candidate_warped_gp(acq_function_type=='pi')\n",
    "                else:\n",
    "                    candidates['pi_0'] = self.get_next_candidate_pi(xi=0)\n",
    "                    candidates['pi_0.001'] = self.get_next_candidate_pi(xi=0.001)\n",
    "                    candidates['pi_0.01'] = self.get_next_candidate_pi(xi=0.01)\n",
    "                    candidates['pi_0.1'] = self.get_next_candidate_pi(xi=0.1)\n",
    "            except:\n",
    "                pass\n",
    "            '''\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['dk_ei'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"deep_kernel_ei\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['dk_log_ei'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"deep_kernel_log_ei\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['dk_ucb'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"deep_kernel_ucb\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['dk_pi'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"deep_kernel_pi\")\n",
    "            except:\n",
    "                pass\n",
    "            '''\n",
    "            try:\n",
    "                pbar.update(2)\n",
    "                candidates['bo_ei'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"ei\")\n",
    "                candidates['bo_ei_fe'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"ei_fe\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(2)\n",
    "                candidates['bo_log_ei'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"log_ei\")\n",
    "                candidates['bo_log_ei_fe'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"log_ei_fe\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(2)\n",
    "                candidates['bo_ucb'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"ucb\")\n",
    "                candidates['bo_ucb_fe'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"ucb_fe\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(2)\n",
    "                candidates['bo_pi'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"pi\")\n",
    "                candidates['bo_pi_fe'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"pi_fe\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['bo_mc_ei'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"mc_ei\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['bo_noisy_ei'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"noisy_ei\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['bo_kg'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"kg\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['bo_mes'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"mes\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['bo_thompson'] = self.get_next_candidate_botorch_advanced(acq_function_type=\"thompson\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['hyperopt'] = self.get_next_candidate_hyperopt()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['bootstrap'] = self.get_next_candidate_bootstrap()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                pbar.update(1)\n",
    "                candidates['cv'] = self.get_next_candidate_cv()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            # If no candidates were generated successfully, fall back to EI\n",
    "            if not candidates:\n",
    "                print(\"All methods failed, falling back to EI with random sampling\")\n",
    "                # Generate random candidates\n",
    "                X_samples = np.random.uniform(\n",
    "                    low=self.bounds[:, 0],\n",
    "                    high=self.bounds[:, 1],\n",
    "                    size=(1000, self.n_dim)\n",
    "                )\n",
    "                \n",
    "                # Process for prediction\n",
    "                X_processed = self._preprocess_X(X_samples)\n",
    "                \n",
    "                # Predict with appropriate model\n",
    "                mu, sigma = self.gp_best.predict(X_processed, return_std=True)\n",
    "                \n",
    "                # Convert predictions if using log transform\n",
    "                if self.use_log_y:\n",
    "                    # Convert mu from log space to original space\n",
    "                    mu_orig = np.expm1(mu)\n",
    "                    \n",
    "                    # Convert sigma to original space (approximately)\n",
    "                    sigma_orig = mu_orig * sigma\n",
    "                    \n",
    "                    # Calculate EI in original space\n",
    "                    best_y_orig = float(self.best_y)\n",
    "                    imp = mu_orig - best_y_orig\n",
    "                    Z = imp / np.maximum(sigma_orig, 1e-10)\n",
    "                    ei = imp * norm.cdf(Z) + sigma_orig * norm.pdf(Z)\n",
    "                else:\n",
    "                    # Standard EI calculation\n",
    "                    best_y = float(self.best_y)\n",
    "                    imp = mu - best_y\n",
    "                    Z = imp / np.maximum(sigma, 1e-10)\n",
    "                    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "                \n",
    "                # Get best candidate\n",
    "                best_idx = np.argmax(ei)\n",
    "                x_next = X_samples[best_idx]\n",
    "                method = \"fallback_ei\"\n",
    "            else:\n",
    "                # Evaluate each candidate\n",
    "                methods = []\n",
    "                means = []\n",
    "                stds = []\n",
    "                eis = []\n",
    "                cands = []\n",
    "\n",
    "                print(\"Methods and candidate points:\")\n",
    "                for method_name, candidate in candidates.items():\n",
    "                    print('{0: >20}'.format(method_name),\":\", \"-\".join(f'{x:.6f}' for x in candidate))\n",
    "\n",
    "                    if method_name in ['botorch_ei', 'botorch_ei_fe', 'botorch_log_ei', 'botorch_log_ei_fe', 'botorch_ucb', 'botorch_ucb_fe', 'botorch_pi', 'botorch_pi_fe', 'botorch_mc_ei', 'botorch_noisy_ei', 'botorch_kg', 'botorch_mes', 'botorch_thompson', 'botorch_vbo']:\n",
    "                        # Make predictions\n",
    "                        with torch.no_grad():\n",
    "                            if isinstance(candidate, np.ndarray):\n",
    "                                x = torch.tensor(candidate, dtype=torch.float32, device=self.device)\n",
    "                            \n",
    "                            # Add batch dimension if needed\n",
    "                            if x.dim() == 1:\n",
    "                                x = x.unsqueeze(0)\n",
    "                                \n",
    "                            posterior = self.botorch_gp.posterior(x)\n",
    "                            \n",
    "                            mu_val = posterior.mean.detach().cpu().numpy().flatten()[0]\n",
    "                            sigma_val = posterior.variance.sqrt().detach().cpu().numpy().flatten()[0]\n",
    "\n",
    "                        ei = ExpectedImprovement(model=self.botorch_gp, best_f=self.y.max())\n",
    "        \n",
    "                        # Calculate EI\n",
    "                        with torch.no_grad():\n",
    "                            ei_values = ei(x)\n",
    "            \n",
    "                            ei_val = ei(x).detach().cpu().numpy().flatten()[0]\n",
    "                    elif method_name in ['dk_ei']:\n",
    "                        # Make predictions\n",
    "                        with torch.no_grad():\n",
    "                            if isinstance(candidate, np.ndarray):\n",
    "                                x = torch.tensor(candidate, dtype=torch.float32, device=self.device)\n",
    "                            \n",
    "                            # Add batch dimension if needed\n",
    "                            if x.dim() == 1:\n",
    "                                x = x.unsqueeze(0)\n",
    "                                \n",
    "                            posterior = self.deep_kernel_model.posterior(x)\n",
    "                            \n",
    "                            mu_val = posterior.mean.detach().cpu().numpy().flatten()[0]\n",
    "                            sigma_val = posterior.variance.sqrt().detach().cpu().numpy().flatten()[0]\n",
    "\n",
    "                        ei = ExpectedImprovement(model=self.deep_kernel_model, best_f=self.y.max())\n",
    "        \n",
    "                        # Calculate EI\n",
    "                        with torch.no_grad():\n",
    "                            ei_values = ei(x)\n",
    "            \n",
    "                            ei_val = ei(x).detach().cpu().numpy().flatten()[0]  \n",
    "                    else:    \n",
    "                        # Process candidate\n",
    "                        candidate_processed = self._preprocess_X(candidate.reshape(1, -1))\n",
    "                        \n",
    "                        # Predict with appropriate GP model\n",
    "                        mu, sigma = self.gp_best.predict(candidate_processed, return_std=True)\n",
    "                        \n",
    "                        # Convert predictions if using log transform\n",
    "                        if self.use_log_y:\n",
    "                            # Convert mu from log space to original space\n",
    "                            mu_orig = np.expm1(mu)\n",
    "                            mu_val = float(mu_orig[0])\n",
    "                            \n",
    "                            # Convert sigma to original space (approximately)\n",
    "                            sigma_orig = mu_orig * sigma\n",
    "                            sigma_val = float(sigma_orig[0])\n",
    "                            \n",
    "                            # Calculate EI in original space\n",
    "                            best_y_orig = float(self.best_y)\n",
    "                            imp = mu_orig - best_y_orig\n",
    "                            Z = imp / np.maximum(sigma_orig, 1e-10)\n",
    "                            ei = imp * norm.cdf(Z) + sigma_orig * norm.pdf(Z)\n",
    "                            ei_val = float(ei[0])\n",
    "                        else:\n",
    "                            # Use values directly\n",
    "                            mu_val = float(mu[0])\n",
    "                            sigma_val = float(sigma[0])\n",
    "                            \n",
    "                            # Calculate EI\n",
    "                            best_y = float(self.best_y)\n",
    "                            imp = mu - best_y\n",
    "                            Z = imp / np.maximum(sigma, 1e-10)\n",
    "                            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "                            ei_val = float(ei[0])\n",
    "                    \n",
    "                    # Store values\n",
    "                    methods.append(method_name)\n",
    "                    means.append(mu_val)\n",
    "                    stds.append(sigma_val)\n",
    "                    eis.append(ei_val)\n",
    "                    cands.append(candidate)\n",
    "                \n",
    "                # Create DataFrame for comparison\n",
    "                candidates_df = pd.DataFrame({\n",
    "                    'Method': methods,\n",
    "                    'Pred. Mean': means,\n",
    "                    'Pred. Std': stds,\n",
    "                    'EI': eis,\n",
    "                    'Candidate': cands\n",
    "                })\n",
    "                \n",
    "                # Sort by EI\n",
    "                candidates_df = candidates_df.sort_values('EI', ascending=False)\n",
    "\n",
    "                # STORE FOR VISUALISATION - DOES THIS WORK?\n",
    "                self.candidates_df = candidates_df\n",
    "                \n",
    "                # Select best method\n",
    "                best_method = candidates_df.iloc[0]['Method']\n",
    "                x_next = candidates[best_method]\n",
    "                method = best_method\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        # Store method used\n",
    "        self._last_method_used = method\n",
    "        \n",
    "        # Evaluate candidates if not already done\n",
    "        if 'candidates_df' not in locals():\n",
    "            methods = [method]\n",
    "            means = []\n",
    "            stds = []\n",
    "            eis = []\n",
    "            cands = []\n",
    "            \n",
    "            # Process candidate\n",
    "            candidate_processed = self._preprocess_X(x_next.reshape(1, -1))\n",
    "            \n",
    "            # Predict with appropriate GP model\n",
    "            mu, sigma = self.gp_best.predict(candidate_processed, return_std=True)\n",
    "            \n",
    "            # Convert predictions if using log transform\n",
    "            if self.use_log_y:\n",
    "                # Convert mu from log space to original space\n",
    "                mu_orig = np.expm1(mu)\n",
    "                mu_val = float(mu_orig[0])\n",
    "                \n",
    "                # Convert sigma to original space (approximately)\n",
    "                sigma_orig = mu_orig * sigma\n",
    "                sigma_val = float(sigma_orig[0])\n",
    "                \n",
    "                # Calculate EI in original space\n",
    "                best_y_orig = float(self.best_y)\n",
    "                imp = mu_orig - best_y_orig\n",
    "                Z = imp / np.maximum(sigma_orig, 1e-10)\n",
    "                ei = imp * norm.cdf(Z) + sigma_orig * norm.pdf(Z)\n",
    "                ei_val = float(ei[0])\n",
    "            else:\n",
    "                # Use values directly\n",
    "                mu_val = float(mu[0])\n",
    "                sigma_val = float(sigma[0])\n",
    "                \n",
    "                # Calculate EI\n",
    "                best_y = float(self.best_y)\n",
    "                imp = mu - best_y\n",
    "                Z = imp / np.maximum(sigma, 1e-10)\n",
    "                ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "                ei_val = float(ei[0])\n",
    "            \n",
    "            # Store values\n",
    "            means.append(mu_val)\n",
    "            stds.append(sigma_val)\n",
    "            eis.append(ei_val)\n",
    "            cands.append(candidate_processed)\n",
    "            \n",
    "            # Create DataFrame for comparison\n",
    "            candidates_df = pd.DataFrame({\n",
    "                'Method': methods,\n",
    "                'Pred. Mean': means,\n",
    "                'Pred. Std': stds,\n",
    "                'EI': eis,\n",
    "                'Candidate': cands\n",
    "            })\n",
    "        \n",
    "        return x_next, method, candidates_df\n",
    "    \n",
    "    # ==================== Methods to help with historical analysis / reverse engineering ====================\n",
    "\n",
    "    def suggest_next_candidate(self):\n",
    "        \"\"\"\n",
    "        Suggest the next candidate based on the analysis of historical performance.\n",
    "        Returns candidate point, method used, and comparison DataFrame.\n",
    "        \"\"\"\n",
    "        x_next, method, candidates_df = self.get_next_candidate(method=\"blend\")\n",
    "        \n",
    "        # Plot comparison of candidate selection methods\n",
    "        try:\n",
    "            # Convert to Python lists for plotting\n",
    "            methods_list = candidates_df['Method'].tolist()\n",
    "            means_list = candidates_df['Pred. Mean'].tolist()\n",
    "            stds_list = candidates_df['Pred. Std'].tolist()\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(methods_list, means_list, yerr=stds_list, alpha=0.7)\n",
    "            plt.xlabel('Method')\n",
    "            plt.ylabel('Predicted Mean')\n",
    "            plt.title('Comparison of Candidate Selection Methods')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {e}\")\n",
    "            # Alternative visualization\n",
    "            try:\n",
    "                # Create a simple table instead of a bar chart\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # Create table data\n",
    "                table_data = []\n",
    "                for i, method in enumerate(methods_list):\n",
    "                    table_data.append([method, f\"{means_list[i]:.4f}\", f\"{stds_list[i]:.4f}\"])\n",
    "                \n",
    "                # Create the table\n",
    "                table = plt.table(cellText=table_data,\n",
    "                                colLabels=['Method', 'Predicted Mean', 'Std'],\n",
    "                                loc='center',\n",
    "                                cellLoc='center')\n",
    "                \n",
    "                # Style the table\n",
    "                table.auto_set_font_size(False)\n",
    "                table.set_fontsize(12)\n",
    "                table.scale(1.2, 1.5)\n",
    "                \n",
    "                plt.title('Comparison of Candidate Selection Methods')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating table visualization: {e}\")\n",
    "        \n",
    "        # Print method comparison table\n",
    "        print(\"\\nMethod Comparison:\")\n",
    "        print(candidates_df[['Method', 'Pred. Mean', 'Pred. Std', 'EI']])\n",
    "        \n",
    "        return x_next, method, candidates_df\n",
    "    \n",
    "    def recommend_next_method(self):\n",
    "        \"\"\"\n",
    "        Recommend which method to use for the next iteration\n",
    "        based on historical performance.\n",
    "        \"\"\"\n",
    "        # If we don't have enough history, use a blend\n",
    "        if len(self.history['iterations']) < 3:\n",
    "            return \"Not enough history to make a recommendation. Using blend.\"\n",
    "        \n",
    "        # Check if exploration or exploitation is needed\n",
    "        # Simple heuristic: if recent iterations show little improvement, explore more\n",
    "        recent_improvements = []\n",
    "        for i in range(max(3, min(10, len(self.history['best_value']) - 1))):\n",
    "            idx = -(i+1)\n",
    "            prev_best = self.history['best_value'][idx-1]\n",
    "            curr_best = self.history['best_value'][idx]\n",
    "            improvement = curr_best - prev_best\n",
    "            recent_improvements.append(improvement)\n",
    "        \n",
    "        avg_improvement = np.mean(recent_improvements)\n",
    "        \n",
    "        # If improvements are small, explore more\n",
    "        if avg_improvement < 0.01 * self.best_y:\n",
    "            # Recommend exploration methods\n",
    "            exploration_methods = [\"botorch_ucb\", \"botorch_thompson\", \"bootstrap\", \"hyperopt\"]\n",
    "            return f\"Exploration: {np.random.choice(exploration_methods)} recommended due to slowing improvements\"\n",
    "        else:\n",
    "            # Recommend exploitation methods\n",
    "            exploitation_methods = [\"botorch_ei\", \"ei\", \"botorch_mc_ei\", \"botorch_kg\"]\n",
    "            return f\"Exploitation: {np.random.choice(exploitation_methods)} recommended based on good progress\"\n",
    "    \n",
    "    def evaluate_methods(self):\n",
    "        \"\"\"\n",
    "        Evaluate which method would have performed best historically.\n",
    "        Handles log transformation properly.\n",
    "        \"\"\"\n",
    "        if len(self.history['iterations']) < 2:\n",
    "            print(\"Not enough history to evaluate methods\")\n",
    "            return None\n",
    "        \n",
    "        # Extract the method used at each iteration\n",
    "        methods = self.history['method_used']\n",
    "        improvements = []\n",
    "        \n",
    "        for i in range(1, len(self.history['iterations'])):\n",
    "            prev_best = self.history['best_value'][i-1]\n",
    "            curr_best = self.history['best_value'][i]\n",
    "            improvement = curr_best - prev_best\n",
    "            improvements.append(improvement)\n",
    "        \n",
    "        # Ensure methods and improvements have the same length\n",
    "        if len(methods[1:]) != len(improvements):\n",
    "            min_length = min(len(methods[1:]), len(improvements))\n",
    "            methods_adjusted = methods[1:min_length+1]\n",
    "            improvements_adjusted = improvements[:min_length]\n",
    "        else:\n",
    "            methods_adjusted = methods[1:]\n",
    "            improvements_adjusted = improvements\n",
    "        \n",
    "        # Create a DataFrame with method performance\n",
    "        method_df = pd.DataFrame({\n",
    "            'Method': methods_adjusted,\n",
    "            'Improvement': improvements_adjusted\n",
    "        })\n",
    "        \n",
    "        # Group by method and calculate average improvement\n",
    "        method_performance = method_df.groupby('Method')['Improvement'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        method_performance = method_performance.sort_values('mean', ascending=False)\n",
    "        \n",
    "        return method_performance\n",
    "    \n",
    "    # ==================== Cross validation ====================\n",
    "\n",
    "    def cross_validate_models(self, model_type='standard', n_splits=5):\n",
    "        \"\"\"\n",
    "        Unified cross-validation method for all model types.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            Type of models to cross-validate ('standard', 'deep', 'warped')\n",
    "        n_splits : int\n",
    "            Number of cross-validation folds\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        cv_results : dict\n",
    "            Cross-validation results for the specified model type\n",
    "        \"\"\"\n",
    "        # Get model configurations based on type\n",
    "        model_configs = self._get_model_configs(model_type)\n",
    "        if not model_configs:\n",
    "            print(f\"No {model_type} models configured\")\n",
    "            return None\n",
    "        \n",
    "        # Basic validation\n",
    "        n_splits = min(n_splits, len(self.X))\n",
    "        if n_splits < 2:\n",
    "            print(\"Not enough data for cross-validation\")\n",
    "            return None\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y = self._prepare_cv_data()\n",
    "        \n",
    "        # Initialize results storage\n",
    "        results = self._initialize_results(model_configs.keys())\n",
    "        failed_configs = set()\n",
    "        \n",
    "        # Setup cross-validation\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            y_test_orig = self.y[test_idx] if self.use_log_y else y_test\n",
    "            \n",
    "            for name, config in model_configs.items():\n",
    "                if name in failed_configs:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    # Create and train model based on type\n",
    "                    model = self._create_model(model_type, config, X_train, y_train)\n",
    "                    trained_model = self._train_model(model_type, model, X_train, y_train)\n",
    "                    \n",
    "                    if trained_model is None:\n",
    "                        raise RuntimeError(\"Model training failed\")\n",
    "                    \n",
    "                    # Make predictions and calculate metrics\n",
    "                    metrics = self._evaluate_model(\n",
    "                        model_type, trained_model, X_test, y_test, y_test_orig, y_train\n",
    "                    )\n",
    "                    \n",
    "                    # Store results\n",
    "                    for metric_name, value in metrics.items():\n",
    "                        results[metric_name][name].append(value)\n",
    "                        \n",
    "#                    if model_type != 'warped':  # Only print for non-warped to reduce output\n",
    "#                        print(f\"CV Fold {fold_idx+1} - {name}: R = {metrics['r2']:.4f}, RMSE = {metrics['rmse']:.4f}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to train/evaluate {name} on fold {fold_idx+1}: {e}\")\n",
    "                    if fold_idx == 0:\n",
    "                        failed_configs.add(name)\n",
    "                        print(f\"Skipping {name} for remaining folds\")\n",
    "                    \n",
    "                    # Add fallback metrics if we've already collected some\n",
    "                    if len(results['r2'][name]) > 0:\n",
    "                        fallback_metrics = self._get_fallback_metrics(y_test)\n",
    "                        for metric_name, value in fallback_metrics.items():\n",
    "                            results[metric_name][name].append(value)\n",
    "        \n",
    "        # Process and return results\n",
    "        return self._process_cv_results(results, model_configs.keys(), model_type)\n",
    "    \n",
    "    def _get_model_configs(self, model_type):\n",
    "        \"\"\"Get model configurations based on type.\"\"\"\n",
    "        if model_type == 'standard':\n",
    "            return self.kernels\n",
    "        elif model_type == 'deep':\n",
    "            return self.deep_kernels\n",
    "        elif model_type == 'warped':\n",
    "            return self.warped_configs\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    def _prepare_cv_data(self):\n",
    "        \"\"\"Prepare data for cross-validation.\"\"\"\n",
    "        if hasattr(self, '_preprocess_X'):\n",
    "            X = self._preprocess_X(self.X)\n",
    "        else:\n",
    "            X = self.X\n",
    "        \n",
    "        y = self.y_log if self.use_log_y else self.y\n",
    "        return X, y\n",
    "    \n",
    "    def _initialize_results(self, model_names):\n",
    "        \"\"\"Initialize results storage dictionaries.\"\"\"\n",
    "        return {\n",
    "            'r2': {name: [] for name in model_names},\n",
    "            'rmse': {name: [] for name in model_names},\n",
    "            'mae': {name: [] for name in model_names},\n",
    "            'nlpd': {name: [] for name in model_names}\n",
    "        }\n",
    "    \n",
    "    def _create_model(self, model_type, config, X_train, y_train):\n",
    "        \"\"\"Create model based on type and configuration.\"\"\"\n",
    "        if model_type == 'standard':\n",
    "            return self._create_standard_model(config)\n",
    "        elif model_type == 'deep':\n",
    "            return self._create_deep_model(config, X_train, y_train)\n",
    "        elif model_type == 'warped':\n",
    "            return self._create_warped_model(config, X_train, y_train)\n",
    "    \n",
    "    def _create_standard_model(self, kernel):\n",
    "        \"\"\"Create standard Gaussian Process model.\"\"\"\n",
    "        from sklearn.base import clone\n",
    "        return GaussianProcessRegressor(\n",
    "            kernel=clone(kernel),\n",
    "            alpha=1e-6,\n",
    "            normalize_y=True,\n",
    "            n_restarts_optimizer=20,\n",
    "            random_state=self.random_state,\n",
    "            optimizer=custom_optimizer\n",
    "        )\n",
    "    \n",
    "    def _create_deep_model(self, config, X_train, y_train):\n",
    "        \"\"\"Create deep kernel GP model.\"\"\"\n",
    "        import torch\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        \n",
    "        model = DeepKernelGP(\n",
    "            train_X=X_train_tensor,\n",
    "            train_Y=y_train_tensor,\n",
    "            hidden_dims=config[\"hidden_dims\"],\n",
    "            output_dim=config[\"output_dim\"]\n",
    "        )\n",
    "        \n",
    "        # Apply constraints and modifications\n",
    "        if \"min_lengthscale\" in config and config[\"min_lengthscale\"] > 0:\n",
    "            model.base_covar_module.register_constraint(\n",
    "                \"raw_lengthscale\", \n",
    "                gpytorch.constraints.GreaterThan(config[\"min_lengthscale\"])\n",
    "            )\n",
    "        \n",
    "        if \"residual\" in config and config[\"residual\"]:\n",
    "            model.feature_extractor = self._build_residual_extractor(\n",
    "                model.input_dim, \n",
    "                config[\"hidden_dims\"],\n",
    "                config[\"output_dim\"]\n",
    "            )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _create_warped_model(self, config, X_train, y_train):\n",
    "        \"\"\"Create warped GP model.\"\"\"\n",
    "        import torch\n",
    "        import gpytorch\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        \n",
    "        # Create likelihood with constraints\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        likelihood.noise_covar.register_constraint(\n",
    "            \"raw_noise\", \n",
    "            gpytorch.constraints.GreaterThan(1e-4)\n",
    "        )\n",
    "        likelihood.initialize(noise=0.01)\n",
    "        \n",
    "        return WarpedGP(\n",
    "            train_X=X_train_tensor,\n",
    "            train_Y=y_train_tensor,\n",
    "            likelihood=likelihood,\n",
    "            **config\n",
    "        )\n",
    "    \n",
    "    def _train_model(self, model_type, model, X_train=None, y_train=None):\n",
    "        \"\"\"Train model based on type.\"\"\"\n",
    "        if model_type == 'standard':\n",
    "            model.fit(X_train, y_train)\n",
    "            return model\n",
    "        elif model_type == 'deep':\n",
    "            return fit_deep_kernel_model(\n",
    "                model, \n",
    "                training_iterations=300,\n",
    "                early_stopping=True,\n",
    "                min_loss_threshold=0.2\n",
    "            )\n",
    "        elif model_type == 'warped':\n",
    "            return fit_warped_gp_model(\n",
    "                model,\n",
    "                training_iterations=300,\n",
    "                early_stopping=True\n",
    "            )\n",
    "    \n",
    "    def _evaluate_model(self, model_type, model, X_test, y_test, y_test_orig, y_train):\n",
    "        \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "        if model_type == 'standard':\n",
    "            return self._evaluate_standard_model(model, X_test, y_test, y_test_orig, y_train)\n",
    "        else:  # deep or warped\n",
    "            return self._evaluate_torch_model(model, X_test, y_test, y_test_orig)\n",
    "    \n",
    "    def _evaluate_standard_model(self, model, X_test, y_test, y_test_orig, y_train):\n",
    "        \"\"\"Evaluate standard GP model.\"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        if self.use_log_y:\n",
    "            y_pred_orig = np.expm1(y_pred)\n",
    "            r2 = 1 - np.sum((y_test_orig - y_pred_orig)**2) / np.sum((y_test_orig - np.mean(y_test_orig))**2)\n",
    "            rmse = np.sqrt(np.mean((y_test_orig - y_pred_orig)**2))\n",
    "            mae = np.mean(np.abs(y_test_orig - y_pred_orig))\n",
    "        else:\n",
    "            r2 = 1 - np.sum((y_test - y_pred)**2) / np.sum((y_test - np.mean(y_train))**2)\n",
    "            rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "            mae = np.mean(np.abs(y_test - y_pred))\n",
    "        \n",
    "        # Simple NLPD approximation for standard GP\n",
    "        nlpd = np.log(rmse)\n",
    "        \n",
    "        return {'r2': r2, 'rmse': rmse, 'mae': mae, 'nlpd': nlpd}\n",
    "    \n",
    "    def _evaluate_torch_model(self, model, X_test, y_test, y_test_orig):\n",
    "        \"\"\"Evaluate PyTorch-based models (deep/warped).\"\"\"\n",
    "        import torch\n",
    "        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "        \n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            posterior = model(X_test_tensor)\n",
    "            pred_mean = posterior.mean.cpu().numpy()\n",
    "            \n",
    "            # Get predictive variance\n",
    "            try:\n",
    "                lower, upper = posterior.confidence_region()\n",
    "                pred_var = ((upper - lower) / 4.0).cpu().numpy() ** 2\n",
    "                pred_var = np.maximum(pred_var, 1e-6)\n",
    "            except:\n",
    "                pred_var = np.ones_like(pred_mean) * 0.01\n",
    "            \n",
    "            # Calculate metrics with safeguards\n",
    "            r2 = r2_score(y_test, pred_mean)\n",
    "            r2 = r2 if not (np.isnan(r2) or np.isinf(r2)) else -1.0\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(y_test, pred_mean))\n",
    "            rmse = rmse if not (np.isnan(rmse) or np.isinf(rmse)) else np.std(y_test) * 2\n",
    "            \n",
    "            mae = mean_absolute_error(y_test, pred_mean)\n",
    "            mae = mae if not (np.isnan(mae) or np.isinf(mae)) else np.std(y_test)\n",
    "            \n",
    "            # Calculate NLPD\n",
    "            try:\n",
    "                nlpd = 0.5 * np.mean(\n",
    "                    np.log(2 * np.pi * pred_var) + \n",
    "                    (y_test - pred_mean)**2 / pred_var\n",
    "                )\n",
    "                nlpd = nlpd if not (np.isnan(nlpd) or np.isinf(nlpd)) else np.log(np.std(y_test) ** 2)\n",
    "            except:\n",
    "                nlpd = np.log(np.std(y_test) ** 2)\n",
    "        \n",
    "        return {'r2': r2, 'rmse': rmse, 'mae': mae, 'nlpd': nlpd}\n",
    "    \n",
    "    def _get_fallback_metrics(self, y_test):\n",
    "        \"\"\"Get fallback metrics for failed model evaluation.\"\"\"\n",
    "        return {\n",
    "            'r2': -1.0,\n",
    "            'rmse': np.std(y_test) * 2,\n",
    "            'mae': np.std(y_test),\n",
    "            'nlpd': np.log(np.std(y_test) ** 2)\n",
    "        }\n",
    "    \n",
    "    def _process_cv_results(self, results, model_names, model_type):\n",
    "        \"\"\"Process cross-validation results and create output.\"\"\"\n",
    "        # Filter valid configurations (at least half the folds worked)\n",
    "        n_splits = len(list(results['r2'].values())[0]) if results['r2'] else 0\n",
    "        valid_configs = [\n",
    "            name for name in model_names \n",
    "            if len(results['r2'][name]) >= max(1, n_splits // 2)\n",
    "        ]\n",
    "        \n",
    "        if not valid_configs:\n",
    "            print(f\"Warning: No valid {model_type} configurations\")\n",
    "            return self._create_dummy_results()\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        cv_results = {}\n",
    "        for metric in ['r2', 'rmse', 'mae', 'nlpd']:\n",
    "            cv_results[f'{metric}_mean'] = {\n",
    "                name: np.mean(results[metric][name]) \n",
    "                for name in valid_configs\n",
    "            }\n",
    "            cv_results[f'{metric}_std'] = {\n",
    "                name: np.std(results[metric][name]) \n",
    "                for name in valid_configs\n",
    "            }\n",
    "        \n",
    "        # Sort by R\n",
    "        sorted_names = sorted(\n",
    "            valid_configs, \n",
    "            key=lambda name: cv_results['r2_mean'][name], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{model_type.title()} Kernel Cross-Validation Results:\")\n",
    "        for name in sorted_names:\n",
    "            print(f\"{name}: R = {cv_results['r2_mean'][name]:.4f}  {cv_results['r2_std'][name]:.4f}, \"\n",
    "                  f\"RMSE = {cv_results['rmse_mean'][name]:.4f}  {cv_results['rmse_std'][name]:.4f}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        self._create_cv_visualization(cv_results, sorted_names, model_type)\n",
    "        \n",
    "        return cv_results\n",
    "    \n",
    "    def _create_dummy_results(self):\n",
    "        \"\"\"Create dummy results when no configurations work.\"\"\"\n",
    "        return {\n",
    "            'r2_mean': {\"Dummy\": -1.0},\n",
    "            'rmse_mean': {\"Dummy\": np.std(self.y) * 2},\n",
    "            'mae_mean': {\"Dummy\": np.std(self.y)},\n",
    "            'nlpd_mean': {\"Dummy\": np.log(np.std(self.y) ** 2)}\n",
    "        }\n",
    "    \n",
    "    def _create_cv_visualization(self, cv_results, sorted_names, model_type):\n",
    "        \"\"\"Create cross-validation visualization plots.\"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            \n",
    "            # R plot\n",
    "            plt.subplot(1, 2, 1)\n",
    "            r2_means = [cv_results['r2_mean'][name] for name in sorted_names]\n",
    "            r2_stds = [cv_results['r2_std'][name] for name in sorted_names]\n",
    "            \n",
    "            plt.bar(sorted_names, r2_means, yerr=r2_stds, alpha=0.7)\n",
    "            plt.ylabel('R Score')\n",
    "            plt.title(f'{model_type.title()} Cross-Validation R Score')\n",
    "            plt.ylim(min(0, min(r2_means) - max(r2_stds) - 0.1), 1.0)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=90)\n",
    "            \n",
    "            # RMSE plot\n",
    "            plt.subplot(1, 2, 2)\n",
    "            rmse_means = [cv_results['rmse_mean'][name] for name in sorted_names]\n",
    "            rmse_stds = [cv_results['rmse_std'][name] for name in sorted_names]\n",
    "            \n",
    "            plt.bar(sorted_names, rmse_means, yerr=rmse_stds, alpha=0.7)\n",
    "            plt.ylabel('Root Mean Squared Error')\n",
    "            plt.title(f'{model_type.title()} Cross-Validation RMSE')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=90)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {e}\")\n",
    "                \n",
    "    # ==================== Initialisation of models ====================\n",
    "\n",
    "    def init_deep_kernel_model(self, kernel_name, y_for_fit):\n",
    "        \"\"\"Initialize the best deep kernel model after cross-validation.\"\"\"\n",
    "        # Get configuration\n",
    "        config = self.deep_kernels[kernel_name]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        X_tensor = torch.tensor(self.X, dtype=torch.float32, device=self.device)\n",
    "        y_tensor = torch.tensor(y_for_fit, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Create the model\n",
    "        self.deep_kernel_model = DeepKernelGP(\n",
    "            train_X=X_tensor,\n",
    "            train_Y=y_tensor,\n",
    "            hidden_dims=config[\"hidden_dims\"],\n",
    "            output_dim=config[\"output_dim\"]\n",
    "        )\n",
    "        \n",
    "        # Apply minimum lengthscale constraint if specified\n",
    "        if \"min_lengthscale\" in config and config[\"min_lengthscale\"] > 0:\n",
    "            self.deep_kernel_model.base_covar_module.register_constraint(\n",
    "                \"raw_lengthscale\", \n",
    "                gpytorch.constraints.GreaterThan(config[\"min_lengthscale\"])\n",
    "            )\n",
    "        \n",
    "        # Add residual connections if specified\n",
    "        if \"residual\" in config and config[\"residual\"]:\n",
    "            self.deep_kernel_model.feature_extractor = self._build_residual_extractor(\n",
    "                self.deep_kernel_model.input_dim, \n",
    "                config[\"hidden_dims\"],\n",
    "                config[\"output_dim\"]\n",
    "            )\n",
    "        \n",
    "        # Train the model with more iterations for final model\n",
    "        self.deep_kernel_model = fit_deep_kernel_model(\n",
    "            self.deep_kernel_model, \n",
    "            training_iterations=500,\n",
    "            early_stopping=True,\n",
    "            min_loss_threshold=0.1\n",
    "        )\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        self.deep_kernel_model.eval()\n",
    "        \n",
    "        # Store the model parameters\n",
    "        self.deep_kernel_config = config\n",
    "    \n",
    "    def init_standard_kernel_model(self, kernel_name, y_for_fit):\n",
    "        \"\"\"Initialize standard kernel model after cross-validation.\"\"\"\n",
    "        # Your existing code to initialize standard GP with selected kernel\n",
    "        self.best_kernel = clone(self.kernels[kernel_name])\n",
    "        \n",
    "        # Initialize GP with best kernel\n",
    "        self.gp_best = GaussianProcessRegressor(\n",
    "            kernel=self.best_kernel,\n",
    "            alpha=1e-6,\n",
    "            normalize_y=True,\n",
    "            n_restarts_optimizer=100,\n",
    "            random_state=self.random_state,\n",
    "            optimizer=custom_optimizer        \n",
    "        )\n",
    "        \n",
    "        # Fit GP with best kernel\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        self.gp_best.fit(X_processed, y_for_fit)\n",
    "\n",
    "    def init_warped_gp_model(self, config_name, y_for_fit):\n",
    "        \"\"\"Initialize warped GP model after cross-validation.\"\"\"\n",
    "        # Get configuration\n",
    "        config = self.warped_configs[config_name]\n",
    "\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        X_tensor = torch.tensor(X_processed, dtype=torch.float32, device=self.device)\n",
    "        y_tensor = torch.tensor(y_for_fit, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Create model\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        self.warped_gp_model = WarpedGP(\n",
    "            train_X=X_tensor,\n",
    "            train_Y=y_tensor,\n",
    "            likelihood=likelihood,\n",
    "            **config\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        self.warped_gp_model = fit_warped_gp_model(\n",
    "            self.warped_gp_model,\n",
    "            training_iterations=2000 # was 500\n",
    "        )\n",
    "        \n",
    "        # Set to evaluation mode\n",
    "        self.warped_gp_model.eval()\n",
    "        \n",
    "        # Store model configuration\n",
    "        self.warped_gp_config = config\n",
    "\n",
    "        # Create a wrapper around the warped model with training data for refitting\n",
    "        self.gp_best = WarpedGPWrapper(\n",
    "            self.warped_gp_model,\n",
    "            X_train=X_processed,\n",
    "            y_train=self.y_log if self.use_log_y else self.y\n",
    "        )\n",
    "        print(\"Using warped GP model through compatibility wrapper\")\n",
    "        \n",
    "    # ==================== Analysis methods ====================\n",
    "    \n",
    "    def analyze_warping_parameters(self):\n",
    "        \"\"\"Analyze and print the learned warping parameters.\"\"\"\n",
    "        if not hasattr(self, 'warped_gp_model') or not self.is_warped:\n",
    "            print(\"No warped GP model available\")\n",
    "            return\n",
    "        \n",
    "        model = self.warped_gp_model\n",
    "        warp_type = model.warp_transform.warp_type\n",
    "        input_dim = model.input_dim\n",
    "        \n",
    "        print(f\"\\nWarping Analysis for {warp_type} warping:\")\n",
    "        \n",
    "        # Get parameters\n",
    "        with torch.no_grad():\n",
    "            params = model.warp_transform.warp_params.cpu().numpy()\n",
    "        \n",
    "        # Interpret parameters based on warping type\n",
    "        if warp_type == \"kumaraswamy\":\n",
    "            print(\"Kumaraswamy Warping Parameters (a, b, direction):\")\n",
    "            for i in range(input_dim):\n",
    "                a = abs(params[i, 0]) + 0.5  # Ensure a > 0\n",
    "                b = abs(params[i, 1]) + 0.5  # Ensure b > 0\n",
    "                direction = torch.sigmoid(torch.tensor(params[i, 2])).item()\n",
    "                \n",
    "                warping_effect = \"Strong\" if abs(direction - 0.5) > 0.3 else \"Moderate\" if abs(direction - 0.5) > 0.1 else \"Weak\"\n",
    "                shape_description = \"\"\n",
    "                \n",
    "                if a < 1 and b < 1:\n",
    "                    shape_description = \"U-shaped (bimodal)\"\n",
    "                elif a < 1 and b > 1:\n",
    "                    shape_description = \"J-shaped, right-skewed\"\n",
    "                elif a > 1 and b < 1:\n",
    "                    shape_description = \"J-shaped, left-skewed\"\n",
    "                elif a > 1 and b > 1:\n",
    "                    if abs(a - b) < 0.5:\n",
    "                        shape_description = \"Bell-shaped, symmetric\"\n",
    "                    else:\n",
    "                        shape_description = \"Bell-shaped, asymmetric\"\n",
    "                \n",
    "                print(f\"  Dim {i+1}: a={a:.4f}, b={b:.4f}, direction={direction:.4f} - {warping_effect} {shape_description}\")\n",
    "                \n",
    "        elif warp_type == \"tanh\" or warp_type == \"sigmoid\":\n",
    "            param_names = [\"scale\", \"shift\", \"direction\"]\n",
    "            print(f\"{warp_type.capitalize()} Warping Parameters ({', '.join(param_names)}):\")\n",
    "            for i in range(input_dim):\n",
    "                if warp_type == \"tanh\":\n",
    "                    scale = abs(params[i, 0]) + 0.5\n",
    "                    shift = params[i, 1]\n",
    "                    direction = torch.sigmoid(torch.tensor(params[i, 2])).item()\n",
    "                else:  # sigmoid\n",
    "                    scale = abs(params[i, 0]) + 1.0\n",
    "                    shift = params[i, 1] * 2\n",
    "                    direction = torch.sigmoid(torch.tensor(params[i, 2])).item()\n",
    "                    \n",
    "                warping_effect = \"Strong\" if abs(direction - 0.5) > 0.3 else \"Moderate\" if abs(direction - 0.5) > 0.1 else \"Weak\"\n",
    "                print(f\"  Dim {i+1}: scale={scale:.4f}, shift={shift:.4f}, direction={direction:.4f} - {warping_effect}\")\n",
    "        \n",
    "        # Analyze covariance parameters\n",
    "        print(\"\\nCovariance Parameters:\")\n",
    "        try:\n",
    "            # Output scale (signal variance)\n",
    "            outputscale = model.covar_module.outputscale.item()\n",
    "            print(f\"  Output Scale: {outputscale:.4f}\")\n",
    "            \n",
    "            # Lengthscales\n",
    "            if hasattr(model.covar_module.base_kernel, 'lengthscale'):\n",
    "                lengthscales = model.covar_module.base_kernel.lengthscale.cpu().numpy()\n",
    "                if lengthscales.ndim > 1 and lengthscales.shape[1] > 1:  # ARD case\n",
    "                    for i in range(input_dim):\n",
    "                        print(f\"  Lengthscale Dim {i+1}: {lengthscales[0, i]:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  Lengthscale: {lengthscales.item():.4f}\")\n",
    "            \n",
    "            # Noise variance\n",
    "            noise = model.likelihood.noise.item()\n",
    "            print(f\"  Noise Variance: {noise:.6f}\")\n",
    "        except:\n",
    "            print(\"  Could not extract all covariance parameters\")\n",
    "        \n",
    "        return {\n",
    "            'warp_params': params,\n",
    "            'warp_type': warp_type,\n",
    "            'covariance_params': {\n",
    "                'outputscale': outputscale if 'outputscale' in locals() else None,\n",
    "                'lengthscales': lengthscales.flatten() if 'lengthscales' in locals() else None,\n",
    "                'noise': noise if 'noise' in locals() else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    # ==================== Visualisation Methods ====================\n",
    "        \n",
    "    def visualize_optimization(self):\n",
    "        \"\"\"Visualize the optimization process.\"\"\"\n",
    "        # Create figure with 3 subplots\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Bayesian Optimization Progress', fontsize=16)\n",
    "        \n",
    "        # Plot 1: Optimization progress\n",
    "        iterations = self.history['iterations']\n",
    "        best_values = self.history['best_value']\n",
    "        \n",
    "        axs[0, 0].plot(iterations, best_values, 'b-', marker='o')\n",
    "        axs[0, 0].set_xlabel('Iteration')\n",
    "        axs[0, 0].set_ylabel('Best Function Value')\n",
    "        axs[0, 0].set_title('Optimization Progress')\n",
    "        axs[0, 0].grid(True)\n",
    "        \n",
    "        # Plot 2: Prediction vs. Actual\n",
    "        if len(self.history['predicted_values']) > 0:\n",
    "            predicted = self.history['predicted_values']\n",
    "            actual = self.y[len(self.y) - len(predicted):]\n",
    "            \n",
    "            axs[0, 1].scatter(predicted, actual)\n",
    "            axs[0, 1].plot([min(predicted), max(predicted)], [min(predicted), max(predicted)], 'r--')\n",
    "            axs[0, 1].set_xlabel('Predicted Value')\n",
    "            axs[0, 1].set_ylabel('Actual Value')\n",
    "            axs[0, 1].set_title('Prediction vs. Actual')\n",
    "            axs[0, 1].grid(True)\n",
    "        \n",
    "        # Plot 3: Method Performance\n",
    "        try:\n",
    "            method_perf = self.evaluate_methods()\n",
    "            if method_perf is not None and len(method_perf) > 0:\n",
    "                method_perf = method_perf.sort_values('mean')\n",
    "                methods = method_perf['Method'].values\n",
    "                means = method_perf['mean'].values\n",
    "                stds = method_perf['std'].values\n",
    "                \n",
    "                y_pos = np.arange(len(methods))\n",
    "                \n",
    "                axs[1, 0].barh(y_pos, means, xerr=stds, align='center')\n",
    "                axs[1, 0].set_yticks(y_pos)\n",
    "                axs[1, 0].set_yticklabels(methods)\n",
    "                axs[1, 0].set_xlabel('Average Improvement')\n",
    "                axs[1, 0].set_title('Method Performance')\n",
    "                axs[1, 0].grid(True)\n",
    "            else:\n",
    "                axs[1, 0].text(0.5, 0.5, 'Not enough data\\nto evaluate methods',\n",
    "                             horizontalalignment='center',\n",
    "                             verticalalignment='center',\n",
    "                             transform=axs[1, 0].transAxes)\n",
    "                axs[1, 0].set_title('Method Performance')\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating methods: {e}\")\n",
    "            axs[1, 0].text(0.5, 0.5, 'Error evaluating methods',\n",
    "                         horizontalalignment='center',\n",
    "                         verticalalignment='center',\n",
    "                         transform=axs[1, 0].transAxes)\n",
    "            axs[1, 0].set_title('Method Performance')\n",
    "        \n",
    "        # Plot 4: Acquisition Function Values\n",
    "        if len(self.history['acquisition_values']) > 0:\n",
    "            acq_values = self.history['acquisition_values']\n",
    "            iterations = range(1, len(acq_values) + 1)\n",
    "            \n",
    "            axs[1, 1].plot(iterations, acq_values, 'g-', marker='x')\n",
    "            axs[1, 1].set_xlabel('Iteration')\n",
    "            axs[1, 1].set_ylabel('Acquisition Function Value')\n",
    "            axs[1, 1].set_title('Acquisition Function Values')\n",
    "            axs[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # If dimensionality allows, visualize in 2D or 3D\n",
    "        try:\n",
    "            self._visualize_space()\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing space: {e}\")\n",
    "            \n",
    "    def _visualize_space(self):\n",
    "        \"\"\"Visualize the input space, reducing dimensions if necessary.\"\"\"\n",
    "        # If n_dim <= 3, we can visualize directly\n",
    "        if self.n_dim <= 3:\n",
    "            self._direct_visualization()\n",
    "        else:\n",
    "            # Use PCA to reduce dimensions\n",
    "            self._pca_visualization()\n",
    "    \n",
    "    def _direct_visualization(self):\n",
    "        \"\"\"Direct visualization for low-dimensional problems.\"\"\"\n",
    "        if self.n_dim == 1:\n",
    "            # 1D visualization\n",
    "            X_plot = np.linspace(self.bounds[0, 0], self.bounds[0, 1], 1000).reshape(-1, 1)\n",
    "            y_pred, sigma = self.gp_best.predict(self._preprocess_X(X_plot), return_std=True)\n",
    "            if self.use_log_y:\n",
    "                y_pred = np.expm1(y_pred)\n",
    "                sigma = np.maximum((y_pred+1.0) * sigma, 1e-10)\n",
    "            \n",
    "            # Plot mean and confidence intervals\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(X_plot, y_pred, 'b-', label='GP Mean')\n",
    "            plt.fill_between(X_plot.flatten(), \n",
    "                            y_pred - 2*sigma, \n",
    "                            y_pred + 2*sigma, \n",
    "                            alpha=0.2, color='b', label='95% Confidence')\n",
    "            \n",
    "            # Plot observed points\n",
    "            plt.scatter(self.X, self.y, c='r', s=50, marker='o', label='Observations')\n",
    "            \n",
    "            # Highlight best point\n",
    "            plt.scatter([self.best_x], [self.best_y], c='g', s=100, marker='*', label='Best Point')\n",
    "            \n",
    "            plt.xlabel('Input')\n",
    "            plt.ylabel('Output')\n",
    "            plt.title('1D Gaussian Process Model')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "        elif self.n_dim == 2:\n",
    "            # 2D visualization\n",
    "            x1_grid = np.linspace(self.bounds[0, 0], self.bounds[0, 1], 100)\n",
    "            x2_grid = np.linspace(self.bounds[1, 0], self.bounds[1, 1], 100)\n",
    "            X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "            X_grid = np.column_stack([X1.flatten(), X2.flatten()])\n",
    "            \n",
    "            # Predict at grid points\n",
    "            y_pred, sigma = self.gp_best.predict(self._preprocess_X(X_grid), return_std=True)\n",
    "            if self.use_log_y:\n",
    "                y_pred = np.expm1(y_pred)\n",
    "                sigma = np.maximum((y_pred+1.0) * sigma, 1e-10)\n",
    "            \n",
    "            # Create plots\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Mean prediction\n",
    "            cf1 = axs[0].contourf(X1, X2, y_pred.reshape(X1.shape), 50, cmap='viridis')\n",
    "            axs[0].scatter(self.X[:, 0], self.X[:, 1], c='r', s=50, marker='o')\n",
    "            axs[0].scatter([self.best_x[0]], [self.best_x[1]], c='g', s=100, marker='*')\n",
    "            axs[0].set_xlabel('Input Dimension 1')\n",
    "            axs[0].set_ylabel('Input Dimension 2')\n",
    "            axs[0].set_title('GP Mean Prediction')\n",
    "            plt.colorbar(cf1, ax=axs[0])\n",
    "\n",
    "            # Show the different candidates as well\n",
    "            df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "            for index, row in df.iterrows():\n",
    "                axs[0].scatter(row['Candidate'][0], row['Candidate'][1], c='b', s=100, marker='+')\n",
    "                axs[0].text(row['Candidate'][0], row['Candidate'][1], row['Method'], fontsize=6, ha='right', va='bottom')\n",
    "            \n",
    "            # Uncertainty\n",
    "            cf2 = axs[1].contourf(X1, X2, sigma.reshape(X1.shape), 50, cmap='plasma')\n",
    "            axs[1].scatter(self.X[:, 0], self.X[:, 1], c='r', s=50, marker='o')\n",
    "            axs[1].set_xlabel('Input Dimension 1')\n",
    "            axs[1].set_ylabel('Input Dimension 2')\n",
    "            axs[1].set_title('GP Prediction Uncertainty')\n",
    "            plt.colorbar(cf2, ax=axs[1])\n",
    "            \n",
    "            # Show the different candidates as well\n",
    "            df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "            for index, row in df.iterrows():\n",
    "                axs[1].scatter(row['Candidate'][0], row['Candidate'][1], c='b', s=100, marker='+')\n",
    "                axs[1].text(row['Candidate'][0], row['Candidate'][1], row['Method'], fontsize=6, ha='right', va='bottom')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        elif self.n_dim == 3:\n",
    "            # 3D visualization using scatter plot\n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Scatter plot of observed points, colored by function value\n",
    "            scatter = ax.scatter(self.X[:, 0], self.X[:, 1], self.X[:, 2], \n",
    "                            c=self.y, cmap='viridis', s=50, alpha=0.8)\n",
    "            \n",
    "            # Highlight best point\n",
    "            ax.scatter([self.best_x[0]], [self.best_x[1]], [self.best_x[2]], \n",
    "                     c='r', s=200, marker='*', label='Best Point')\n",
    "\n",
    "            # Highlight candidates - DOES THIS WORK?\n",
    "            df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "            for index, row in df.iterrows():\n",
    "                ax.scatter(row['Candidate'], c='b', s=200, marker='+', label=row['method'])\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(scatter)\n",
    "            cbar.set_label('Function Value')\n",
    "            \n",
    "            # Labels and title\n",
    "            ax.set_xlabel('Input Dimension 1')\n",
    "            ax.set_ylabel('Input Dimension 2')\n",
    "            ax.set_zlabel('Input Dimension 3')\n",
    "            ax.set_title('3D Observation Space')\n",
    "            \n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def _pca_visualization(self):\n",
    "        \"\"\"Use PCA to visualize high-dimensional data.\"\"\"\n",
    "        # Perform PCA on input points\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(self.X)\n",
    "        \n",
    "        # Create scatter plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=self.y, s=100, cmap='viridis')\n",
    "        \n",
    "        # Highlight points added during optimization\n",
    "        if len(self.history['candidate_points']) > 0:\n",
    "            candidate_points = np.array(self.history['candidate_points'])\n",
    "            candidates_pca = pca.transform(candidate_points)\n",
    "            \n",
    "            # Connect points in sequence\n",
    "            for i in range(len(candidates_pca)):\n",
    "                plt.text(candidates_pca[i, 0], candidates_pca[i, 1], str(i+1), \n",
    "                       fontsize=12, ha='center', va='center')\n",
    "            \n",
    "            plt.plot(candidates_pca[:, 0], candidates_pca[:, 1], 'r--', alpha=0.5)\n",
    "        \n",
    "        # Highlight best point\n",
    "        best_pca = pca.transform(self.best_x.reshape(1, -1))\n",
    "        plt.scatter(best_pca[:, 0], best_pca[:, 1], c='r', s=200, marker='*', label='Best Point')\n",
    "\n",
    "        # Show the different candidates as well\n",
    "        df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "        for index, row in df.iterrows():\n",
    "            best_pca = pca.transform(row['Candidate'].reshape(1, -1))\n",
    "            plt.scatter(best_pca[:, 0], best_pca[:, 1], c='b', s=100, marker='+')\n",
    "            plt.text(best_pca[:, 0], best_pca[:, 1], row['Method'], fontsize=6, ha='right', va='bottom')\n",
    "        \n",
    "        # Add colorbar and labels\n",
    "        cbar = plt.colorbar(scatter)\n",
    "        cbar.set_label('Function Value')\n",
    "        \n",
    "        plt.xlabel(f'PCA Component 1 (Variance: {pca.explained_variance_ratio_[0]:.2f})')\n",
    "        plt.ylabel(f'PCA Component 2 (Variance: {pca.explained_variance_ratio_[1]:.2f})')\n",
    "        plt.title('PCA Visualization of Input Space')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Also visualize in 3D if possible\n",
    "        if self.n_dim > 3:\n",
    "            pca3d = PCA(n_components=3)\n",
    "            X_pca3d = pca3d.fit_transform(self.X)\n",
    "            \n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Scatter plot of observed points, colored by function value\n",
    "            scatter = ax.scatter(X_pca3d[:, 0], X_pca3d[:, 1], X_pca3d[:, 2], \n",
    "                               c=self.y, cmap='viridis', s=50, alpha=0.8)\n",
    "            \n",
    "            # Highlight best point\n",
    "            best_pca3d = pca3d.transform(self.best_x.reshape(1, -1))\n",
    "            ax.scatter(best_pca3d[:, 0], best_pca3d[:, 1], best_pca3d[:, 2], \n",
    "                     c='r', s=200, marker='*', label='Best Point')\n",
    "            \n",
    "            # Show the different candidates as well\n",
    "            df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "            for index, row in df.iterrows():\n",
    "                best_pca3d = pca3d.transform(row['Candidate'].reshape(1, -1))\n",
    "                ax.scatter(best_pca3d[:, 0], best_pca3d[:, 1], best_pca3d[:, 2], c='b', s=100, marker='+')\n",
    "                ax.text(best_pca3d[0, 0], best_pca3d[0, 1], best_pca3d[0, 2], row['Method'], fontsize=6, ha='right', va='bottom')\n",
    "\n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(scatter)\n",
    "            cbar.set_label('Function Value')\n",
    "            \n",
    "            # Labels and title\n",
    "            ax.set_xlabel(f'PCA Component 1 (Variance: {pca3d.explained_variance_ratio_[0]:.2f})')\n",
    "            ax.set_ylabel(f'PCA Component 2 (Variance: {pca3d.explained_variance_ratio_[1]:.2f})')\n",
    "            ax.set_zlabel(f'PCA Component 3 (Variance: {pca3d.explained_variance_ratio_[2]:.2f})')\n",
    "            ax.set_title('3D PCA Visualization')\n",
    "            \n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_prediction_surface(self, resolution=50):\n",
    "        \"\"\"\n",
    "        Visualize the prediction surface using 2D PCA.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        resolution : int\n",
    "            Grid resolution for visualization\n",
    "        \"\"\"\n",
    "        if self.n_dim <= 1:\n",
    "            print(\"This visualization is only for dimensions > 1\")\n",
    "            return\n",
    "        \n",
    "        # Use PCA to reduce dimensions for visualization\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(self.X)\n",
    "        \n",
    "        # Define grid in PCA space\n",
    "        x1_min, x1_max = X_pca[:, 0].min() - 0.1, X_pca[:, 0].max() + 0.1\n",
    "        x2_min, x2_max = X_pca[:, 1].min() - 0.1, X_pca[:, 1].max() + 0.1\n",
    "        \n",
    "        xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, resolution),\n",
    "                              np.linspace(x2_min, x2_max, resolution))\n",
    "        \n",
    "        # Grid points in PCA space\n",
    "        grid_pca = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "        \n",
    "        # Project grid points back to original space\n",
    "        # We need to make sure we handle the dimensionality correctly\n",
    "        grid_orig = np.zeros((grid_pca.shape[0], self.n_dim))\n",
    "        \n",
    "        for i in range(grid_pca.shape[0]):\n",
    "            # This is a simplified approach - we project from PCA space back to original\n",
    "            # and then ensure bounds are respected\n",
    "            point_orig = pca.inverse_transform(grid_pca[i])\n",
    "            # Ensure bounds\n",
    "            point_orig = np.maximum(point_orig, self.bounds[:, 0])\n",
    "            point_orig = np.minimum(point_orig, self.bounds[:, 1])\n",
    "            grid_orig[i] = point_orig\n",
    "        \n",
    "        # Predict function values\n",
    "        y_pred, sigma = self.gp_best.predict(self._preprocess_X(grid_orig), return_std=True)\n",
    "        if self.use_log_y:\n",
    "            y_pred = np.expm1(y_pred)\n",
    "            sigma = np.maximum((y_pred+1.0) * sigma, 1e-10)\n",
    "        \n",
    "        # Reshape for plotting\n",
    "        y_pred = y_pred.reshape(xx1.shape)\n",
    "        sigma = sigma.reshape(xx1.shape)\n",
    "        \n",
    "        # Create plots\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(32, 16)) # was 1,2; (16,7)\n",
    "        \n",
    "        # Mean prediction\n",
    "        cf1 = axs[0].contourf(xx1, xx2, y_pred, 50, cmap='viridis')\n",
    "        axs[0].scatter(X_pca[:, 0], X_pca[:, 1], c='r', s=50, marker='o')\n",
    "        \n",
    "        # Highlight best point\n",
    "        best_pca = pca.transform(self.best_x.reshape(1, -1))\n",
    "        axs[0].scatter(best_pca[:, 0], best_pca[:, 1], c='g', s=100, marker='*')\n",
    "        \n",
    "        # Show the different candidates as well\n",
    "        df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "        for index, row in df.iterrows():\n",
    "            best_pca = pca.transform(row['Candidate'].reshape(1, -1))\n",
    "            axs[0].scatter(best_pca[:, 0], best_pca[:, 1], c='b', s=100, marker='+')\n",
    "            axs[0].text(best_pca[:, 0], best_pca[:, 1], row['Method'], fontsize=6, ha='right', va='bottom')\n",
    "        \n",
    "        axs[0].set_xlabel(f'PCA Component 1')\n",
    "        axs[0].set_ylabel(f'PCA Component 2')\n",
    "        axs[0].set_title('GP Mean Prediction (PCA Space)')\n",
    "        plt.colorbar(cf1, ax=axs[0])\n",
    "        \n",
    "        # Uncertainty\n",
    "        cf2 = axs[1].contourf(xx1, xx2, sigma, 50, cmap='plasma')\n",
    "        axs[1].scatter(X_pca[:, 0], X_pca[:, 1], c='r', s=50, marker='o')\n",
    "        axs[1].set_xlabel(f'PCA Component 1')\n",
    "        axs[1].set_ylabel(f'PCA Component 2')\n",
    "        axs[1].set_title('GP Prediction Uncertainty (PCA Space)')\n",
    "        plt.colorbar(cf2, ax=axs[1])\n",
    "        \n",
    "        # Highlight best point\n",
    "        best_pca = pca.transform(self.best_x.reshape(1, -1))\n",
    "        axs[1].scatter(best_pca[:, 0], best_pca[:, 1], c='g', s=100, marker='*')\n",
    "        \n",
    "        # Show the different candidates as well\n",
    "        df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "        for index, row in df.iterrows():\n",
    "            best_pca = pca.transform(row['Candidate'].reshape(1, -1))\n",
    "            axs[1].scatter(best_pca[:, 0], best_pca[:, 1], c='b', s=100, marker='+')\n",
    "            axs[1].text(best_pca[:, 0], best_pca[:, 1], row['Method'], fontsize=6, ha='right', va='bottom')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    def plot_parallel_coordinates(self):\n",
    "        fig = px.parallel_coordinates(self.df,color='y',color_continuous_scale='plasma',\n",
    "                                  color_continuous_midpoint=(self.df['y'].max()+self.df['y'].min())/2)\n",
    "        return fig\n",
    "\n",
    "    def plot_parallel_coordinates_with_candidates(self):\n",
    "        \"\"\"\n",
    "        Create a parallel coordinates plot to visualize candidates and observations\n",
    "        \n",
    "        Args:\n",
    "            candidate_points: Candidate points to highlight in the plot\n",
    "        \"\"\"\n",
    "        X_train_np = self.X\n",
    "        y_train_np = self.y\n",
    "\n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Set up dimension names and positions\n",
    "        dimensions = [f'X{i+1}' for i in range(self.n_dim)]\n",
    "        x = list(range(len(dimensions)))\n",
    "        \n",
    "        # Normalize y values for color mapping\n",
    "        norm = plt.Normalize(y_train_np.min(), y_train_np.max())\n",
    "        cmap = plt.cm.plasma # viridis\n",
    "        \n",
    "        # Plot observations\n",
    "        for i, row in enumerate(X_train_np):\n",
    "            ax.plot(x, row, 'o-', c=cmap(norm(y_train_np[i])), alpha=0.7)\n",
    "        \n",
    "        markers = ['*', 's', 'D', '^', 'v']\n",
    "        df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "        for index, row in df.iterrows():\n",
    "            cand = row['Candidate']\n",
    "            # Plot candidates with different line styles\n",
    "            marker = markers[i % len(markers)]\n",
    "            ax.plot(x, cand, marker, markersize=10, label=row['Method'])\n",
    "            ax.plot(x, cand, '--', linewidth=2)\n",
    "        \n",
    "        # Set up axes\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(dimensions)\n",
    "        ax.set_xlim(min(x)-0.5, max(x)+0.5)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Add legend and colorbar\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper right', fontsize='small')\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        plt.colorbar(sm, ax=ax, label='Function Value')\n",
    "        \n",
    "        plt.title('Parallel Coordinates Plot of Observations and Candidates')\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def plot_pca(self, n_components=2):\n",
    "        \"\"\"\n",
    "        Visualize the data and candidates in a reduced dimensionality space using PCA\n",
    "        \n",
    "        Args:\n",
    "            n_components: Number of PCA components to use (default: 2)\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.decomposition import PCA\n",
    "        \n",
    "        # Get numpy arrays for easier handling\n",
    "        X_train_np = self.X\n",
    "        y_train_np = self.y\n",
    "\n",
    "        # Auto-determine n_components if not specified or too large\n",
    "        if n_components is None or n_components > min(X_train_np.shape):\n",
    "            n_components = min(X_train_np.shape[0], X_train_np.shape[1])\n",
    "\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_pca = pca.fit_transform(X_train_np)\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # Plot 2D PCA projection\n",
    "        if n_components >= 2:\n",
    "            ax1 = fig.add_subplot(221)\n",
    "            scatter = ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train_np, \n",
    "                       cmap='viridis', alpha=0.7, s=50)\n",
    "            \n",
    "            # Add candidates\n",
    "            df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "            for index, row in df.iterrows():\n",
    "                cand = pca.transform(row['Candidate'].reshape(1, -1))\n",
    "                ax1.scatter(cand[0][0], cand[0][1], color=f'C{index+1}', marker='*', s=200, \n",
    "                           label=row['Method'])\n",
    "                \n",
    "            # Add labels and legend\n",
    "            ax1.set_title('PCA Projection (PC1 vs PC2)')\n",
    "            ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "            ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "            ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper right', fontsize='small')\n",
    "            plt.colorbar(scatter, ax=ax1, label='Function Value')\n",
    "        \n",
    "        # Plot 3D PCA projection if we have at least 3 components\n",
    "        if n_components >= 3:\n",
    "            ax2 = fig.add_subplot(222, projection='3d')\n",
    "            scatter3d = ax2.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                         c=y_train_np, cmap='viridis', alpha=0.7, s=50)\n",
    "            \n",
    "            # Add candidates\n",
    "            df = self.candidates_df.reset_index()  # make sure indexes pair with number of rows\n",
    "            for index, row in df.iterrows():\n",
    "                cand = pca.transform(row['Candidate'].reshape(1, -1))\n",
    "                ax2.scatter(cand[0][0], cand[0][1], cand[0][2], color=f'C{index+1}', marker='*', s=200,\n",
    "                           label=row['Method'])\n",
    "                \n",
    "            # Add labels\n",
    "            ax2.set_title('3D PCA Projection')\n",
    "            ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "            ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "            ax2.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})')\n",
    "        \n",
    "        # Plot explained variance\n",
    "        ax3 = fig.add_subplot(223)\n",
    "        components = range(1, n_components+1)\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "        cumulative_variance = np.cumsum(explained_variance)\n",
    "        \n",
    "        ax3.bar(components, explained_variance, alpha=0.7, label='Individual')\n",
    "        ax3.step(components, cumulative_variance, where='mid', \n",
    "                 label='Cumulative', color='red')\n",
    "        ax3.axhline(y=0.95, linestyle='--', color='green', alpha=0.7, \n",
    "                    label='95% Explained Variance')\n",
    "        ax3.set_title('Explained Variance by PCA Components')\n",
    "        ax3.set_xlabel('Principal Components')\n",
    "        ax3.set_ylabel('Explained Variance Ratio')\n",
    "        ax3.set_xticks(components)\n",
    "        ax3.legend()\n",
    "        \n",
    "        # Component loadings plot\n",
    "        ax4 = fig.add_subplot(224)\n",
    "        features = [f'X{i+1}' for i in range(self.n_dim)]\n",
    "        loadings = pca.components_\n",
    "        \n",
    "        # Show top components as heatmap\n",
    "        show_n = min(5, n_components)  # Show at most 5 components\n",
    "        im = ax4.imshow(loadings[:show_n, :], aspect='auto', cmap='coolwarm')\n",
    "        \n",
    "        # Add labels\n",
    "        ax4.set_title('PCA Component Loadings')\n",
    "        ax4.set_xlabel('Input Features')\n",
    "        ax4.set_ylabel('Principal Components')\n",
    "        ax4.set_yticks(range(show_n))\n",
    "        ax4.set_yticklabels([f'PC{i+1}' for i in range(show_n)])\n",
    "        \n",
    "        # Only show feature labels if there aren't too many\n",
    "        if self.n_dim <= 20:\n",
    "            ax4.set_xticks(range(self.n_dim))\n",
    "            ax4.set_xticklabels(features, rotation=90)\n",
    "        else:\n",
    "            ax4.set_xticks([])\n",
    "        \n",
    "        plt.colorbar(im, ax=ax4)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def plot_partial_dependence_gpr(self, dims=None, resolution=20, figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Create partial dependence plots for scikit-learn GP to show how each input dimension \n",
    "        affects the predicted output while averaging over all other dimensions.\n",
    "        \n",
    "        Properly handles feature engineering by applying preprocessing to inputs.\n",
    "        \n",
    "        Args:\n",
    "            dims: Which dimensions to plot (None for all original dimensions)\n",
    "            resolution: Number of points to evaluate along each dimension\n",
    "            figsize: Size of the resulting figure\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'gp_best') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"GP model not fitted or no data available\")\n",
    "        \n",
    "        # If dims not specified, use all original dimensions\n",
    "        if dims is None:\n",
    "            dims = list(range(self.n_dim))\n",
    "        \n",
    "        n_dims_to_plot = len(dims)\n",
    "        nSubDims = int(np.ceil(np.sqrt(n_dims_to_plot)))\n",
    "        fig, axes = plt.subplots(nSubDims, nSubDims, figsize=figsize)\n",
    "        \n",
    "        if n_dims_to_plot == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        # Create a grid for each dimension\n",
    "        for i, dim_idx in enumerate(dims):\n",
    "            ax = axes[int(i/nSubDims)][i%nSubDims]\n",
    "            param_name = self.param_names[dim_idx] if hasattr(self, 'param_names') else f\"X{dim_idx}\"\n",
    "            \n",
    "            # Generate points along this dimension\n",
    "            x_vals = np.linspace(self.bounds[dim_idx][0], self.bounds[dim_idx][1], resolution)\n",
    "            \n",
    "            # For each point, create samples that vary only this dimension\n",
    "            mean_predictions = []\n",
    "            std_predictions = []\n",
    "            \n",
    "            for x_val in x_vals:\n",
    "                # Create samples with this fixed value for dimension dim_idx\n",
    "                X_samples = np.tile(np.mean(self.X, axis=0), (resolution, 1))\n",
    "                X_samples[:, dim_idx] = x_val\n",
    "                \n",
    "                # Apply feature engineering to get the preprocessed inputs\n",
    "                X_processed = self._preprocess_X(X_samples)\n",
    "                \n",
    "                # Get predictions with scikit-learn's GP\n",
    "                means, stds = self.gp_best.predict(X_processed, return_std=True)\n",
    "                \n",
    "                # If using log transform, convert back\n",
    "                if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "                    means = np.expm1(means)\n",
    "                    stds = means * stds  # Approximate transformation of std dev\n",
    "                \n",
    "                mean_predictions.append(np.mean(means))\n",
    "                std_predictions.append(np.mean(stds))\n",
    "            \n",
    "            # Plot mean prediction\n",
    "            ax.plot(x_vals, mean_predictions, 'b-', label='Mean prediction')\n",
    "            \n",
    "            # Plot confidence intervals\n",
    "            ax.fill_between(\n",
    "                x_vals,\n",
    "                np.array(mean_predictions) - 2 * np.array(std_predictions),\n",
    "                np.array(mean_predictions) + 2 * np.array(std_predictions),\n",
    "                alpha=0.3, color='b'\n",
    "            )\n",
    "            \n",
    "            # Plot observed data points projected onto this dimension\n",
    "            y_to_plot = self.y  # Use original y values for plotting\n",
    "            ax.scatter(self.X[:, dim_idx], y_to_plot, c='red', marker='o', alpha=0.5, label='Observations')\n",
    "            \n",
    "            ax.set_xlabel(param_name)\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('Target value')\n",
    "            ax.set_title(f'Partial Dependence for {param_name}')\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_expected_improvement_landscape_gpr(self, dims=(0, 1), resolution=50, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Visualize the Expected Improvement acquisition function landscape using scikit-learn's GP.\n",
    "        \n",
    "        Properly handles feature engineering by applying preprocessing to inputs.\n",
    "        \n",
    "        Args:\n",
    "            dims: Tuple of two dimensions to visualize (from original dimensions)\n",
    "            resolution: Grid resolution for each dimension\n",
    "            figsize: Size of the resulting figure\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'gp_best') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"GP model not fitted or no data available\")\n",
    "            \n",
    "        if len(dims) != 2:\n",
    "            raise ValueError(\"dims must specify exactly two dimensions to plot\")\n",
    "            \n",
    "        # Create a 2D grid for the specified dimensions\n",
    "        x1 = np.linspace(self.bounds[dims[0]][0], self.bounds[dims[0]][1], resolution)\n",
    "        x2 = np.linspace(self.bounds[dims[1]][0], self.bounds[dims[1]][1], resolution)\n",
    "        x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "        \n",
    "        # Prepare grid points for all dimensions, using mean values for non-visualized dimensions\n",
    "        X_mean = np.mean(self.X, axis=0)\n",
    "        X_grid = np.tile(X_mean, (resolution*resolution, 1))\n",
    "        flat_grid = np.vstack([x1_grid.flatten(), x2_grid.flatten()]).T\n",
    "        X_grid[:, dims[0]] = flat_grid[:, 0]\n",
    "        X_grid[:, dims[1]] = flat_grid[:, 1]\n",
    "        \n",
    "        # Apply feature engineering to get preprocessed inputs\n",
    "        X_processed = self._preprocess_X(X_grid)\n",
    "        \n",
    "        # Current best observed value\n",
    "        if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "            best_y_for_ei = np.max(self.y_log)\n",
    "        else:\n",
    "            best_y_for_ei = np.max(self.y)\n",
    "        \n",
    "        # Get posterior from scikit-learn GP model\n",
    "        mean, std = self.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # If using log transform and plotting in original space, convert back\n",
    "        if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "            mean = np.expm1(mean)\n",
    "            std = mean * std  # Approximate transformation of std dev\n",
    "            best_y_for_ei = np.expm1(best_y_for_ei)\n",
    "        \n",
    "        # Calculate Expected Improvement\n",
    "        imp = mean - best_y_for_ei\n",
    "        Z = imp * norm.cdf(imp / (std + 1e-9)) + std * norm.pdf(imp / (std + 1e-9))\n",
    "        Z = Z.reshape(resolution, resolution)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot EI landscape\n",
    "        contour = ax.contourf(x1_grid, x2_grid, Z, levels=50, cmap='viridis')\n",
    "        plt.colorbar(contour, ax=ax, label='Expected Improvement')\n",
    "        \n",
    "        # Plot observed points\n",
    "        scatter = ax.scatter(\n",
    "            self.X[:, dims[0]],\n",
    "            self.X[:, dims[1]],\n",
    "            c=self.y,  # Use original y values for coloring\n",
    "            cmap='plasma', \n",
    "            s=100,\n",
    "            edgecolor='k'\n",
    "        )\n",
    "        plt.colorbar(scatter, ax=ax, label='Observed Values')\n",
    "        \n",
    "        # Highlight the best point\n",
    "        best_idx = np.argmax(self.y)\n",
    "        ax.scatter(\n",
    "            self.X[best_idx, dims[0]],\n",
    "            self.X[best_idx, dims[1]],\n",
    "            s=200,\n",
    "            facecolors='none',\n",
    "            edgecolors='red',\n",
    "            linewidth=3,\n",
    "            label='Best observation'\n",
    "        )\n",
    "        \n",
    "        # Labels and title\n",
    "        dim1_name = self.param_names[dims[0]] if hasattr(self, 'param_names') else f\"X{dims[0]}\"\n",
    "        dim2_name = self.param_names[dims[1]] if hasattr(self, 'param_names') else f\"X{dims[1]}\"\n",
    "        \n",
    "        ax.set_xlabel(dim1_name)\n",
    "        ax.set_ylabel(dim2_name)\n",
    "        ax.set_title(f'Expected Improvement Landscape')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_partial_dependence_botorch(self, dims=None, resolution=20, figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Create partial dependence plots for BoTorch model to show how each input dimension \n",
    "        affects the predicted output while averaging over all other dimensions.\n",
    "        \n",
    "        This method correctly leverages the input_transform already configured in the BoTorch model.\n",
    "        \n",
    "        Args:\n",
    "            dims: Which dimensions to plot (None for all original dimensions)\n",
    "            resolution: Number of points to evaluate along each dimension\n",
    "            figsize: Size of the resulting figure\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'botorch_gp') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"BoTorch model not fitted or no data available\")\n",
    "        \n",
    "        # If dims not specified, use all original dimensions (not feature dimensions)\n",
    "        if dims is None:\n",
    "            dims = list(range(self.n_dim))  # Only use original dimensions, not engineered features\n",
    "        \n",
    "        n_dims_to_plot = len(dims)\n",
    "        nSubDims = int(np.ceil(np.sqrt(n_dims_to_plot)))\n",
    "        fig, axes = plt.subplots(nSubDims, nSubDims, figsize=figsize)\n",
    "        \n",
    "        if n_dims_to_plot == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Get device\n",
    "        device = self.device if hasattr(self, 'device') else None\n",
    "        \n",
    "        # Create a grid for each dimension\n",
    "        for i, dim_idx in enumerate(dims):\n",
    "            ax = axes[int(i/nSubDims)][i%nSubDims]\n",
    "            param_name = self.param_names[dim_idx] if hasattr(self, 'param_names') else f\"X{dim_idx}\"\n",
    "            \n",
    "            # Generate points along this dimension\n",
    "            x_vals = np.linspace(self.bounds[dim_idx][0], self.bounds[dim_idx][1], resolution)\n",
    "            \n",
    "            # For each point, create samples that vary only this dimension\n",
    "            mean_predictions = []\n",
    "            std_predictions = []\n",
    "            \n",
    "            # Get base point as mean of original X (not preprocessed)\n",
    "            X_mean = np.mean(self.X, axis=0)\n",
    "            \n",
    "            for x_val in x_vals:\n",
    "                # Create samples with this fixed value for dimension dim_idx\n",
    "                X_samples = np.tile(X_mean, (1, 1))  # Start with a single sample\n",
    "                X_samples[0, dim_idx] = x_val\n",
    "                \n",
    "                # Convert to PyTorch tensor\n",
    "                X_tensor = torch.tensor(X_samples, dtype=torch.float64, device=device)\n",
    "                \n",
    "                # Use the model directly (it will apply input_transform internally)\n",
    "                with torch.no_grad():\n",
    "                    posterior = self.botorch_gp.posterior(X_tensor)\n",
    "                    means = posterior.mean.cpu().numpy().flatten()\n",
    "                    variances = posterior.variance.cpu().numpy().flatten()\n",
    "                \n",
    "                stds = np.sqrt(variances)\n",
    "                \n",
    "                mean_predictions.append(means[0])  # Take just the first (and only) value\n",
    "                std_predictions.append(stds[0])\n",
    "            \n",
    "            # Plot mean prediction\n",
    "            ax.plot(x_vals, mean_predictions, 'b-', label='Mean prediction')\n",
    "            \n",
    "            # Plot confidence intervals\n",
    "            ax.fill_between(\n",
    "                x_vals,\n",
    "                np.array(mean_predictions) - 2 * np.array(std_predictions),\n",
    "                np.array(mean_predictions) + 2 * np.array(std_predictions),\n",
    "                alpha=0.3, color='b'\n",
    "            )\n",
    "            \n",
    "            # Plot observed data points projected onto this dimension\n",
    "            y_to_plot = self.y  # Use original y values for plotting\n",
    "            ax.scatter(self.X[:, dim_idx], y_to_plot, c='red', marker='o', alpha=0.5, label='Observations')\n",
    "            \n",
    "            ax.set_xlabel(param_name)\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('Target value')\n",
    "            ax.set_title(f'Partial Dependence for {param_name}')\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_expected_improvement_landscape_botorch(self, dims=(0, 1), resolution=50, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Visualize the Expected Improvement acquisition function landscape using a BoTorch model.\n",
    "        \n",
    "        This method correctly leverages the input_transform already configured in the BoTorch model.\n",
    "        \n",
    "        Args:\n",
    "            dims: Tuple of two dimensions to visualize (from original dimensions)\n",
    "            resolution: Grid resolution for each dimension\n",
    "            figsize: Size of the resulting figure\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'botorch_gp') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"BoTorch model not fitted or no data available\")\n",
    "            \n",
    "        if len(dims) != 2:\n",
    "            raise ValueError(\"dims must specify exactly two dimensions to plot\")\n",
    "            \n",
    "        # Create a 2D grid for the specified dimensions\n",
    "        x1 = np.linspace(self.bounds[dims[0]][0], self.bounds[dims[0]][1], resolution)\n",
    "        x2 = np.linspace(self.bounds[dims[1]][0], self.bounds[dims[1]][1], resolution)\n",
    "        x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "        \n",
    "        # Get mean values for non-visualized dimensions\n",
    "        X_mean = np.mean(self.X, axis=0)\n",
    "        \n",
    "        # Get device\n",
    "        device = self.device if hasattr(self, 'device') else None\n",
    "        \n",
    "        # Current best observed value (in appropriate scale)\n",
    "        best_y_for_ei = torch.tensor(np.max(self.y), dtype=torch.float64, device=device)\n",
    "        \n",
    "        # Initialize arrays for EI values\n",
    "        Z = np.zeros((resolution, resolution))\n",
    "        \n",
    "        # Evaluate EI at each grid point - do it one by one to avoid memory issues\n",
    "        for i in range(resolution):\n",
    "            for j in range(resolution):\n",
    "                # Create a single test point at this grid location\n",
    "                X_test = X_mean.copy().reshape(1, -1)\n",
    "                X_test[0, dims[0]] = x1_grid[i, j]\n",
    "                X_test[0, dims[1]] = x2_grid[i, j]\n",
    "                \n",
    "                # Convert to torch tensor\n",
    "                X_tensor = torch.tensor(X_test, dtype=torch.float64, device=device)\n",
    "                \n",
    "                # Get posterior from the model (which will apply input_transform internally)\n",
    "                with torch.no_grad():\n",
    "                    posterior = self.botorch_gp.posterior(X_tensor)\n",
    "                    mean = posterior.mean.cpu().numpy()[0, 0]\n",
    "                    std = np.sqrt(posterior.variance.cpu().numpy()[0, 0])\n",
    "                \n",
    "                best_y_np = best_y_for_ei.cpu().numpy()\n",
    "                \n",
    "                # Calculate Expected Improvement\n",
    "                imp = mean - best_y_np\n",
    "                z_val = imp * norm.cdf(imp / (std + 1e-9)) + std * norm.pdf(imp / (std + 1e-9))\n",
    "                Z[i, j] = z_val\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot EI landscape\n",
    "        contour = ax.contourf(x1_grid, x2_grid, Z, levels=50, cmap='viridis')\n",
    "        plt.colorbar(contour, ax=ax, label='Expected Improvement')\n",
    "        \n",
    "        # Plot observed points\n",
    "        scatter = ax.scatter(\n",
    "            self.X[:, dims[0]],\n",
    "            self.X[:, dims[1]],\n",
    "            c=self.y,  # Use original y values for coloring\n",
    "            cmap='plasma', \n",
    "            s=100,\n",
    "            edgecolor='k'\n",
    "        )\n",
    "        plt.colorbar(scatter, ax=ax, label='Observed Values')\n",
    "        \n",
    "        # Highlight the best point\n",
    "        best_idx = np.argmax(self.y)\n",
    "        ax.scatter(\n",
    "            self.X[best_idx, dims[0]],\n",
    "            self.X[best_idx, dims[1]],\n",
    "            s=200,\n",
    "            facecolors='none',\n",
    "            edgecolors='red',\n",
    "            linewidth=3,\n",
    "            label='Best observation'\n",
    "        )\n",
    "        \n",
    "        # Labels and title\n",
    "        dim1_name = self.param_names[dims[0]] if hasattr(self, 'param_names') else f\"X{dims[0]}\"\n",
    "        dim2_name = self.param_names[dims[1]] if hasattr(self, 'param_names') else f\"X{dims[1]}\"\n",
    "        \n",
    "        ax.set_xlabel(dim1_name)\n",
    "        ax.set_ylabel(dim2_name)\n",
    "        ax.set_title(f'Expected Improvement Landscape')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "            \n",
    "    def plot_decision_boundary_botorch(self, threshold_percentile=75, dims=(0, 1), resolution=50, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Create a decision boundary plot showing regions above/below a performance threshold\n",
    "        using a BoTorch model.\n",
    "        \n",
    "        This method correctly leverages the input_transform already configured in the BoTorch model.\n",
    "        \n",
    "        Args:\n",
    "            threshold_percentile: Percentile of observed performance to use as threshold (0-100)\n",
    "            dims: Tuple of two dimensions to visualize\n",
    "            resolution: Grid resolution for each dimension\n",
    "            figsize: Size of the resulting figure\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'botorch_gp') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"BoTorch model not fitted or no data available\")\n",
    "            \n",
    "        if len(dims) != 2:\n",
    "            raise ValueError(\"dims must specify exactly two dimensions to plot\")\n",
    "            \n",
    "        # Create a 2D grid for the specified dimensions\n",
    "        x1 = np.linspace(self.bounds[dims[0]][0], self.bounds[dims[0]][1], resolution)\n",
    "        x2 = np.linspace(self.bounds[dims[1]][0], self.bounds[dims[1]][1], resolution)\n",
    "        x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "        \n",
    "        # Get mean values for non-visualized dimensions\n",
    "        X_mean = np.mean(self.X, axis=0)\n",
    "        \n",
    "        # Get device\n",
    "        device = self.device if hasattr(self, 'device') else None\n",
    "        \n",
    "        # Calculate the threshold value based on percentile of observed values\n",
    "        threshold = np.percentile(self.y, threshold_percentile)\n",
    "        \n",
    "        threshold_for_prediction = threshold\n",
    "        \n",
    "        # Initialize probability grid\n",
    "        prob_grid = np.zeros((resolution, resolution))\n",
    "        \n",
    "        # Evaluate probability at each grid point - do it one by one\n",
    "        for i in range(resolution):\n",
    "            for j in range(resolution):\n",
    "                # Create a single test point at this grid location\n",
    "                X_test = X_mean.copy().reshape(1, -1)\n",
    "                X_test[0, dims[0]] = x1_grid[i, j]\n",
    "                X_test[0, dims[1]] = x2_grid[i, j]\n",
    "                \n",
    "                # Convert to torch tensor\n",
    "                X_tensor = torch.tensor(X_test, dtype=torch.float64, device=device)\n",
    "                \n",
    "                # Get posterior from the model (which will apply input_transform internally)\n",
    "                with torch.no_grad():\n",
    "                    posterior = self.botorch_gp.posterior(X_tensor)\n",
    "                    mean = posterior.mean.cpu().numpy()[0, 0]\n",
    "                    std = np.sqrt(posterior.variance.cpu().numpy()[0, 0])\n",
    "                \n",
    "                threshold_for_prob = threshold_for_prediction\n",
    "                \n",
    "                # Calculate probability of being above threshold\n",
    "                prob_above = 1 - norm.cdf((threshold_for_prob - mean) / (std + 1e-9))\n",
    "                prob_grid[i, j] = prob_above\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot probability contour\n",
    "        contour = ax.contourf(x1_grid, x2_grid, prob_grid, levels=np.linspace(0, 1, 21), \n",
    "                           cmap='RdYlGn', alpha=0.7)\n",
    "        plt.colorbar(contour, ax=ax, label=f'Probability of exceeding {threshold_percentile}th percentile')\n",
    "        \n",
    "        # Add contour lines\n",
    "        contour_lines = ax.contour(x1_grid, x2_grid, prob_grid, levels=[0.1, 0.25, 0.5, 0.75, 0.9], \n",
    "                                colors='k', linestyles='--', linewidths=1)\n",
    "        plt.clabel(contour_lines, inline=True, fontsize=8)\n",
    "        \n",
    "        # Add the threshold value\n",
    "        threshold_text = f'Threshold value: {threshold:.4f}'\n",
    "        ax.text(0.02, 0.02, threshold_text, transform=ax.transAxes, \n",
    "             bbox=dict(facecolor='white', alpha=0.7, boxstyle='round'))\n",
    "        \n",
    "        # Plot observed points colored by their actual values\n",
    "        scatter = ax.scatter(\n",
    "            self.X[:, dims[0]],\n",
    "            self.X[:, dims[1]],\n",
    "            c=self.y > threshold,\n",
    "            cmap='RdYlGn',\n",
    "            s=100,\n",
    "            edgecolor='k',\n",
    "            alpha=1.0\n",
    "        )\n",
    "        \n",
    "        # Highlight the best point\n",
    "        best_idx = np.argmax(self.y)\n",
    "        ax.scatter(\n",
    "            self.X[best_idx, dims[0]],\n",
    "            self.X[best_idx, dims[1]],\n",
    "            s=200,\n",
    "            facecolors='none',\n",
    "            edgecolors='blue',\n",
    "            linewidth=3,\n",
    "            label='Best observation'\n",
    "        )\n",
    "        \n",
    "        # Labels and title\n",
    "        dim1_name = self.param_names[dims[0]] if hasattr(self, 'param_names') else f\"X{dims[0]}\"\n",
    "        dim2_name = self.param_names[dims[1]] if hasattr(self, 'param_names') else f\"X{dims[1]}\"\n",
    "        \n",
    "        ax.set_xlabel(dim1_name)\n",
    "        ax.set_ylabel(dim2_name)\n",
    "        ax.set_title(f'Decision Boundary: P(y > {threshold:.4f})')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def plot_shap_values_botorch(self, num_samples=100):\n",
    "        \"\"\"\n",
    "        Create SHAP plots for BoTorch model with robust error handling.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'botorch_gp') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"BoTorch model not fitted or no data available\")\n",
    "        \n",
    "        try:\n",
    "            import shap\n",
    "            \n",
    "            # Define a safer model prediction function\n",
    "            def model_predict(X):\n",
    "                results = []\n",
    "                # Process one point at a time to avoid batch size issues\n",
    "                for i in range(len(X)):\n",
    "                    x = X[i:i+1]  # Keep as 2D array with one row\n",
    "                    tensor_x = torch.tensor(x, dtype=torch.float64)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        try:\n",
    "                            pred = self.botorch_gp.posterior(tensor_x).mean.cpu().numpy().item()\n",
    "                        except Exception:\n",
    "                            # If prediction fails, return mean of training data\n",
    "                            pred = np.mean(self.y)\n",
    "                            \n",
    "                    results.append(pred)\n",
    "                return np.array(results)\n",
    "            \n",
    "            # Sample a manageable subset of data points (max 50)\n",
    "            n_samples = min(50, len(self.X))\n",
    "            sample_idx = np.random.choice(len(self.X), n_samples, replace=False)\n",
    "            X_sample = self.X[sample_idx]\n",
    "            \n",
    "            # Create background data (max 100 points)\n",
    "            background_size = min(100, len(self.X))\n",
    "            background_idx = np.random.choice(len(self.X), background_size, replace=False)\n",
    "            background_data = self.X[background_idx]\n",
    "            \n",
    "            # Initialize the explainer with fewer samples if needed\n",
    "            explainer = shap.KernelExplainer(model_predict, background_data)\n",
    "            \n",
    "            # Calculate SHAP values with a small nsamples for speed\n",
    "            shap_values = explainer.shap_values(X_sample, nsamples=100)\n",
    "            \n",
    "            # Create feature names\n",
    "            feature_names = self.param_names if hasattr(self, 'param_names') else [f\"X{i}\" for i in range(self.X.shape[1])]\n",
    "            \n",
    "            # Create bar plot (more robust than the default summary plot)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            abs_shap_values = np.abs(shap_values).mean(0)\n",
    "            feature_importance = pd.DataFrame(list(zip(feature_names, abs_shap_values)), \n",
    "                                             columns=['Feature', 'SHAP Importance'])\n",
    "            feature_importance.sort_values('SHAP Importance', ascending=False, inplace=True)\n",
    "            \n",
    "            plt.barh(feature_importance['Feature'], feature_importance['SHAP Importance'])\n",
    "            plt.xlabel('Mean |SHAP Value|')\n",
    "            plt.title('Feature Importance (SHAP) - BoTorch Model')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            summary_fig = plt.gcf()\n",
    "            \n",
    "            # Create individual dependence plots\n",
    "            dependence_figs = []\n",
    "            for i in range(len(feature_names)):\n",
    "                # Find the index of the feature in the original data\n",
    "                if isinstance(feature_names, list):\n",
    "                    feature_idx = feature_names.index(feature_importance['Feature'].iloc[i])\n",
    "                else:\n",
    "                    feature_idx = i\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.scatter(X_sample[:, feature_idx], shap_values[:, feature_idx], \n",
    "                           c=model_predict(X_sample), cmap='viridis')\n",
    "                plt.colorbar(label='Model output')\n",
    "                plt.xlabel(feature_importance['Feature'].iloc[i])\n",
    "                plt.ylabel(f'SHAP value for {feature_importance[\"Feature\"].iloc[i]}')\n",
    "                plt.title(f'SHAP Dependence Plot (BoTorch)')\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                dependence_figs.append(plt.gcf())\n",
    "            \n",
    "            return summary_fig, dependence_figs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in BoTorch SHAP calculation: {e}\")\n",
    "            # Return empty figures so we can continue without errors\n",
    "            empty_fig1 = plt.figure()\n",
    "            empty_fig2 = [plt.figure()]\n",
    "            return empty_fig1, empty_fig2\n",
    "            \n",
    "    def plot_decision_boundary_gpr(self, threshold_percentile=75, dims=(0, 1), resolution=50, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Create a decision boundary plot showing regions above/below a performance threshold\n",
    "        using scikit-learn's GP. Handles feature engineering and log transformations.\n",
    "        \n",
    "        Args:\n",
    "            threshold_percentile: Percentile of observed performance to use as threshold (0-100)\n",
    "            dims: Tuple of two dimensions to visualize\n",
    "            resolution: Grid resolution for each dimension\n",
    "            figsize: Size of the resulting figure\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'gp_best') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"GP model not fitted or no data available\")\n",
    "            \n",
    "        if len(dims) != 2:\n",
    "            raise ValueError(\"dims must specify exactly two dimensions to plot\")\n",
    "            \n",
    "        # Create a 2D grid for the specified dimensions\n",
    "        x1 = np.linspace(self.bounds[dims[0]][0], self.bounds[dims[0]][1], resolution)\n",
    "        x2 = np.linspace(self.bounds[dims[1]][0], self.bounds[dims[1]][1], resolution)\n",
    "        x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "        \n",
    "        # Prepare grid points for all dimensions, using mean values for non-visualized dimensions\n",
    "        X_mean = np.mean(self.X, axis=0)\n",
    "        X_grid = np.tile(X_mean, (resolution*resolution, 1))\n",
    "        flat_grid = np.vstack([x1_grid.flatten(), x2_grid.flatten()]).T\n",
    "        X_grid[:, dims[0]] = flat_grid[:, 0]\n",
    "        X_grid[:, dims[1]] = flat_grid[:, 1]\n",
    "        \n",
    "        # Apply feature engineering\n",
    "        X_processed = self._preprocess_X(X_grid)\n",
    "        \n",
    "        # Calculate the threshold value based on percentile of observed values\n",
    "        threshold = np.percentile(self.y, threshold_percentile)\n",
    "        \n",
    "        # For log-transformed models, we need the threshold in log space for prediction\n",
    "        if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "            threshold_for_prediction = np.log(threshold)\n",
    "        else:\n",
    "            threshold_for_prediction = threshold\n",
    "        \n",
    "        # Get predictions from scikit-learn GP model\n",
    "        mean, std = self.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # If using log transform and we want to display in original space, transform back\n",
    "        if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "            mean = np.expm1(mean)\n",
    "            std = mean * std  # Approximate transformation of std dev\n",
    "            threshold_for_prob = threshold  # Use original threshold for probability calc\n",
    "        else:\n",
    "            threshold_for_prob = threshold_for_prediction\n",
    "        \n",
    "        # Calculate probability of being above threshold\n",
    "        prob_above = 1 - norm.cdf((threshold_for_prob - mean) / (std + 1e-9))\n",
    "        prob_grid = prob_above.reshape(resolution, resolution)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot probability contour\n",
    "        contour = ax.contourf(x1_grid, x2_grid, prob_grid, levels=np.linspace(0, 1, 21), \n",
    "                           cmap='RdYlGn', alpha=0.7)\n",
    "        plt.colorbar(contour, ax=ax, label=f'Probability of exceeding {threshold_percentile}th percentile')\n",
    "        \n",
    "        # Add contour lines\n",
    "        contour_lines = ax.contour(x1_grid, x2_grid, prob_grid, levels=[0.1, 0.25, 0.5, 0.75, 0.9], \n",
    "                                colors='k', linestyles='--', linewidths=1)\n",
    "        plt.clabel(contour_lines, inline=True, fontsize=8)\n",
    "        \n",
    "        # Add the threshold value\n",
    "        threshold_text = f'Threshold value: {threshold:.4f}'\n",
    "        ax.text(0.02, 0.02, threshold_text, transform=ax.transAxes, \n",
    "             bbox=dict(facecolor='white', alpha=0.7, boxstyle='round'))\n",
    "        \n",
    "        # Plot observed points colored by their actual values\n",
    "        scatter = ax.scatter(\n",
    "            self.X[:, dims[0]],\n",
    "            self.X[:, dims[1]],\n",
    "            c=self.y > threshold,\n",
    "            cmap='RdYlGn',\n",
    "            s=100,\n",
    "            edgecolor='k',\n",
    "            alpha=1.0\n",
    "        )\n",
    "        \n",
    "        # Highlight the best point\n",
    "        best_idx = np.argmax(self.y)\n",
    "        ax.scatter(\n",
    "            self.X[best_idx, dims[0]],\n",
    "            self.X[best_idx, dims[1]],\n",
    "            s=200,\n",
    "            facecolors='none',\n",
    "            edgecolors='blue',\n",
    "            linewidth=3,\n",
    "            label='Best observation'\n",
    "        )\n",
    "        \n",
    "        # Labels and title\n",
    "        dim1_name = self.param_names[dims[0]] if hasattr(self, 'param_names') else f\"X{dims[0]}\"\n",
    "        dim2_name = self.param_names[dims[1]] if hasattr(self, 'param_names') else f\"X{dims[1]}\"\n",
    "        \n",
    "        ax.set_xlabel(dim1_name)\n",
    "        ax.set_ylabel(dim2_name)\n",
    "        ax.set_title(f'Decision Boundary: P(y > {threshold:.4f})')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_shap_values_gpr(self, num_samples=100):\n",
    "        \"\"\"\n",
    "        Create SHAP (SHapley Additive exPlanations) plots that handle sizing issues.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'gp_best') or not hasattr(self, 'X'):\n",
    "            raise AttributeError(\"GP model not fitted or no data available\")\n",
    "        \n",
    "        try:\n",
    "            # Define a wrapper function that works with both single and batched inputs\n",
    "            def model_predict(X):\n",
    "                # Ensure X is 2D\n",
    "                if X.ndim == 1:\n",
    "                    X = X.reshape(1, -1)\n",
    "                    \n",
    "                X_processed = self._preprocess_X(X)\n",
    "                predictions = self.gp_best.predict(X_processed)\n",
    "                \n",
    "                if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "                    predictions = np.expm1(predictions)\n",
    "                    \n",
    "                return predictions\n",
    "            \n",
    "            # Sample a manageable subset of data points (max 50)\n",
    "            n_samples = min(50, len(self.X))\n",
    "            sample_idx = np.random.choice(len(self.X), n_samples, replace=False)\n",
    "            X_sample = self.X[sample_idx]\n",
    "            \n",
    "            # Create background data (max 100 points)\n",
    "            background_size = min(100, len(self.X))\n",
    "            background_idx = np.random.choice(len(self.X), background_size, replace=False)\n",
    "            background_data = self.X[background_idx]\n",
    "            \n",
    "            # Initialize the explainer\n",
    "            explainer = shap.KernelExplainer(model_predict, background_data)\n",
    "            \n",
    "            # Calculate SHAP values - handle potential shape issues\n",
    "            shap_values = explainer.shap_values(X_sample)\n",
    "            \n",
    "            # Create feature names\n",
    "            feature_names = self.param_names if hasattr(self, 'param_names') else [f\"X{i}\" for i in range(self.X.shape[1])]\n",
    "            \n",
    "            # Create bar plot (more robust than the default summary plot)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            abs_shap_values = np.abs(shap_values).mean(0)\n",
    "            feature_importance = pd.DataFrame(list(zip(feature_names, abs_shap_values)), \n",
    "                                             columns=['Feature', 'SHAP Importance'])\n",
    "            feature_importance.sort_values('SHAP Importance', ascending=False, inplace=True)\n",
    "            \n",
    "            plt.barh(feature_importance['Feature'], feature_importance['SHAP Importance'])\n",
    "            plt.xlabel('Mean |SHAP Value|')\n",
    "            plt.title('Feature Importance (SHAP)')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            summary_fig = plt.gcf()\n",
    "            \n",
    "            # Create individual dependence plots\n",
    "            dependence_figs = []\n",
    "            for i in range(len(feature_names)):\n",
    "                # Find the index of the feature in the original data\n",
    "                if isinstance(feature_names, list):\n",
    "                    feature_idx = feature_names.index(feature_importance['Feature'].iloc[i])\n",
    "                else:\n",
    "                    feature_idx = i\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.scatter(X_sample[:, feature_idx], shap_values[:, feature_idx], \n",
    "                           c=model_predict(X_sample).flatten(), cmap='viridis')\n",
    "                plt.colorbar(label='Model output')\n",
    "                plt.xlabel(feature_importance['Feature'].iloc[i])\n",
    "                plt.ylabel(f'SHAP value for {feature_importance[\"Feature\"].iloc[i]}')\n",
    "                plt.title(f'SHAP Dependence Plot')\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                dependence_figs.append(plt.gcf())\n",
    "            \n",
    "            return summary_fig, dependence_figs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in SHAP calculation: {e}\")\n",
    "            # Return empty figures so we can continue without errors\n",
    "            empty_fig1 = plt.figure()\n",
    "            empty_fig2 = [plt.figure()]\n",
    "            return empty_fig1, empty_fig2\n",
    "    \n",
    "    def plot_tsne_umap(self, method='tsne', figsize=(12, 10), target_scaling='minmax', perp=30):\n",
    "        \"\"\"\n",
    "        Create dimensionality reduction plots using t-SNE or UMAP.\n",
    "        \n",
    "        Args:\n",
    "            method: Either 'tsne', 'umap', or 'mds'\n",
    "            figsize: Size of the resulting figure\n",
    "            target_scaling: How to scale target values for colors ('minmax' or 'normalized')\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'X') or not hasattr(self, 'y'):\n",
    "            raise AttributeError(\"No data available\")\n",
    "        \n",
    "        # Scale target values for coloring\n",
    "        if target_scaling == 'minmax':\n",
    "            y_color = (self.y - np.min(self.y)) / (np.max(self.y) - np.min(self.y) + 1e-10)\n",
    "        elif target_scaling == 'normalized':\n",
    "            y_color = (self.y - np.mean(self.y)) / (np.std(self.y) + 1e-10)\n",
    "        else:\n",
    "            y_color = self.y\n",
    "        \n",
    "        # Choose dimensionality reduction method\n",
    "        if method.lower() == 'tsne':\n",
    "            # 2D t-SNE\n",
    "            tsne_2d = TSNE(n_components=2, perplexity=min(perp, len(self.X)-1), \n",
    "                        random_state=1, n_iter=1000)\n",
    "            X_tsne_2d = tsne_2d.fit_transform(self.X)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "            scatter = ax.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], \n",
    "                              c=y_color, cmap='viridis', s=100, alpha=0.8)\n",
    "            \n",
    "            # Highlight the best point\n",
    "            best_idx = np.argmax(self.y)\n",
    "            ax.scatter(X_tsne_2d[best_idx, 0], X_tsne_2d[best_idx, 1], \n",
    "                    s=200, facecolors='none', edgecolors='red', linewidth=3, \n",
    "                    label='Best observation')\n",
    "            \n",
    "            plt.colorbar(scatter, label='Normalized function value')\n",
    "            ax.set_title(f't-SNE Projection (Perplexity: {perp})')\n",
    "            ax.set_xlabel('t-SNE Dimension 1')\n",
    "            ax.set_ylabel('t-SNE Dimension 2')\n",
    "            ax.legend()                \n",
    "            plt.tight_layout()\n",
    "        elif method.lower() == 'umap':\n",
    "            # 2D UMAP\n",
    "            umap_2d = umap.UMAP(n_components=2, n_neighbors=min(15, len(self.X)-1), \n",
    "                             min_dist=0.1, random_state=1)\n",
    "            X_umap_2d = umap_2d.fit_transform(self.X)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "            scatter = ax.scatter(X_umap_2d[:, 0], X_umap_2d[:, 1], \n",
    "                              c=y_color, cmap='viridis', s=100, alpha=0.8)\n",
    "            \n",
    "            # Highlight the best point\n",
    "            best_idx = np.argmax(self.y)\n",
    "            ax.scatter(X_umap_2d[best_idx, 0], X_umap_2d[best_idx, 1], \n",
    "                    s=200, facecolors='none', edgecolors='red', linewidth=3, \n",
    "                    label='Best observation')\n",
    "            \n",
    "            plt.colorbar(scatter, label='Normalized function value')\n",
    "            ax.set_title('UMAP Projection')\n",
    "            ax.set_xlabel('UMAP Dimension 1')\n",
    "            ax.set_ylabel('UMAP Dimension 2')\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "        elif method.lower() == 'mds':\n",
    "            # 2D MDS\n",
    "            mds_2d = MDS(n_components=2, random_state=1)\n",
    "            X_mds_2d = mds_2d.fit_transform(self.X)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "            scatter = ax.scatter(X_mds_2d[:, 0], X_mds_2d[:, 1], \n",
    "                              c=y_color, cmap='viridis', s=100, alpha=0.8)\n",
    "            \n",
    "            # Highlight the best point\n",
    "            best_idx = np.argmax(self.y)\n",
    "            ax.scatter(X_mds_2d[best_idx, 0], X_mds_2d[best_idx, 1], \n",
    "                    s=200, facecolors='none', edgecolors='red', linewidth=3, \n",
    "                    label='Best observation')\n",
    "            \n",
    "            plt.colorbar(scatter, label='Normalized function value')\n",
    "            ax.set_title('MDS Projection')\n",
    "            ax.set_xlabel('MDS Dimension 1')\n",
    "            ax.set_ylabel('MDS Dimension 2')\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'tsne', 'umap', or 'mds'\")\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "    def plot_feature_importance(self, figsize=(10, 6)):\n",
    "        \"\"\"\n",
    "        Visualize the relative importance of original dimensions versus engineered features\n",
    "        by comparing model performance with different feature sets.\n",
    "        \n",
    "        Args:\n",
    "            figsize: Size of the resulting figure\n",
    "        \n",
    "        Returns:\n",
    "            Figure showing relative feature importance\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'X') or not hasattr(self, 'y'):\n",
    "            raise AttributeError(\"No data available\")\n",
    "            \n",
    "        # Get number of original dimensions and engineered features\n",
    "        X_processed = self._preprocess_X(self.X)\n",
    "        n_original = self.X.shape[1]\n",
    "        n_engineered = X_processed.shape[1] - n_original\n",
    "        \n",
    "        if n_engineered == 0:\n",
    "            raise ValueError(\"No engineered features found. _preprocess_X doesn't add features.\")\n",
    "            \n",
    "        # Prepare data for CV\n",
    "        if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "            y_for_cv = self.y_log\n",
    "        else:\n",
    "            y_for_cv = self.y\n",
    "            \n",
    "        # Define feature groups to test\n",
    "        feature_groups = {\n",
    "            'All Features': list(range(X_processed.shape[1])),\n",
    "            'Original Only': list(range(n_original)),\n",
    "        }\n",
    "        \n",
    "        # Add individual original dimensions\n",
    "        for i in range(n_original):\n",
    "            feature_name = self.param_names[i] if hasattr(self, 'param_names') else f\"X{i}\"\n",
    "            feature_groups[feature_name] = [i]\n",
    "            \n",
    "        # Add engineered features (if they can be identified)\n",
    "        if hasattr(self, 'feature_names') and len(self.feature_names) == n_engineered:\n",
    "            for i, name in enumerate(self.feature_names):\n",
    "                feature_groups[name] = [n_original + i]\n",
    "        else:\n",
    "            feature_groups['All Engineered'] = list(range(n_original, X_processed.shape[1]))\n",
    "            \n",
    "        # Perform cross-validation for each feature group\n",
    "        cv = KFold(n_splits=min(5, len(self.X)), shuffle=True, random_state=1)\n",
    "        scores = {}\n",
    "        \n",
    "        for group_name, feature_indices in feature_groups.items():\n",
    "            group_scores = []\n",
    "            for train_idx, test_idx in cv.split(X_processed):\n",
    "                X_train = X_processed[train_idx][:, feature_indices]\n",
    "                X_test = X_processed[test_idx][:, feature_indices]\n",
    "                y_train, y_test = y_for_cv[train_idx], y_for_cv[test_idx]\n",
    "                \n",
    "                # Simple GPR for testing features\n",
    "                kernel = ConstantKernel() * Matern(nu=2.5)\n",
    "                model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = model.predict(X_test)\n",
    "                score = r2_score(y_test, y_pred)\n",
    "                group_scores.append(score)\n",
    "                \n",
    "            scores[group_name] = np.mean(group_scores)\n",
    "            \n",
    "        # Create bar plot\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Sort by scores\n",
    "        sorted_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        names = [item[0] for item in sorted_items]\n",
    "        values = [item[1] for item in sorted_items]\n",
    "        \n",
    "        # Plot\n",
    "        bars = ax.bar(names, values, color='skyblue')\n",
    "        \n",
    "        # Highlight special categories\n",
    "        if 'All Features' in scores:\n",
    "            idx = names.index('All Features')\n",
    "            bars[idx].set_color('green')\n",
    "            \n",
    "        if 'Original Only' in scores:\n",
    "            idx = names.index('Original Only')\n",
    "            bars[idx].set_color('orange')\n",
    "            \n",
    "        if 'All Engineered' in scores:\n",
    "            idx = names.index('All Engineered')\n",
    "            bars[idx].set_color('purple')\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        ax.set_ylabel('Cross-validation R Score')\n",
    "        ax.set_title('Feature Importance Comparison')\n",
    "        ax.set_ylim([max(0, min(values) - 0.1), min(1.0, max(values) + 0.1)])\n",
    "        \n",
    "        # Rotate x-axis labels if there are many features\n",
    "        if len(names) > 5:\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def plot_interaction_heatmap(self, figsize=(12, 10)):\n",
    "        \"\"\"\n",
    "        Create a heatmap showing interactions between original dimensions\n",
    "        by measuring the difference between additive and joint effects.\n",
    "        \n",
    "        Args:\n",
    "            figsize: Size of the resulting figure\n",
    "        \n",
    "        Returns:\n",
    "            Figure showing interaction heatmap\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'X') or not hasattr(self, 'y'):\n",
    "            raise AttributeError(\"No data available\")\n",
    "            \n",
    "        n_dims = self.X.shape[1]\n",
    "        interaction_matrix = np.zeros((n_dims, n_dims))\n",
    "        \n",
    "        # Define model prediction function\n",
    "        if hasattr(self, 'botorch_gp'):\n",
    "            def predict_fn(X):\n",
    "                X_tensor = torch.tensor(X, dtype=torch.float64, device=self.device if hasattr(self, 'device') else None)\n",
    "                with torch.no_grad():\n",
    "                    predictions = self.botorch_gp.posterior(X_tensor).mean.cpu().numpy()\n",
    "                if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "                    predictions = np.expm1(predictions)\n",
    "                return predictions\n",
    "        else:\n",
    "            def predict_fn(X):\n",
    "                X_processed = self._preprocess_X(X)\n",
    "                predictions = self.gp_best.predict(X_processed)\n",
    "                if hasattr(self, 'use_log_y') and self.use_log_y:\n",
    "                    predictions = np.expm1(predictions)\n",
    "                return predictions\n",
    "            \n",
    "        # Create a grid for evaluation\n",
    "        resolution = 20\n",
    "        X_mean = np.mean(self.X, axis=0)\n",
    "        \n",
    "        # For each pair of dimensions, compute interactions\n",
    "        for i in range(n_dims):\n",
    "            for j in range(i+1, n_dims):\n",
    "                # Create 1D grids for each dimension\n",
    "                x_i = np.linspace(self.bounds[i][0], self.bounds[i][1], resolution)\n",
    "                x_j = np.linspace(self.bounds[j][0], self.bounds[j][1], resolution)\n",
    "                \n",
    "                # Create 2D grid for joint effect\n",
    "                X_i_grid, X_j_grid = np.meshgrid(x_i, x_j)\n",
    "                X_joint = np.tile(X_mean, (resolution*resolution, 1))\n",
    "                X_joint[:, i] = X_i_grid.flatten()\n",
    "                X_joint[:, j] = X_j_grid.flatten()\n",
    "                \n",
    "                # Predict joint effect\n",
    "                joint_effect = predict_fn(X_joint).reshape(resolution, resolution)\n",
    "                \n",
    "                # Create separate 1D effect for dimension i\n",
    "                X_i_only = np.tile(X_mean, (resolution, 1))\n",
    "                X_i_only[:, i] = x_i\n",
    "                i_effect = predict_fn(X_i_only)\n",
    "                \n",
    "                # Create separate 1D effect for dimension j\n",
    "                X_j_only = np.tile(X_mean, (resolution, 1))\n",
    "                X_j_only[:, j] = x_j\n",
    "                j_effect = predict_fn(X_j_only)\n",
    "                \n",
    "                # Compute the additive effect (assuming no interaction)\n",
    "                additive_effect = np.zeros((resolution, resolution))\n",
    "                for a in range(resolution):\n",
    "                    for b in range(resolution):\n",
    "                        # Additive effect = i_effect + j_effect - baseline\n",
    "                        baseline = predict_fn(np.array([X_mean]))[0]\n",
    "                        additive_effect[a, b] = i_effect[a] + j_effect[b] - baseline\n",
    "                \n",
    "                # Compute interaction strength as the normalized difference between joint and additive\n",
    "                interaction_diff = joint_effect - additive_effect\n",
    "                interaction_strength = np.abs(interaction_diff).mean() / np.std(self.y)\n",
    "                \n",
    "                interaction_matrix[i, j] = interaction_strength\n",
    "                interaction_matrix[j, i] = interaction_strength\n",
    "        \n",
    "        # Create heatmap\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Create feature names\n",
    "        feature_names = self.param_names if hasattr(self, 'param_names') else [f\"X{i}\" for i in range(n_dims)]\n",
    "        \n",
    "        # Create mask for the upper triangle (optional)\n",
    "        mask = np.triu(np.ones_like(interaction_matrix, dtype=bool), k=1)\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sns.heatmap(interaction_matrix, \n",
    "                   annot=True, \n",
    "                   cmap='viridis', \n",
    "                   xticklabels=feature_names,\n",
    "                   yticklabels=feature_names,\n",
    "                   mask=mask,\n",
    "                   ax=ax,\n",
    "                   cbar_kws={'label': 'Interaction Strength'})\n",
    "        \n",
    "        ax.set_title('Dimension Interaction Heatmap')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def plot_acquisition_landscape(self, acq_name, n_candidates=1000):\n",
    "        \"\"\"\n",
    "        Compare different acquisition functions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_candidates : int\n",
    "            Number of random candidates to evaluate\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        candidates : numpy.ndarray\n",
    "            Array of candidate points\n",
    "        acq_name   : string\n",
    "            Acquisition function type\n",
    "        acq_values : dict\n",
    "            Dictionary of acquisition function values for each candidate\n",
    "        \"\"\"\n",
    "        # Generate random candidates\n",
    "        candidates = np.random.uniform(\n",
    "            low=self.bounds[:, 0],\n",
    "            high=self.bounds[:, 1],\n",
    "            size=(n_candidates, self.n_dim)\n",
    "        )\n",
    "        \n",
    "        # Store acquisition function values\n",
    "        acq_values = np.zeros(n_candidates)\n",
    "        \n",
    "        # Evaluate each candidate with different acquisition functions\n",
    "        for i, candidate in enumerate(candidates):\n",
    "            candidate = candidate.reshape(1, -1)\n",
    "            if acq_name == 'log_ei':\n",
    "                acq_values[i] = self._acquisition_log_ei(candidate)[0]\n",
    "            elif acq_name == 'ucb':\n",
    "                acq_values[i] = self._acquisition_ucb(candidate)[0]\n",
    "            elif acq_name == 'pi':\n",
    "                acq_values[i] = self._acquisition_pi(candidate)[0]\n",
    "            else:\n",
    "                acq_values[i] = self._acquisition_ei(candidate)[0]\n",
    "        \n",
    "        if self.n_dim <= 2:\n",
    "            # For 1D or 2D, we can visualize directly\n",
    "            if self.n_dim == 1:\n",
    "                # 1D visualization\n",
    "                fig, axs = plt.subplots(1, 1, figsize=(14, 10))\n",
    "                \n",
    "                # Sort for better visualization\n",
    "                sorted_indices = np.argsort(candidates.flatten())\n",
    "                sorted_candidates = candidates.flatten()[sorted_indices]\n",
    "                sorted_values = acq_values[sorted_indices]\n",
    "                \n",
    "                axs.plot(sorted_candidates, sorted_values)\n",
    "                axs.set_title(f'{acq_name} Acquisition Function')\n",
    "                axs.set_xlabel('Input')\n",
    "                axs.set_ylabel('Acquisition Value')\n",
    "                axs.grid(True)\n",
    "                \n",
    "                # Mark observations\n",
    "                for x in self.X:\n",
    "                    axs.axvline(x=x[0], color='r', linestyle='--', alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "            elif self.n_dim == 2:\n",
    "                # 2D visualization using contour plots\n",
    "                fig, axs = plt.subplots(1, 1, figsize=(14, 12))\n",
    "                \n",
    "                # Prepare grid\n",
    "                x1_grid = np.linspace(self.bounds[0, 0], self.bounds[0, 1], 100)\n",
    "                x2_grid = np.linspace(self.bounds[1, 0], self.bounds[1, 1], 100)\n",
    "                X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "                \n",
    "                # Reshape for contour plots\n",
    "                # Interpolate acquisition values to grid\n",
    "                grid_values = griddata(candidates, acq_values, (X1, X2), method='cubic')\n",
    "                \n",
    "                # Contour plot\n",
    "                cf = axs.contourf(X1, X2, grid_values, 50, cmap='viridis')\n",
    "                axs.scatter(self.X[:, 0], self.X[:, 1], c='r', s=30, marker='o')\n",
    "                axs.set_title(f'{acq_name} Acquisition Function')\n",
    "                axs.set_xlabel('Input Dimension 1')\n",
    "                axs.set_ylabel('Input Dimension 2')\n",
    "                plt.colorbar(cf, ax=axs)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "        else:\n",
    "            # For higher dimensions, use PCA\n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(candidates)\n",
    "            \n",
    "            # Create subplots for each acquisition function\n",
    "            fig, axs = plt.subplots(1, 1, figsize=(14, 12))\n",
    "            \n",
    "            # Scatter plot colored by acquisition value\n",
    "            scatter = axs.scatter(X_pca[:, 0], X_pca[:, 1], c=acq_values, \n",
    "                                   cmap='viridis', s=30, alpha=0.7)\n",
    "            \n",
    "            # Plot observations\n",
    "            obs_pca = pca.transform(self.X)\n",
    "            axs.scatter(obs_pca[:, 0], obs_pca[:, 1], c='r', s=50, marker='o')\n",
    "            \n",
    "            axs.set_title(f'{acq_name} Acquisition Function')\n",
    "            axs.set_xlabel('PCA Component 1')\n",
    "            axs.set_ylabel('PCA Component 2')\n",
    "            plt.colorbar(scatter, ax=axs)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    def get_most_important_dimensions(self, top_k=6):\n",
    "        \"\"\"\n",
    "        Identify the most important dimensions based on various criteria\n",
    "        \"\"\"\n",
    "        importance_scores = np.zeros(self.n_dim)\n",
    "        \n",
    "        # Method 1: Variance in the data\n",
    "        variances = np.var(self.X, axis=0)\n",
    "        importance_scores += variances / variances.max()\n",
    "        \n",
    "        # Method 2: Correlation with target variable\n",
    "        correlations = np.abs([np.corrcoef(self.X[:, i], self.y)[0,1] for i in range(self.n_dim)])\n",
    "        # Handle NaN correlations (constant features)\n",
    "        correlations = np.nan_to_num(correlations)\n",
    "        if correlations.max() > 0:\n",
    "            importance_scores += correlations / correlations.max()\n",
    "        \n",
    "        # Method 3: Range of values\n",
    "        ranges = np.ptp(self.X, axis=0)  # peak-to-peak (max - min)\n",
    "        if ranges.max() > 0:\n",
    "            importance_scores += ranges / ranges.max()\n",
    "        \n",
    "        # Return indices of top dimensions\n",
    "        top_indices = np.argsort(importance_scores)[-top_k:][::-1]\n",
    "        \n",
    "        # Fix: Create the formatted string separately\n",
    "        dim_scores = [(i+1, importance_scores[i]) for i in top_indices]\n",
    "        formatted_scores = [f\"({dim}, {score:.3f})\" for dim, score in dim_scores]\n",
    "#        print(f\"Most important dimensions (scores): {formatted_scores}\")\n",
    "        \n",
    "        return top_indices.tolist()\n",
    "\n",
    "    def plot_acquisition_3d_selected(self, acq_type=\"ei\", beta=2.0, max_plots=6, figsize_per_plot=(12, 8)):\n",
    "        \"\"\"\n",
    "        Create separate large 3D plots for the most important dimension combinations\n",
    "        \"\"\"\n",
    "        from itertools import combinations\n",
    "        \n",
    "        if self.n_dim < 3:\n",
    "            print(\"Need at least 3 dimensions for 3D acquisition visualization\")\n",
    "            return []\n",
    "        \n",
    "        # Set up acquisition function\n",
    "        if acq_type.lower() == \"ei\":\n",
    "            acq_func = ExpectedImprovement(self.botorch_gp, best_f=self.y.max())\n",
    "        elif acq_type.lower() == \"log_ei\":\n",
    "            acq_func = LogExpectedImprovement(self.botorch_gp, best_f=self.y.max())\n",
    "        elif acq_type.lower() == \"ucb\":\n",
    "            acq_func = UpperConfidenceBound(self.botorch_gp, beta=beta)\n",
    "        elif acq_type.lower() == \"pi\":\n",
    "            acq_func = ProbabilityOfImprovement(self.botorch_gp, best_f=self.y.max())\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown acquisition function type: {acq_type}\")\n",
    "        \n",
    "        # Find most important dimensions (highest variance or feature importance)\n",
    "        important_dims = self.get_most_important_dimensions(top_k=6)\n",
    "        \n",
    "        # Get combinations of important dimensions\n",
    "        dim_combinations = list(combinations(important_dims, 3))[:max_plots]\n",
    "        \n",
    "        figures = []\n",
    "        \n",
    "        for dims in dim_combinations:\n",
    "            # Create figure with specific layout for 3D plot + colorbar + legend\n",
    "            fig = plt.figure(figsize=figsize_per_plot)\n",
    "            \n",
    "            # Create subplot with specific positioning to leave room for colorbar and legend\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Your existing plotting code for a single combination\n",
    "            resolution = 25  # Increase resolution since we have fewer plots\n",
    "            grid_points = np.ones((resolution, resolution, resolution, self.n_dim))\n",
    "            \n",
    "            # Use mean values from training data for non-displayed dimensions\n",
    "            default_values = np.mean(self.X, axis=0)\n",
    "            \n",
    "            # Set up grid values for each dimension\n",
    "            for d_idx, dim in enumerate(dims):\n",
    "                grid_vals = np.linspace(0, 1, resolution)\n",
    "                if d_idx == 0:\n",
    "                    grid_points[:, :, :, dim] = grid_vals.reshape(resolution, 1, 1)\n",
    "                elif d_idx == 1:\n",
    "                    grid_points[:, :, :, dim] = grid_vals.reshape(1, resolution, 1)\n",
    "                else:\n",
    "                    grid_points[:, :, :, dim] = grid_vals.reshape(1, 1, resolution)\n",
    "            \n",
    "            # Fill in default values for non-displayed dimensions\n",
    "            for d in range(self.n_dim):\n",
    "                if d not in dims:\n",
    "                    grid_points[:, :, :, d] = default_values[d]\n",
    "            \n",
    "            # Evaluate acquisition function\n",
    "            grid_torch = torch.tensor(grid_points.reshape(-1, self.n_dim), \n",
    "                                   dtype=torch.float32, device=self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                acq_values = acq_func(grid_torch.unsqueeze(1)).squeeze().cpu().numpy()\n",
    "            \n",
    "            acq_values = acq_values.reshape(resolution, resolution, resolution)\n",
    "            \n",
    "            # Create coordinate grids\n",
    "            x, y, z = np.meshgrid(\n",
    "                np.linspace(0, 1, resolution),\n",
    "                np.linspace(0, 1, resolution),\n",
    "                np.linspace(0, 1, resolution),\n",
    "                indexing='ij'\n",
    "            )\n",
    "            \n",
    "            # Show top 15% of acquisition values\n",
    "            threshold = np.percentile(acq_values, 85)\n",
    "            mask = acq_values > threshold\n",
    "            \n",
    "            points = np.column_stack([x[mask].flatten(), y[mask].flatten(), z[mask].flatten()])\n",
    "            colors = acq_values[mask].flatten()\n",
    "            \n",
    "            scatter = ax.scatter(points[:, 0], points[:, 1], points[:, 2],\n",
    "                               c=colors, cmap='coolwarm', alpha=0.6, s=30)\n",
    "            \n",
    "            # Plot training points\n",
    "            ax.scatter(self.X[:, dims[0]], self.X[:, dims[1]], self.X[:, dims[2]], \n",
    "                      color='black', s=100, marker='o', label='Observations', alpha=0.8)\n",
    "            \n",
    "            # Plot candidates\n",
    "            df = self.candidates_df.reset_index()\n",
    "            for index, row in df.iterrows():\n",
    "                cand = row['Candidate']\n",
    "                ax.scatter(cand[dims[0]], cand[dims[1]], cand[dims[2]],\n",
    "                          color=f'C{index+1}', s=150, marker='*', \n",
    "                          label=row['Method'], edgecolors='black', linewidth=1)\n",
    "            \n",
    "            # Set labels and title with appropriate font sizes\n",
    "            ax.set_xlabel(f'Dimension {dims[0]+1}', fontsize=12)\n",
    "            ax.set_ylabel(f'Dimension {dims[1]+1}', fontsize=12)\n",
    "            ax.set_zlabel(f'Dimension {dims[2]+1}', fontsize=12)\n",
    "            ax.set_title(f'{acq_type.upper()} Acquisition Function\\n(Dims {dims[0]+1}, {dims[1]+1}, {dims[2]+1})', \n",
    "                         fontsize=14, pad=20)\n",
    "            \n",
    "            # Adjust subplot position to make room for colorbar and legend\n",
    "            plt.subplots_adjust(left=0.05, right=0.75, top=0.9, bottom=0.1)\n",
    "            \n",
    "            # Add colorbar with better positioning\n",
    "            # Create axis for colorbar\n",
    "            cbar_ax = fig.add_axes([0.78, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "            cbar = plt.colorbar(scatter, cax=cbar_ax)\n",
    "            cbar.set_label('Acquisition Value', fontsize=11)\n",
    "            cbar.ax.tick_params(labelsize=10)\n",
    "            \n",
    "            # Add legend with better positioning\n",
    "            legend = ax.legend(bbox_to_anchor=(1.25, 1.0), loc='upper left', fontsize=10, \n",
    "                              markerscale=0.8, framealpha=0.9)\n",
    "            \n",
    "            # Ensure the legend doesn't get cut off\n",
    "            legend.set_bbox_to_anchor((1.25, 1.0))\n",
    "            \n",
    "            figures.append(fig)\n",
    "        \n",
    "        return figures\n",
    "    \n",
    "    def visualize_warping(self):\n",
    "        \"\"\"Visualize the learned input warping functions.\"\"\"\n",
    "        if not hasattr(self, 'warped_gp_model'):\n",
    "            print(\"No warped GP model available\")\n",
    "            return\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        model = self.warped_gp_model\n",
    "        input_dim = model.input_dim\n",
    "        \n",
    "        # Create original input grid\n",
    "        if input_dim <= 2:  # Only visualize for 1D or 2D inputs\n",
    "            fig, axes = plt.subplots(1, input_dim, figsize=(input_dim * 5, 4))\n",
    "            if input_dim == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for dim in range(input_dim):\n",
    "                ax = axes[dim]\n",
    "                \n",
    "                # Create grid of values in original space\n",
    "                x_grid = torch.linspace(\n",
    "                    model.warp_transform.mins[dim].item(),\n",
    "                    model.warp_transform.mins[dim].item() + model.warp_transform.ranges[dim].item(),\n",
    "                    100, dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "                \n",
    "                # Get warped values\n",
    "                x_warped = torch.zeros_like(x_grid)\n",
    "                for i, x_val in enumerate(x_grid):\n",
    "                    # Create a full input where only the current dimension varies\n",
    "                    x_full = torch.zeros(1, input_dim, dtype=torch.float32)\n",
    "                    x_full[0, dim] = x_val\n",
    "                    \n",
    "                    # Apply warping\n",
    "                    with torch.no_grad():\n",
    "                        x_w = model.warp_transform.transform(x_full)\n",
    "                        x_warped[i] = x_w[0, dim]\n",
    "                \n",
    "                # Plot\n",
    "                ax.plot(x_grid.numpy(), x_warped.numpy(), 'b-', linewidth=2)\n",
    "                ax.plot([x_grid.min().item(), x_grid.max().item()], \n",
    "                        [0, 1], 'r--', alpha=0.5)\n",
    "                ax.set_title(f'Dimension {dim+1} Warping')\n",
    "                ax.set_xlabel('Original Input')\n",
    "                ax.set_ylabel('Warped Input')\n",
    "                ax.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            return fig\n",
    "        else:\n",
    "            print(\"Visualization only available for 1D or 2D inputs\")\n",
    "            return None\n",
    "\n",
    "    def plot_model_fit(self):\n",
    "        \"\"\"Plot the model fit for 1D and 2D inputs.\"\"\"\n",
    "        if self.n_dim > 2:\n",
    "            print(\"Visualization only available for 1D or 2D inputs\")\n",
    "            return None\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib import cm\n",
    "        \n",
    "        # Prepare data\n",
    "        X = self.X\n",
    "        y = self.y_log if self.use_log_y else self.y\n",
    "        \n",
    "        # Create grid for visualization\n",
    "        if self.n_dim == 1:\n",
    "            x_grid = np.linspace(self.bounds[0, 0], self.bounds[0, 1], 100).reshape(-1, 1)\n",
    "            X_grid_tensor = torch.tensor(self._preprocess_X(x_grid), dtype=torch.float32)\n",
    "            \n",
    "            # Get predictions\n",
    "            if self.is_warped:\n",
    "                model = self.warped_gp_model\n",
    "                with torch.no_grad():\n",
    "                    posterior = model(X_grid_tensor)\n",
    "                    mean = posterior.mean.cpu().numpy()\n",
    "                    lower, upper = posterior.confidence_region()\n",
    "                    lower = lower.cpu().numpy()\n",
    "                    upper = upper.cpu().numpy()\n",
    "            else:\n",
    "                # For sklearn GP, need different approach\n",
    "                if hasattr(self, 'gp_best'):\n",
    "                    X_grid_proc = self._preprocess_X(x_grid)\n",
    "                    mean, std = self.gp_best.predict(X_grid_proc, return_std=True)\n",
    "                    lower = mean - 2 * std\n",
    "                    upper = mean + 2 * std\n",
    "                else:\n",
    "                    print(\"No model available\")\n",
    "                    return None\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "            \n",
    "            # Plot mean and confidence intervals\n",
    "            ax.plot(x_grid, mean, 'b-', label='Prediction')\n",
    "            ax.fill_between(x_grid.flatten(), lower.flatten(), upper.flatten(), \n",
    "                            alpha=0.2, color='b', label='95% Confidence')\n",
    "            \n",
    "            # Plot training data\n",
    "            ax.scatter(X, y, c='r', s=50, label='Observations')\n",
    "            \n",
    "            ax.set_title('Gaussian Process Regression')\n",
    "            ax.set_xlabel('Input')\n",
    "            ax.set_ylabel('Output')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            \n",
    "        elif self.n_dim == 2:\n",
    "            # Create meshgrid\n",
    "            resolution = 200 # was 50\n",
    "            x0_range = np.linspace(self.bounds[0, 0], self.bounds[0, 1], resolution)\n",
    "            x1_range = np.linspace(self.bounds[1, 0], self.bounds[1, 1], resolution)\n",
    "            x0_grid, x1_grid = np.meshgrid(x0_range, x1_range)\n",
    "            X_grid = np.column_stack([x0_grid.ravel(), x1_grid.ravel()])\n",
    "            X_grid_tensor = torch.tensor(self._preprocess_X(X_grid), dtype=torch.float32)\n",
    "            \n",
    "            # Get predictions\n",
    "            if self.is_warped:\n",
    "                model = self.warped_gp_model\n",
    "                with torch.no_grad():\n",
    "                    posterior = model(X_grid_tensor)\n",
    "                    mean = posterior.mean.cpu().numpy()\n",
    "                    lower, upper = posterior.confidence_region()\n",
    "                    std = ((upper - lower) / 4).cpu().numpy()\n",
    "            else:\n",
    "                # For sklearn GP\n",
    "                if hasattr(self, 'gp_best'):\n",
    "                    X_grid_proc = self._preprocess_X(X_grid)\n",
    "                    mean, std = self.gp_best.predict(X_grid_proc, return_std=True)\n",
    "                else:\n",
    "                    print(\"No model available\")\n",
    "                    return None\n",
    "            \n",
    "            # Create plot\n",
    "            fig = plt.figure(figsize=(18, 6))\n",
    "            \n",
    "            # Predicted surface\n",
    "            ax1 = fig.add_subplot(131, projection='3d')\n",
    "            ax1.plot_surface(x0_grid, x1_grid, mean.reshape(resolution, resolution),\n",
    "                            cmap=cm.viridis, alpha=0.7, linewidth=0)\n",
    "            ax1.scatter(X[:, 0], X[:, 1], y, c='r', s=50)\n",
    "            ax1.set_title('GP Prediction Surface')\n",
    "            ax1.set_xlabel('x0')\n",
    "            ax1.set_ylabel('x1')\n",
    "            ax1.set_zlabel('y')\n",
    "            \n",
    "            # Heatmap view\n",
    "            ax2 = fig.add_subplot(132)\n",
    "            c = ax2.pcolormesh(x0_grid, x1_grid, mean.reshape(resolution, resolution),\n",
    "                              cmap=cm.viridis, shading='auto')\n",
    "            ax2.scatter(X[:, 0], X[:, 1], c=y, edgecolors='w', s=50, cmap=cm.plasma)\n",
    "            fig.colorbar(c, ax=ax2)\n",
    "            ax2.set_title('GP Prediction (Top View)')\n",
    "            ax2.set_xlabel('x0')\n",
    "            ax2.set_ylabel('x1')\n",
    "            \n",
    "            # Uncertainty\n",
    "            ax3 = fig.add_subplot(133)\n",
    "            c = ax3.pcolormesh(x0_grid, x1_grid, std.reshape(resolution, resolution),\n",
    "                             cmap=cm.inferno, shading='auto')\n",
    "            ax3.scatter(X[:, 0], X[:, 1], c='w', edgecolors='k', s=50)\n",
    "            fig.colorbar(c, ax=ax3)\n",
    "            ax3.set_title('Predictive Uncertainty')\n",
    "            ax3.set_xlabel('x0')\n",
    "            ax3.set_ylabel('x1')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def plot_model_fit_high_dim(self, method='pca', n_components=2, feature_indices=None):\n",
    "        \"\"\"\n",
    "        Plot the model fit for high-dimensional inputs using dimensionality reduction.\n",
    "        \n",
    "        Args:\n",
    "            method: Dimensionality reduction method ('pca', 'tsne', or 'umap')\n",
    "            n_components: Number of components for visualization (2 or 3)\n",
    "            feature_indices: If provided, use these specific feature indices instead of dimensionality reduction\n",
    "        \n",
    "        Returns:\n",
    "            Matplotlib figure\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib import cm\n",
    "        import numpy as np\n",
    "        \n",
    "        # Prepare data\n",
    "        X = self.X\n",
    "        y = self.y_log if self.use_log_y else self.y\n",
    "        \n",
    "        # Check dimensions\n",
    "        if self.n_dim <= 2:\n",
    "#            print(\"Use plot_model_fit() for 1D or 2D inputs\")\n",
    "            return self.plot_model_fit()\n",
    "        \n",
    "        # If specific feature indices are provided, use them directly\n",
    "        if feature_indices is not None:\n",
    "            if len(feature_indices) == 2:\n",
    "                n_components = 2\n",
    "                X_reduced = X[:, feature_indices]\n",
    "                feature_names = [f\"Feature {i+1}\" for i in feature_indices]\n",
    "                reduction_name = \"Selected Features\"\n",
    "            elif len(feature_indices) == 3:\n",
    "                n_components = 3\n",
    "                X_reduced = X[:, feature_indices]\n",
    "                feature_names = [f\"Feature {i+1}\" for i in feature_indices]\n",
    "                reduction_name = \"Selected Features\"\n",
    "            else:\n",
    "                print(\"Feature indices must be of length 2 or 3\")\n",
    "                return None\n",
    "        else:\n",
    "            # Apply dimensionality reduction\n",
    "            if method.lower() == 'pca':\n",
    "                from sklearn.decomposition import PCA\n",
    "                reducer = PCA(n_components=n_components)\n",
    "                X_reduced = reducer.fit_transform(X)\n",
    "                # Get explained variance ratio for labels\n",
    "                explained_var = reducer.explained_variance_ratio_\n",
    "                feature_names = [f\"PC{i+1} ({var:.1%})\" for i, var in enumerate(explained_var)]\n",
    "                reduction_name = \"PCA\"\n",
    "                \n",
    "                # Save the PCA model for later use in grid generation\n",
    "                self._last_reducer = reducer\n",
    "                \n",
    "            elif method.lower() == 'tsne':\n",
    "                from sklearn.manifold import TSNE\n",
    "                reducer = TSNE(n_components=n_components, random_state=1)\n",
    "                X_reduced = reducer.fit_transform(X)\n",
    "                feature_names = [f\"t-SNE{i+1}\" for i in range(n_components)]\n",
    "                reduction_name = \"t-SNE\"\n",
    "                \n",
    "            elif method.lower() == 'umap':\n",
    "                try:\n",
    "                    import umap\n",
    "                    reducer = umap.UMAP(n_components=n_components, random_state=1)\n",
    "                    X_reduced = reducer.fit_transform(X)\n",
    "                    feature_names = [f\"UMAP{i+1}\" for i in range(n_components)]\n",
    "                    reduction_name = \"UMAP\"\n",
    "                except ImportError:\n",
    "                    print(\"UMAP not installed. Please install with: pip install umap-learn\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Unknown dimensionality reduction method: {method}\")\n",
    "                return None\n",
    "        \n",
    "        # Create a grid for prediction\n",
    "        if n_components == 2:\n",
    "            resolution = 100\n",
    "            \n",
    "            # Create grid bounds\n",
    "            x0_min, x0_max = X_reduced[:, 0].min(), X_reduced[:, 0].max()\n",
    "            x1_min, x1_max = X_reduced[:, 1].min(), X_reduced[:, 1].max()\n",
    "            \n",
    "            # Add margin\n",
    "            margin = 0.1\n",
    "            x0_range = np.linspace(x0_min - margin * (x0_max - x0_min), \n",
    "                                  x0_max + margin * (x0_max - x0_min), resolution)\n",
    "            x1_range = np.linspace(x1_min - margin * (x1_max - x1_min), \n",
    "                                  x1_max + margin * (x1_max - x1_min), resolution)\n",
    "            \n",
    "            # Create meshgrid\n",
    "            x0_grid, x1_grid = np.meshgrid(x0_range, x1_range)\n",
    "            grid_points = np.column_stack([x0_grid.ravel(), x1_grid.ravel()])\n",
    "            \n",
    "            # Transform grid points back to original space if using dimensionality reduction\n",
    "            if feature_indices is None:\n",
    "                if method.lower() == 'pca':\n",
    "                    # For PCA, we can use the inverse_transform\n",
    "                    grid_original = reducer.inverse_transform(grid_points)\n",
    "                else:\n",
    "                    # For t-SNE and UMAP, finding the closest training point\n",
    "                    from scipy.spatial import cKDTree\n",
    "                    tree = cKDTree(X_reduced)\n",
    "                    _, indices = tree.query(grid_points, k=5)\n",
    "                    \n",
    "                    # Average the k nearest original points\n",
    "                    grid_original = np.zeros((len(grid_points), self.n_dim))\n",
    "                    for i, idx_list in enumerate(indices):\n",
    "                        grid_original[i] = X[idx_list].mean(axis=0)\n",
    "            else:\n",
    "                # For direct feature selection, we need to recreate the full input vector\n",
    "                grid_original = np.zeros((len(grid_points), self.n_dim))\n",
    "                \n",
    "                # Set non-plotted dimensions to their median values\n",
    "                for i in range(self.n_dim):\n",
    "                    if i in feature_indices:\n",
    "                        idx = feature_indices.index(i)\n",
    "                        grid_original[:, i] = grid_points[:, idx]\n",
    "                    else:\n",
    "                        grid_original[:, i] = np.median(X[:, i])\n",
    "            \n",
    "            # Get predictions using the full model\n",
    "            if self.is_warped:\n",
    "                model = self.warped_gp_model\n",
    "                grid_tensor = torch.tensor(self._preprocess_X(grid_original), dtype=torch.float32)\n",
    "                with torch.no_grad():\n",
    "                    posterior = model(grid_tensor)\n",
    "                    mean = posterior.mean.cpu().numpy()\n",
    "                    lower, upper = posterior.confidence_region()\n",
    "                    std = ((upper - lower) / 4).cpu().numpy()\n",
    "            else:\n",
    "                # For sklearn GP\n",
    "                if hasattr(self, 'gp_best'):\n",
    "                    grid_proc = self._preprocess_X(grid_original)\n",
    "                    mean, std = self.gp_best.predict(grid_proc, return_std=True)\n",
    "                else:\n",
    "                    print(\"No model available\")\n",
    "                    return None\n",
    "            \n",
    "            # Create plot\n",
    "            fig = plt.figure(figsize=(18, 6))\n",
    "            \n",
    "            # Predicted surface\n",
    "            ax1 = fig.add_subplot(131, projection='3d')\n",
    "            ax1.plot_surface(x0_grid, x1_grid, mean.reshape(resolution, resolution),\n",
    "                            cmap=cm.viridis, alpha=0.7, linewidth=0)\n",
    "            scatter = ax1.scatter(X_reduced[:, 0], X_reduced[:, 1], y, c=y, cmap=cm.plasma, s=50)\n",
    "            ax1.set_title(f'GP Prediction Surface ({reduction_name})')\n",
    "            ax1.set_xlabel(feature_names[0])\n",
    "            ax1.set_ylabel(feature_names[1])\n",
    "            ax1.set_zlabel('Output')\n",
    "            \n",
    "            # Heatmap view\n",
    "            ax2 = fig.add_subplot(132)\n",
    "            heatmap = ax2.pcolormesh(x0_grid, x1_grid, mean.reshape(resolution, resolution),\n",
    "                                    cmap=cm.viridis, shading='auto')\n",
    "            scatter2 = ax2.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, edgecolors='w', s=50, cmap=cm.plasma)\n",
    "            fig.colorbar(heatmap, ax=ax2, label='Predicted Value')\n",
    "            ax2.set_title(f'GP Prediction ({reduction_name} - Top View)')\n",
    "            ax2.set_xlabel(feature_names[0])\n",
    "            ax2.set_ylabel(feature_names[1])\n",
    "            \n",
    "            # Uncertainty\n",
    "            ax3 = fig.add_subplot(133)\n",
    "            uncertainty = ax3.pcolormesh(x0_grid, x1_grid, std.reshape(resolution, resolution),\n",
    "                                        cmap=cm.inferno, shading='auto')\n",
    "            ax3.scatter(X_reduced[:, 0], X_reduced[:, 1], c='w', edgecolors='k', s=50)\n",
    "            fig.colorbar(uncertainty, ax=ax3, label='Uncertainty ()')\n",
    "            ax3.set_title(f'Predictive Uncertainty ({reduction_name})')\n",
    "            ax3.set_xlabel(feature_names[0])\n",
    "            ax3.set_ylabel(feature_names[1])\n",
    "    \n",
    "        elif n_components == 3:\n",
    "            # 3D visualization using 3 components\n",
    "            from mpl_toolkits.mplot3d import Axes3D\n",
    "            \n",
    "            # Create a figure with 3D scatter plots\n",
    "            fig = plt.figure(figsize=(20, 10))\n",
    "            \n",
    "            # Create a scatter plot of the reduced data\n",
    "            ax1 = fig.add_subplot(121, projection='3d')\n",
    "            scatter = ax1.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], \n",
    "                                c=y, cmap=cm.plasma, s=50)\n",
    "            ax1.set_title(f'Training Data in {reduction_name} Space')\n",
    "            ax1.set_xlabel(feature_names[0])\n",
    "            ax1.set_ylabel(feature_names[1])\n",
    "            ax1.set_zlabel(feature_names[2])\n",
    "            fig.colorbar(scatter, ax=ax1, label='Output Value')\n",
    "            \n",
    "            # Create a 4D visualization (3D space + color for prediction)\n",
    "            # We'll sample points in the reduced space and color them by predicted value\n",
    "            from scipy.interpolate import griddata\n",
    "            \n",
    "            # Create a coarser grid in 3D reduced space\n",
    "            resolution = 20\n",
    "            grid_x = np.linspace(X_reduced[:, 0].min(), X_reduced[:, 0].max(), resolution)\n",
    "            grid_y = np.linspace(X_reduced[:, 1].min(), X_reduced[:, 1].max(), resolution)\n",
    "            grid_z = np.linspace(X_reduced[:, 2].min(), X_reduced[:, 2].max(), resolution)\n",
    "            \n",
    "            # Create meshgrid points\n",
    "            X_grid, Y_grid, Z_grid = np.meshgrid(grid_x, grid_y, grid_z)\n",
    "            grid_points = np.column_stack([X_grid.ravel(), Y_grid.ravel(), Z_grid.ravel()])\n",
    "            \n",
    "            # Interpolate original data for prediction\n",
    "            if feature_indices is None:\n",
    "                if method.lower() == 'pca':\n",
    "                    # For PCA, we can use the inverse_transform\n",
    "                    grid_original = reducer.inverse_transform(grid_points)\n",
    "                else:\n",
    "                    # For t-SNE and UMAP, find the closest training point\n",
    "                    from scipy.spatial import cKDTree\n",
    "                    tree = cKDTree(X_reduced)\n",
    "                    _, indices = tree.query(grid_points, k=5)\n",
    "                    \n",
    "                    # Average the k nearest original points\n",
    "                    grid_original = np.zeros((len(grid_points), self.n_dim))\n",
    "                    for i, idx_list in enumerate(indices):\n",
    "                        grid_original[i] = X[idx_list].mean(axis=0)\n",
    "            else:\n",
    "                # For direct feature selection, we need to recreate the full input vector\n",
    "                grid_original = np.zeros((len(grid_points), self.n_dim))\n",
    "                \n",
    "                # Set non-plotted dimensions to their median values\n",
    "                for i in range(self.n_dim):\n",
    "                    if i in feature_indices:\n",
    "                        idx = feature_indices.index(i)\n",
    "                        grid_original[:, i] = grid_points[:, idx]\n",
    "                    else:\n",
    "                        grid_original[:, i] = np.median(X[:, i])\n",
    "            \n",
    "            # Get predictions using the full model\n",
    "            if self.is_warped:\n",
    "                model = self.warped_gp_model\n",
    "                grid_tensor = torch.tensor(self._preprocess_X(grid_original), dtype=torch.float32)\n",
    "                with torch.no_grad():\n",
    "                    posterior = model(grid_tensor)\n",
    "                    mean = posterior.mean.cpu().numpy()\n",
    "            else:\n",
    "                # For sklearn GP\n",
    "                if hasattr(self, 'gp_best'):\n",
    "                    grid_proc = self._preprocess_X(grid_original)\n",
    "                    mean = self.gp_best.predict(grid_proc)\n",
    "                else:\n",
    "                    print(\"No model available\")\n",
    "                    return None\n",
    "            \n",
    "            # Create a plot with predictions\n",
    "            ax2 = fig.add_subplot(122, projection='3d')\n",
    "            \n",
    "            # We'll sample a subset of points for clarity\n",
    "            sample_idx = np.random.choice(len(grid_points), size=5000, replace=False)\n",
    "            sampled_grid = grid_points[sample_idx]\n",
    "            sampled_mean = mean[sample_idx]\n",
    "            \n",
    "            # Create a scatter plot with predictions as color\n",
    "            prediction_scatter = ax2.scatter(\n",
    "                sampled_grid[:, 0], sampled_grid[:, 1], sampled_grid[:, 2],\n",
    "                c=sampled_mean, cmap=cm.viridis, s=30, alpha=0.8\n",
    "            )\n",
    "            \n",
    "            # Also plot the original data points\n",
    "            ax2.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], \n",
    "                       c='black', marker='o', s=30, alpha=1)\n",
    "            \n",
    "            ax2.set_title(f'Predicted Values in {reduction_name} Space')\n",
    "            ax2.set_xlabel(feature_names[0])\n",
    "            ax2.set_ylabel(feature_names[1])\n",
    "            ax2.set_zlabel(feature_names[2])\n",
    "            fig.colorbar(prediction_scatter, ax=ax2, label='Predicted Value')\n",
    "        \n",
    "        else:\n",
    "            print(\"n_components must be 2 or 3\")\n",
    "            return None\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def plot_dimension_importance(self):\n",
    "        \"\"\"Plot a heatmap of dimension importance based on GP parameters.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import numpy as np\n",
    "        \n",
    "        lengthscales = None\n",
    "        \n",
    "        # Extract lengthscales to determine importance\n",
    "        if self.is_warped:\n",
    "            if hasattr(self.warped_gp_model.covar_module, 'base_kernel') and hasattr(self.warped_gp_model.covar_module.base_kernel, 'lengthscale'):\n",
    "                lengthscales = self.warped_gp_model.covar_module.base_kernel.lengthscale.detach().cpu().numpy()\n",
    "                if len(lengthscales.shape) > 1:\n",
    "                    lengthscales = lengthscales.squeeze()\n",
    "            else:\n",
    "                print(\"Cannot extract lengthscales from warped model\")\n",
    "                return None\n",
    "        else:\n",
    "            # Extract length scales from the kernel\n",
    "            lengthscales_list = []\n",
    "            \n",
    "            for param_name, param_value in self.gp_best.kernel_.get_params().items():\n",
    "                if \"length_scale\" in param_name and isinstance(param_value, (int, float, np.ndarray)):\n",
    "                    if isinstance(param_value, np.ndarray):\n",
    "                        lengthscales = param_value\n",
    "                        break\n",
    "                    else:\n",
    "                        lengthscales_list.append(param_value)\n",
    "            \n",
    "            # If we didn't find an array but found individual values, convert to array\n",
    "            if lengthscales is None and lengthscales_list:\n",
    "                lengthscales = np.array(lengthscales_list)\n",
    "            \n",
    "            # Check if we successfully extracted lengthscales\n",
    "            if lengthscales is None or (isinstance(lengthscales, (list, np.ndarray)) and len(lengthscales) == 0):\n",
    "                print(\"Cannot extract lengthscales from model\")\n",
    "                return None\n",
    "        \n",
    "        # Ensure lengthscales is a numpy array\n",
    "        if not isinstance(lengthscales, np.ndarray):\n",
    "            lengthscales = np.array(lengthscales)\n",
    "        \n",
    "        # Check for valid lengthscales\n",
    "        if lengthscales.size == 0:\n",
    "            print(\"No valid lengthscales found\")\n",
    "            return None\n",
    "        \n",
    "        # Inverse lengthscales indicate feature importance\n",
    "        # Add small epsilon to avoid division by zero\n",
    "        epsilon = 1e-8\n",
    "        importance = 1.0 / (lengthscales + epsilon)\n",
    "        \n",
    "        # Normalize importance\n",
    "        importance = importance / importance.sum()\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "        \n",
    "        # Create bar plot\n",
    "        sns.barplot(x=list(range(len(importance))), y=importance, ax=ax)\n",
    "        \n",
    "        # Generate labels based on available dimensions\n",
    "        if hasattr(self, 'n_dim_processed'):\n",
    "            n_dims = self.n_dim_processed\n",
    "        else:\n",
    "            n_dims = len(importance)\n",
    "        \n",
    "        # Original dimensions + engineered features\n",
    "        dim_labels = [f\"x{i}\" for i in range(min(self.n_dim, n_dims))]\n",
    "        for i in range(self.n_dim, n_dims):\n",
    "            dim_labels.append(f\"feature{i}\")\n",
    "        \n",
    "        # Ensure we have the right number of labels\n",
    "        dim_labels = dim_labels[:len(importance)]\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_title('Feature Importance based on GP Lengthscales')\n",
    "        ax.set_xlabel('Feature Dimension')\n",
    "        ax.set_ylabel('Relative Importance')\n",
    "        ax.set_xticks(list(range(len(importance))))\n",
    "        ax.set_xticklabels(dim_labels, rotation=45 if len(dim_labels) > 10 else 0)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(importance):\n",
    "            ax.text(i, v + 0.01 * max(importance), f'{v:.3f}', \n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    # ==================== Save/Load Methods ====================\n",
    "    \n",
    "    def save_state(self, filename):\n",
    "        \"\"\"\n",
    "        Save the current state of the optimizer to a file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename : str\n",
    "            Path to save the optimizer state\n",
    "        \"\"\"\n",
    "        # Create a dictionary with the state\n",
    "        state = {\n",
    "            'X': self.X,\n",
    "            'y': self.y,\n",
    "            'bounds': self.bounds,\n",
    "            'n_dim': self.n_dim,\n",
    "            'random_state': self.random_state,\n",
    "            'history': self.history,\n",
    "            'best_idx': self.best_idx,\n",
    "            'best_x': self.best_x,\n",
    "            'best_y': self.best_y,\n",
    "            'use_log_y': self.use_log_y,\n",
    "            'best_kernel_name': self.best_kernel_name\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(state, f)\n",
    "        \n",
    "        print(f\"Optimizer state saved to {filename}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_state(cls, filename):\n",
    "        \"\"\"\n",
    "        Load an optimizer state from a file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename : str\n",
    "            Path to the optimizer state file\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        optimizer : BayesianOptimizer\n",
    "            The loaded optimizer\n",
    "        \"\"\"\n",
    "        # Load state from file\n",
    "        with open(filename, 'rb') as f:\n",
    "            state = pickle.load(f)\n",
    "        \n",
    "        # Create a new optimizer\n",
    "        optimizer = cls(\n",
    "            state['X'],\n",
    "            state['y'],\n",
    "            state['bounds'],\n",
    "            state['n_dim'],\n",
    "            random_state=state['random_state']\n",
    "        )\n",
    "        \n",
    "        # Restore state\n",
    "        optimizer.history = state['history']\n",
    "        optimizer.best_idx = state['best_idx']\n",
    "        optimizer.best_x = state['best_x']\n",
    "        optimizer.best_y = state['best_y']\n",
    "        \n",
    "        # Restore log transform setting if it exists\n",
    "        if 'use_log_y' in state:\n",
    "            optimizer.use_log_y = state['use_log_y']\n",
    "            if optimizer.use_log_y:\n",
    "                optimizer.y_log = np.log1p(optimizer.y)\n",
    "        \n",
    "        # Restore best kernel if it exists\n",
    "        if 'best_kernel_name' in state:\n",
    "            optimizer.best_kernel_name = state['best_kernel_name']\n",
    "        \n",
    "        print(f\"Optimizer state loaded from {filename}\")\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26baac1d-0c28-47c0-bcb1-380411765282",
   "metadata": {},
   "source": [
    "The next function calls various visualisation methods from the BayesianOptimizer class and saves them to file, creating an\n",
    "appropriate directory structure and an html index of thumbnails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "772354a7-a148-4fef-b80b-d368366d18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a suite of visualisations and save them into a directory structure along with an html index page with thumbnails\n",
    "\n",
    "def generate_all_visualizations(optimizer, output_dir=\"visualisation_results\"):\n",
    "    \"\"\"\n",
    "    Generate and save all visualizations from the optimizer instance with robust error handling.\n",
    "    \n",
    "    Args:\n",
    "        optimizer: Instance of BayesianOptimizer class\n",
    "        output_dir: Directory to save visualization results\n",
    "    \"\"\"\n",
    "    # Create timestamp for unique run folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(output_dir, f\"run_{timestamp}\")\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectories for different visualization types\n",
    "    dirs = {\n",
    "        \"parallel_coordinates\": os.path.join(run_dir, \"parallel_coordinates\"),\n",
    "        \"prediction_surface\": os.path.join(run_dir, \"prediction_surface\"),\n",
    "        \"acquisition_landscape\": os.path.join(run_dir, \"acquisition_landscape\"),\n",
    "        \"dimension_importance\": os.path.join(run_dir, \"dimension_importance\"),\n",
    "        \"pca\": os.path.join(run_dir, \"pca\"),\n",
    "        \"partial_dependence\": os.path.join(run_dir, \"partial_dependence\"),\n",
    "        \"ei_landscape\": os.path.join(run_dir, \"ei_landscape\"),\n",
    "        \"decision_boundary\": os.path.join(run_dir, \"decision_boundary\"),\n",
    "        \"dimensionality_reduction\": os.path.join(run_dir, \"dimensionality_reduction\"),\n",
    "        \"shap\": os.path.join(run_dir, \"shap\"),\n",
    "        \"feature_analysis\": os.path.join(run_dir, \"feature_analysis\"),\n",
    "        \"model_fits\": os.path.join(run_dir, \"model_fits\")\n",
    "    }\n",
    "    \n",
    "    for dir_path in dirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving all visualizations to: {run_dir}\")\n",
    "    \n",
    "    # Dictionary to track all generated figures for easy access\n",
    "    all_figures = {}\n",
    "\n",
    "    # Parallel coords\n",
    "    try:\n",
    "        print(\"  Creating parallel coordinate plots...\")\n",
    "    \n",
    "        fig = optimizer.plot_parallel_coordinates()\n",
    "        if fig is not None:\n",
    "            fig.write_image(os.path.join(dirs[\"parallel_coordinates\"], \"parallel_coordinates.png\"))\n",
    "            all_figures[\"parallel_coordinates\"] = fig \n",
    "\n",
    "        fig = optimizer.plot_parallel_coordinates_with_candidates()\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"parallel_coordinates\"], \"parallel_coordinates_with_candidates.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"parallel_coordinates_with_candidates\"] = fig    \n",
    "            plt.close(fig)    \n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating parallel coordinates plot: {e}\")\n",
    "    \n",
    "   # Prediction surface\n",
    "    try:\n",
    "        print(\"  Creating prediction surface...\")\n",
    "    \n",
    "        fig = optimizer.plot_prediction_surface()\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"prediction_surface\"], \"prediction_surface.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"prediction_surface\"] = fig \n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating prediction surface: {e}\")\n",
    "    \n",
    "    # Acqusition Landscapes\n",
    "    try:\n",
    "        print(\"  Creating acquisition landscapes...\")\n",
    "    \n",
    "        for acq_name in ['ei','log_ei','ucb','pi']:\n",
    "            fig = optimizer.plot_acquisition_landscape(acq_name = acq_name)\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"acquisition_landscape\"], f\"acquisition_landscape_{acq_name}.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[f\"acquisition_landscape_{acq_name}\"] = fig \n",
    "                plt.close(fig)\n",
    "            if optimizer.n_dim>2:\n",
    "                figures = optimizer.plot_acquisition_3d_selected(acq_type=acq_name)\n",
    "                if figures:\n",
    "                    for i, fig in enumerate(figures):\n",
    "                        filename = f\"acquisition_3d_{acq_name}_combo_{i+1}.png\"\n",
    "                        fig.savefig(os.path.join(dirs[\"acquisition_landscape\"], filename), \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        all_figures[f\"acquisition_3d_{acq_name}_combo_{i+1}\"] = fig\n",
    "                        plt.close(fig)            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating acquisition landscape: {e}\")\n",
    "    \n",
    "    # Dimension Importance\n",
    "    try:\n",
    "        print(\"  Creating dimension importance plot...\")\n",
    "    \n",
    "        fig = optimizer.plot_dimension_importance()\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"dimension_importance\"], \"dimension_importance.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"dimension_importance\"] = fig \n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating dimension importance plot: {e}\")\n",
    "\n",
    "    # PCA\n",
    "    try:\n",
    "        print(\"  Creating PCA plots...\")\n",
    "    \n",
    "        fig = optimizer.plot_pca(n_components=5)\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"pca\"], \"pca.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"pca\"] = fig \n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating PCA plots: {e}\")\n",
    "    \n",
    "    # Get original dimensions for pairwise visualizations\n",
    "    n_dims = optimizer.X.shape[1]\n",
    "    important_dim_pairs = []\n",
    "    \n",
    "    # Add some important dimension pairs for 2D visualizations\n",
    "    if n_dims >= 2:\n",
    "        # Add first few dimensions as pairs\n",
    "        for i in range(min(3, n_dims)):\n",
    "            for j in range(i+1, min(4, n_dims)):\n",
    "                important_dim_pairs.append((i, j))\n",
    "    \n",
    "    # If no pairs were added (e.g., for 1D problems), add the first dimension pair\n",
    "    if not important_dim_pairs and n_dims >= 2:\n",
    "        important_dim_pairs.append((0, 1))\n",
    "    \n",
    "    # Generate visualizations using scikit-learn GP model\n",
    "    if hasattr(optimizer, 'gp_best'):\n",
    "        print(\"Generating visualizations using scikit-learn GP model...\")\n",
    "        \n",
    "        # 1. Partial Dependence Plots\n",
    "        try:\n",
    "            print(\"  Creating partial dependence plots...\")\n",
    "            fig = optimizer.plot_partial_dependence_gpr(figsize=(15, 3*n_dims))\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"partial_dependence\"], \"partial_dependence_gpr.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"partial_dependence_gpr\"] = fig  # Replace with real figure if successful\n",
    "                plt.close(fig)  # Close the default\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating partial dependence plots for GPR: {e}\")\n",
    "        \n",
    "        # 2. Expected Improvement Landscapes\n",
    "        try:\n",
    "            print(\"  Creating EI landscapes...\")\n",
    "            for i, dims in enumerate(important_dim_pairs):\n",
    "                fig = optimizer.plot_expected_improvement_landscape_gpr(dims=dims)\n",
    "                if fig is not None:\n",
    "                    dim_str = f\"dims_{dims[0]}_{dims[1]}\"\n",
    "                    fig.savefig(os.path.join(dirs[\"ei_landscape\"], f\"ei_landscape_gpr_{dim_str}.png\"), dpi=300, bbox_inches='tight')\n",
    "                    all_figures[f\"ei_landscape_gpr_{dim_str}\"] = fig\n",
    "                    plt.close(fig)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating EI landscapes for GPR: {e}\")\n",
    "        \n",
    "        # 3. Decision Boundary Plots\n",
    "        try:\n",
    "            print(\"  Creating decision boundary plots...\")\n",
    "            for i, dims in enumerate(important_dim_pairs):\n",
    "                # Create decision boundaries at different percentiles\n",
    "                for percentile in [50, 75, 90]:\n",
    "                    fig = optimizer.plot_decision_boundary_gpr(dims=dims, threshold_percentile=percentile)\n",
    "                    if fig is not None:\n",
    "                        dim_str = f\"dims_{dims[0]}_{dims[1]}_p{percentile}\"\n",
    "                        fig.savefig(os.path.join(dirs[\"decision_boundary\"], f\"decision_boundary_gpr_{dim_str}.png\"), dpi=300, bbox_inches='tight')\n",
    "                        all_figures[f\"decision_boundary_gpr_{dim_str}\"] = fig\n",
    "                        plt.close(fig)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating decision boundary plots for GPR: {e}\")\n",
    "        \n",
    "        # 4. SHAP Values - Handle with extra care due to 'NoneType' error\n",
    "        try:\n",
    "            print(\"  Creating SHAP plots...\")\n",
    "            try:\n",
    "                summary_fig, dep_figs = optimizer.plot_shap_values_gpr()\n",
    "                \n",
    "                # Check if summary_fig is not None before saving\n",
    "                if summary_fig is not None:\n",
    "                    summary_fig.savefig(os.path.join(dirs[\"shap\"], \"shap_summary_gpr.png\"), dpi=300, bbox_inches='tight')\n",
    "                    all_figures[\"shap_summary_gpr\"] = summary_fig\n",
    "                    plt.close(summary_fig)\n",
    "                \n",
    "                # Check each figure in dep_figs\n",
    "                if dep_figs is not None and hasattr(dep_figs, '__iter__'):\n",
    "                    for i, fig in enumerate(dep_figs):\n",
    "                        if fig is not None:\n",
    "#                            if hasattr(optimizer, 'param_names') and i < len(optimizer.param_names):\n",
    "#                                param_name = optimizer.param_names[i]\n",
    "#                            else:\n",
    "#                                param_name = f\"X{i}\"\n",
    "                            param_name=f\"importance{i+1}\"\n",
    "                            # Sanitize for filename\n",
    "                            param_name = param_name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                            fig.savefig(os.path.join(dirs[\"shap\"], f\"shap_dependence_gpr_{param_name}.png\"), dpi=300, bbox_inches='tight')\n",
    "                            all_figures[f\"shap_dependence_gpr_{param_name}\"] = fig\n",
    "                            plt.close(fig)\n",
    "            except ImportError:\n",
    "                print(\"  SHAP module not found. Skipping SHAP plots.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating SHAP plots for GPR: {e}\")\n",
    "    \n",
    "    # Generate visualizations using BoTorch model\n",
    "    if hasattr(optimizer, 'botorch_gp'):\n",
    "        print(\"\\nGenerating visualizations using BoTorch model...\")\n",
    "        \n",
    "        # 1. Partial Dependence Plots\n",
    "        try:\n",
    "            print(\"  Creating partial dependence plots...\")\n",
    "            # Check if CustomInputTransform is applied correctly\n",
    "            if hasattr(optimizer.botorch_gp, 'input_transform') and optimizer.botorch_gp.input_transform is not None:\n",
    "                # Input transform is set up - check its compatibility\n",
    "                if optimizer.botorch_gp.input_transform.input_dim == optimizer.X.shape[1]:\n",
    "                    fig = optimizer.plot_partial_dependence_botorch(figsize=(15, 3*n_dims))\n",
    "                    if fig is not None:\n",
    "                        fig.savefig(os.path.join(dirs[\"partial_dependence\"], \"partial_dependence_botorch.png\"), dpi=300, bbox_inches='tight')\n",
    "                        all_figures[\"partial_dependence_botorch\"] = fig\n",
    "                        plt.close(fig)\n",
    "                else:\n",
    "                    print(\"  Skipping BoTorch visualization as input_transform dimensions don't match\")\n",
    "            else:\n",
    "                # No input transform - try direct visualization\n",
    "                fig = optimizer.plot_partial_dependence_botorch(figsize=(15, 3*n_dims))\n",
    "                if fig is not None:\n",
    "                    fig.savefig(os.path.join(dirs[\"partial_dependence\"], \"partial_dependence_botorch.png\"), dpi=300, bbox_inches='tight')\n",
    "                    all_figures[\"partial_dependence_botorch\"] = fig\n",
    "                    plt.close(fig)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating partial dependence plots for BoTorch: {e}\")\n",
    "        \n",
    "        # 2. Expected Improvement Landscapes\n",
    "        try:\n",
    "            print(\"  Creating EI landscapes...\")\n",
    "            for i, dims in enumerate(important_dim_pairs):\n",
    "                fig = optimizer.plot_expected_improvement_landscape_botorch(dims=dims)\n",
    "                if fig is not None:\n",
    "                    dim_str = f\"dims_{dims[0]}_{dims[1]}\"\n",
    "                    fig.savefig(os.path.join(dirs[\"ei_landscape\"], f\"ei_landscape_botorch_{dim_str}.png\"), dpi=300, bbox_inches='tight')\n",
    "                    all_figures[f\"ei_landscape_botorch_{dim_str}\"] = fig\n",
    "                    plt.close(fig)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating EI landscapes for BoTorch: {e}\")\n",
    "        \n",
    "        # 3. Decision Boundary Plots\n",
    "        try:\n",
    "            print(\"  Creating decision boundary plots...\")\n",
    "            for i, dims in enumerate(important_dim_pairs):\n",
    "                # Create decision boundaries at different percentiles\n",
    "                for percentile in [50, 75, 90]:\n",
    "                    fig = optimizer.plot_decision_boundary_botorch(dims=dims, threshold_percentile=percentile)\n",
    "                    if fig is not None:\n",
    "                        dim_str = f\"dims_{dims[0]}_{dims[1]}_p{percentile}\"\n",
    "                        fig.savefig(os.path.join(dirs[\"decision_boundary\"], f\"decision_boundary_botorch_{dim_str}.png\"), dpi=300, bbox_inches='tight')\n",
    "                        all_figures[f\"decision_boundary_botorch_{dim_str}\"] = fig\n",
    "                        plt.close(fig)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating decision boundary plots for BoTorch: {e}\")\n",
    "        \n",
    "        # 4. SHAP Values - Handle with extra care due to 'NoneType' error\n",
    "        try:\n",
    "            print(\"  Creating SHAP plots...\")\n",
    "            try:\n",
    "                summary_fig, dep_figs = optimizer.plot_shap_values_gpr()\n",
    "                \n",
    "                # Check if summary_fig is not None before saving\n",
    "                if summary_fig is not None:\n",
    "                    summary_fig.savefig(os.path.join(dirs[\"shap\"], \"shap_summary_botorch.png\"), dpi=300, bbox_inches='tight')\n",
    "                    all_figures[\"shap_summary_gpr\"] = summary_fig\n",
    "                    plt.close(summary_fig)\n",
    "                \n",
    "                # Check each figure in dep_figs\n",
    "                if dep_figs is not None and hasattr(dep_figs, '__iter__'):\n",
    "                    for i, fig in enumerate(dep_figs):\n",
    "                        if fig is not None:\n",
    "#                            if hasattr(optimizer, 'param_names') and i < len(optimizer.param_names):\n",
    "#                                param_name = optimizer.param_names[i]\n",
    "#                            else:\n",
    "#                                param_name = f\"X{i}\"\n",
    "                            param_name=f\"importance{i+1}\"\n",
    "                            # Sanitize for filename\n",
    "                            param_name = param_name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                            fig.savefig(os.path.join(dirs[\"shap\"], f\"shap_dependence_botorch_{param_name}.png\"), dpi=300, bbox_inches='tight')\n",
    "                            all_figures[f\"shap_dependence_botorch_{param_name}\"] = fig\n",
    "                            plt.close(fig)\n",
    "            except ImportError:\n",
    "                print(\"  SHAP module not found. Skipping SHAP plots.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating SHAP plots for BoTorch: {e}\")\n",
    "    \n",
    "    # Generate model-independent visualizations\n",
    "    print(\"\\nGenerating model-independent visualizations...\")\n",
    "    \n",
    "    # 1. Dimensionality Reduction Plots\n",
    "    try:\n",
    "        print(\"  Creating t-SNE plots...\")\n",
    "        for perp in [5,10,30]:\n",
    "            fig = optimizer.plot_tsne_umap(perp=perp)\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"dimensionality_reduction\"], f\"tsne_projection_{perp}.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"tsne_projection\"] = fig\n",
    "                plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating t-SNE plots: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(\"  Creating UMAP plots...\")\n",
    "\n",
    "        fig = optimizer.plot_tsne_umap(method='umap')\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"dimensionality_reduction\"], \"umap_projection.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"umap_projection\"] = fig\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating UMAP plots: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(\"  Creating MDS plots...\")\n",
    "\n",
    "        fig = optimizer.plot_tsne_umap(method='mds')\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"dimensionality_reduction\"], \"mds_projection.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"mds_projection\"] = fig\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating MDS plots: {e}\")\n",
    "               \n",
    "    # 2. Feature Importance Analysis\n",
    "    try:\n",
    "        print(\"  Creating feature importance plot...\")\n",
    "        fig = optimizer.plot_feature_importance()\n",
    "        if fig is not None:\n",
    "            fig.savefig(os.path.join(dirs[\"feature_analysis\"], \"feature_importance.png\"), dpi=300, bbox_inches='tight')\n",
    "            all_figures[\"feature_importance\"] = fig\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating feature importance plots: {e}\")\n",
    "    \n",
    "    # 3. Interaction Heatmap - Skip if BoTorch dimension mismatch is present\n",
    "    try:\n",
    "        print(\"  Creating interaction heatmap...\")\n",
    "        # Try model-agnostic approach with GPR\n",
    "        if hasattr(optimizer, 'gp_best'):\n",
    "            fig = optimizer.plot_interaction_heatmap()\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"feature_analysis\"], \"interaction_heatmap.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"interaction_heatmap\"] = fig\n",
    "                plt.close(fig)\n",
    "        else:\n",
    "            print(\"  Skipping interaction heatmap as GPR model not available\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating interaction heatmap: {e}\")\n",
    "\n",
    "    # 4. \n",
    "    try:\n",
    "        print(\"  Creating model fit plots...\")\n",
    "        if optimizer.n_dim>2:\n",
    "            # Basic PCA visualization\n",
    "            fig = optimizer.plot_model_fit_high_dim(method='pca', n_components=2)\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"model_fits\"], \"model_fits_pca_2d.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"model_fits_pca_2d\"] = fig\n",
    "                plt.close(fig)\n",
    "            \n",
    "            # Using t-SNE for better cluster preservation\n",
    "            fig = optimizer.plot_model_fit_high_dim(method='tsne', n_components=2)\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"model_fits\"], \"model_fits_tsne.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"model_fits_tsne\"] = fig\n",
    "                plt.close(fig)\n",
    "            \n",
    "            # 3D visualization using PCA\n",
    "            fig = optimizer.plot_model_fit_high_dim(method='pca', n_components=3)\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"model_fits\"], \"model_fits_pca_3d.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"model_fits_pca_3d\"] = fig\n",
    "                plt.close(fig)\n",
    "            \n",
    "            # Plotting specific feature dimensions\n",
    "            for i, dims in enumerate(important_dim_pairs):\n",
    "                fig = optimizer.plot_model_fit_high_dim(feature_indices=dims)  # Plot dimensions 1 and 4\n",
    "                dim_str = f\"dims_{dims[0]}_{dims[1]}\"\n",
    "                if fig is not None:\n",
    "                    fig.savefig(os.path.join(dirs[\"model_fits\"], f\"model_fits_feature_{dim_str}.png\"), dpi=300, bbox_inches='tight')\n",
    "                    all_figures[f\"model_fits_pca_{dim_str}\"] = fig\n",
    "                    plt.close(fig)\n",
    "        else:\n",
    "            # Basic PCA visualization\n",
    "            fig = optimizer.plot_model_fit()\n",
    "            if fig is not None:\n",
    "                fig.savefig(os.path.join(dirs[\"model_fits\"], \"model_fit.png\"), dpi=300, bbox_inches='tight')\n",
    "                all_figures[\"model_fit\"] = fig\n",
    "                plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating model fit plots: {e}\")\n",
    "        \n",
    "    # Generate HTML index\n",
    "    try:\n",
    "        generate_html_index(run_dir, dirs)\n",
    "        print(f\"HTML index generated: {os.path.join(run_dir, 'index.html')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating HTML index: {e}\")\n",
    "        # Fallback to simple index\n",
    "        try:\n",
    "            with open(os.path.join(run_dir, 'index_simple.html'), 'w') as f:\n",
    "                f.write(\"<html><body><h1>Bayesian Optimization Visualizations</h1>\")\n",
    "                f.write(\"<p>Generated: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"</p>\")\n",
    "                f.write(\"<p>Please browse the subdirectories to view the visualizations.</p>\")\n",
    "                f.write(\"</body></html>\")\n",
    "            print(f\"Simple HTML index generated as fallback\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return all_figures, run_dir\n",
    "\n",
    "def generate_html_index(run_dir, dirs):\n",
    "    \"\"\"Generate an HTML index file with links to all visualizations.\"\"\"\n",
    "    \n",
    "    # Get current time\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    html_content = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Bayesian Optimization Visualizations</title>\n",
    "    <style>\n",
    "        body { \n",
    "            font-family: Arial, sans-serif; \n",
    "            margin: 0; \n",
    "            padding: 20px; \n",
    "        }\n",
    "        h1 { \n",
    "            color: #2c3e50; \n",
    "        }\n",
    "        h2 { \n",
    "            color: #3498db; \n",
    "            margin-top: 30px; \n",
    "        }\n",
    "        .gallery { \n",
    "            display: flex; \n",
    "            flex-wrap: wrap; \n",
    "            gap: 20px; \n",
    "        }\n",
    "        .gallery-item { \n",
    "            border: 1px solid #ddd; \n",
    "            padding: 10px; \n",
    "            border-radius: 5px;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            width: 300px;\n",
    "        }\n",
    "        .gallery-item img { \n",
    "            width: 100%; \n",
    "            height: auto; \n",
    "        }\n",
    "        .gallery-item p { \n",
    "            margin: 5px 0; \n",
    "            font-size: 14px; \n",
    "        }\n",
    "        .section { \n",
    "            margin-bottom: 30px; \n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Bayesian Optimization Visualizations</h1>\n",
    "    <p>Generated: \"\"\" + current_time + \"\"\"</p>\n",
    "\"\"\"\n",
    "    \n",
    "    # Add each section\n",
    "    section_titles = {\n",
    "        \"partial_dependence\": \"Partial Dependence Plots\",\n",
    "        \"ei_landscape\": \"Expected Improvement Landscapes\",\n",
    "        \"decision_boundary\": \"Decision Boundary Plots\",\n",
    "        \"dimensionality_reduction\": \"Dimensionality Reduction\",\n",
    "        \"shap\": \"SHAP Analysis\",\n",
    "        \"feature_analysis\": \"Feature Importance and Interactions\"\n",
    "    }\n",
    "    \n",
    "    for section_key, section_dir in dirs.items():\n",
    "        section_title = section_titles.get(section_key, section_key.capitalize())\n",
    "        html_content += f\"<h2>{section_title}</h2>\\n<div class='section'>\\n<div class='gallery'>\\n\"\n",
    "        \n",
    "        # Get image files in this directory\n",
    "        try:\n",
    "            image_files = [f for f in os.listdir(section_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            image_files.sort()\n",
    "            \n",
    "            if not image_files:\n",
    "                html_content += \"<p>No images found in this section</p>\\n\"\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                rel_path = f\"{os.path.basename(section_dir)}/{img_file}\"\n",
    "                img_title = img_file.replace('.png', '').replace('_', ' ')\n",
    "                html_content += f\"\"\"\n",
    "                <div class=\"gallery-item\">\n",
    "                    <p>{img_title}</p>\n",
    "                    <a href=\"{rel_path}\" target=\"_blank\">\n",
    "                        <img src=\"{rel_path}\" alt=\"{img_title}\">\n",
    "                    </a>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        except Exception as e:\n",
    "            html_content += f\"<p>Error loading images: {str(e)}</p>\\n\"\n",
    "        \n",
    "        html_content += \"</div>\\n</div>\\n\"\n",
    "    \n",
    "    # Close the HTML\n",
    "    html_content += \"\"\"\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    \n",
    "    # Write to file\n",
    "    with open(os.path.join(run_dir, 'index.html'), 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35afc0-280f-41a1-bcec-8819345e994a",
   "metadata": {},
   "source": [
    "The next section deals with a workflow to run the optimiser over a series of different submissions, saving/loading state inbetween\n",
    "and monitoring the progress of the optimisation. It also contains logic to reverse engineer which techniques may have been used to select previous candidates, if a record was not kept at the time.\n",
    "\n",
    "This workflow is not currently used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8783df55-c85c-44a7-87c1-249053abba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assorted workflow functions if maintaining history inside the optimiser to analyse performance of different techniques.\n",
    "# Includes functions to save/load state and also to reverse engineer history if it hasn't been stored.\n",
    "\n",
    "def reverse_engineer_method_history(X_all, y_all, n_initial, n_added=None):\n",
    "    \"\"\"\n",
    "    Reverse-engineer which methods were likely used to generate candidates.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_all : numpy.ndarray\n",
    "        All input points including initial and added points\n",
    "    y_all : numpy.ndarray\n",
    "        All output values\n",
    "    n_initial : int\n",
    "        Number of initial points before candidate suggestions began\n",
    "    n_added : int, optional\n",
    "        Number of points that were added through the optimization process.\n",
    "        If None, inferred as len(X_all) - n_initial\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optimizer : BayesianOptimizer\n",
    "        Optimizer with reconstructed history\n",
    "    method_matches : list\n",
    "        List of tuples with (iteration, best_method, distance) information\n",
    "    \"\"\"\n",
    "    # Determine n_added if not provided\n",
    "    if n_added is None:\n",
    "        n_added = len(X_all) - n_initial\n",
    "    \n",
    "    # Validate inputs\n",
    "    if n_initial + n_added != len(X_all):\n",
    "        raise ValueError(\"n_initial + n_added must equal the total number of observations\")\n",
    "    \n",
    "    # Separate initial data from added data\n",
    "    X_initial = X_all[:n_initial]\n",
    "    y_initial = y_all[:n_initial]\n",
    "    \n",
    "    # Set up the bounds\n",
    "    n_dim = X_initial.shape[1]\n",
    "    bounds = np.array([[0.0, 1.0] for _ in range(n_dim)])\n",
    "    \n",
    "    # Initialize optimizer with initial data\n",
    "    optimizer = BayesianOptimizer(X_initial, y_initial, bounds)\n",
    "    \n",
    "    # List to store method match information\n",
    "    method_matches = []\n",
    "    \n",
    "    # Available methods to test\n",
    "    methods = [\n",
    "        'ei', 'log_ei', 'ucb', 'pi',\n",
    "        'botorch_ei', 'botorch_log_ei', 'botorch_ucb', 'botorch_pi',\n",
    "        'hyperopt', 'bootstrap', 'cv'\n",
    "    ]\n",
    "    \n",
    "    # For each added point\n",
    "    for i in range(n_added):\n",
    "        current_idx = n_initial + i\n",
    "        actual_next_point = X_all[current_idx]\n",
    "        actual_next_value = y_all[current_idx]\n",
    "        \n",
    "        print(f\"\\nAnalyzing observation {current_idx} (iteration {i+1}/{n_added})...\")\n",
    "        \n",
    "        # Generate candidates using each method\n",
    "        candidates = {}\n",
    "        distances = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            try:\n",
    "                # Generate candidate using this method\n",
    "                candidate = optimizer.get_next_candidate(method=method)[0]\n",
    "                \n",
    "                # Calculate Euclidean distance to actual point\n",
    "                distance = np.linalg.norm(candidate - actual_next_point)\n",
    "                \n",
    "                candidates[method] = candidate\n",
    "                distances[method] = distance\n",
    "                \n",
    "                print(f\"  Method {method}: distance = {distance:.6f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error with method {method}: {e}\")\n",
    "                distances[method] = float('inf')\n",
    "        \n",
    "        # Find method with closest candidate\n",
    "        best_method = min(distances, key=distances.get)\n",
    "        best_distance = distances[best_method]\n",
    "        \n",
    "        print(f\"Best match: {best_method} (distance: {best_distance:.6f})\")\n",
    "        \n",
    "        # Store match information\n",
    "        method_matches.append((current_idx, best_method, best_distance))\n",
    "        \n",
    "        # Update optimizer with actual point and inferred method\n",
    "        optimizer.update(actual_next_point, actual_next_value, best_method)\n",
    "    \n",
    "    # Generate analysis\n",
    "    method_counts = {}\n",
    "    for _, method, _ in method_matches:\n",
    "        method_counts[method] = method_counts.get(method, 0) + 1\n",
    "    \n",
    "    print(\"\\nMethod usage analysis:\")\n",
    "    for method, count in sorted(method_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {method}: {count} times ({count/n_added:.1%})\")\n",
    "    \n",
    "    # Compute average distance by method\n",
    "    method_distances = {}\n",
    "    for _, method, dist in method_matches:\n",
    "        if method not in method_distances:\n",
    "            method_distances[method] = []\n",
    "        method_distances[method].append(dist)\n",
    "    \n",
    "    print(\"\\nAverage distance by method:\")\n",
    "    for method, distances in method_distances.items():\n",
    "        avg_dist = sum(distances) / len(distances)\n",
    "        print(f\"  {method}: {avg_dist:.6f}\")\n",
    "    \n",
    "    return optimizer, method_matches\n",
    "\n",
    "def initialize_optimizer_from_files(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Initialize an optimizer from input and output files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_file : str\n",
    "        Path to the input file (.npy)\n",
    "    output_file : str\n",
    "        Path to the output file (.npy)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optimizer : BayesianOptimizer\n",
    "        Initialized optimizer\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    X = np.load(input_file)\n",
    "    y = np.load(output_file)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Loaded data: {len(X)} observations, {X.shape[1]} dimensions\")\n",
    "    \n",
    "    # Display sample of data\n",
    "    sample_df = pd.DataFrame(X)\n",
    "    sample_df.columns = [f\"x{i}\" for i in range(X.shape[1])]\n",
    "    sample_df['y'] = y\n",
    "    print(sample_df)\n",
    "    \n",
    "    # Set up bounds\n",
    "    n_dim = X.shape[1]\n",
    "    bounds = np.array([[0.0, 1.0] for _ in range(n_dim)])\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = BayesianOptimizer(X, y, bounds)\n",
    "    \n",
    "    # Print optimizer information\n",
    "    print(f\"Initialized optimizer with {len(X)} observations\")\n",
    "    print(f\"Best value: {optimizer.best_y:.6f} at index {optimizer.best_idx}\")\n",
    "    \n",
    "    # Determine if log transform is being used\n",
    "    if optimizer.use_log_y:\n",
    "        print(\"Using log transformation for outputs\")\n",
    "    else:\n",
    "        print(\"Not using log transformation for outputs\")\n",
    "    \n",
    "    # Print best kernel\n",
    "    print(f\"Using {optimizer.best_kernel_name} kernel\")\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "def recommend_next_candidate(optimizer, save_file=None):\n",
    "    \"\"\"\n",
    "    Recommend and save the next candidate point to evaluate.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    optimizer : BayesianOptimizer\n",
    "        The optimizer to use\n",
    "    save_file : str, optional\n",
    "        Path to save the candidate to. If None, not saved.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x_next : numpy.ndarray\n",
    "        The next candidate point to evaluate\n",
    "    \"\"\"\n",
    "    # Get next candidate recommendation\n",
    "    x_next, method, candidates_df = optimizer.suggest_next_candidate()\n",
    "    \n",
    "    # Print recommendation\n",
    "    print(f\"Recommended next candidate using {method}:\")\n",
    "    print(x_next)\n",
    "    \n",
    "    # Save candidate if requested\n",
    "    if save_file is not None:\n",
    "        np.save(save_file, x_next)\n",
    "        print(f\"Candidate saved to {save_file}\")\n",
    "    \n",
    "    return x_next\n",
    "\n",
    "def update_with_new_observation(optimizer, x_next, y_next, method=None, save_file=None):\n",
    "    \"\"\"\n",
    "    Update the optimizer with a new observation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    optimizer : BayesianOptimizer\n",
    "        The optimizer to update\n",
    "    x_next : numpy.ndarray\n",
    "        The input point that was evaluated\n",
    "    y_next : float\n",
    "        The observed function value\n",
    "    method : str, optional\n",
    "        The method used to generate x_next\n",
    "    save_file : str, optional\n",
    "        Path to save the updated optimizer to\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    optimizer : BayesianOptimizer\n",
    "        The updated optimizer\n",
    "    \"\"\"\n",
    "    # Update the optimizer\n",
    "    optimizer.update(x_next, y_next, method)\n",
    "    \n",
    "    # Print update information\n",
    "    print(f\"Updated optimizer with new observation: f({x_next}) = {y_next:.6f}\")\n",
    "    print(f\"Current best value: {optimizer.best_y:.6f} at {optimizer.best_x}\")\n",
    "    \n",
    "    # Save optimizer if requested\n",
    "    if save_file is not None:\n",
    "        optimizer.save_state(save_file)\n",
    "        print(f\"Optimizer saved to {save_file}\")\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "# Example of a weekly workflow\n",
    "def weekly_workflow_example():\n",
    "    \"\"\"Example of how to use the optimizer in a weekly workflow.\"\"\"\n",
    "    print(\"Week 1: Initialize the optimizer and get first candidate\")\n",
    "    # Initialize optimizer from files (assuming you have these files)\n",
    "    # optimizer = initialize_optimizer_from_files(\"inputs.npy\", \"outputs.npy\")\n",
    "    \n",
    "    # For this example, we'll create some synthetic data\n",
    "    X_init = np.random.uniform(0, 1, size=(10, 4))\n",
    "    y_init = np.sum(X_init**2, axis=1)  # Simple function for demonstration\n",
    "    \n",
    "    n_dim = X_init.shape[1]\n",
    "    bounds = np.array([[0.0, 1.0] for _ in range(n_dim)])\n",
    "    optimizer = BayesianOptimizer(X_init, y_init, bounds)\n",
    "    \n",
    "    # Get first candidate to evaluate\n",
    "    x_next = recommend_next_candidate(optimizer, save_file=\"week1_candidate.npy\")\n",
    "    \n",
    "    print(\"\\nWeek 2: Update with last week's result and get new candidate\")\n",
    "    # In a real scenario, you'd evaluate x_next on your real function\n",
    "    # Here we'll simulate the evaluation\n",
    "    y_next = np.sum(x_next**2)  # Simple function for demonstration\n",
    "    \n",
    "    # Update the optimizer with the new observation\n",
    "    optimizer = update_with_new_observation(\n",
    "        optimizer, x_next, y_next, \n",
    "        method=\"blend\", save_file=\"optimizer_week2.pkl\"\n",
    "    )\n",
    "    \n",
    "    # Visualize and analyze\n",
    "    optimizer.visualize_optimization()\n",
    "    \n",
    "    # Get next candidate\n",
    "    x_next = recommend_next_candidate(optimizer, save_file=\"week2_candidate.npy\")\n",
    "    \n",
    "    print(\"\\nWeek 3: Load last week's optimizer and continue\")\n",
    "    # You could load the saved optimizer\n",
    "    # optimizer = BayesianOptimizer.load_state(\"optimizer_week2.pkl\")\n",
    "    \n",
    "    # Update with the new observation\n",
    "    y_next = np.sum(x_next**2)  # Simple function for demonstration\n",
    "    optimizer = update_with_new_observation(\n",
    "        optimizer, x_next, y_next, \n",
    "        method=\"blend\", save_file=\"optimizer_week3.pkl\"\n",
    "    )\n",
    "    \n",
    "    # Cross validate to check model quality\n",
    "    optimizer.cross_validate_models()\n",
    "    \n",
    "    # Get next candidate\n",
    "    x_next = recommend_next_candidate(optimizer, save_file=\"week3_candidate.npy\")\n",
    "    \n",
    "    print(\"\\nAnd so on for future weeks...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c099a1-c08b-4e78-b059-ca137a408905",
   "metadata": {},
   "source": [
    "This is the main function to run the optimisation for the Imperial College ML/AI Capstone Competition, using the BayesianOptimizer class.\n",
    "\n",
    "The iterations can be ignored unless the intent is to simulate several steps into the future, assuming that function outputs will turn out to be exactly as the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f79a9d1-fcf6-4a49-9edf-e1fc285471bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run optimisation\n",
    "\n",
    "def run_optimization(X_init, y_init, feature_transformer=None, n_iterations=0, log_transform=None, output_dir='visualization_results'):\n",
    "    \"\"\"\n",
    "    Run a complete optimization process.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_init : numpy.ndarray\n",
    "        Initial input points\n",
    "    y_init : numpy.ndarray\n",
    "        Function values at initial points\n",
    "    feature_transformer: FeatureTransformer (optional)\n",
    "        Class to add feature engineering\n",
    "    n_iterations : int (optional)\n",
    "        Number of iterations to run\n",
    "    log_transform : bool or None\n",
    "        Whether to use log transformation. If None, it's determined automatically.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    optimizer : BayesianOptimizer\n",
    "        The optimizer after all iterations\n",
    "    \"\"\"\n",
    "    # Get dimensions and bounds\n",
    "    n_dim = X_init.shape[1]\n",
    "    bounds = np.array([[0, 0.999999] for _ in range(n_dim)]) # was 1\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = BayesianOptimizer(X_init, y_init, bounds, feature_transformer=feature_transformer)\n",
    "\n",
    "#    print(\"\\nLoaded data:\")\n",
    "#    optimizer.print_data()\n",
    "\n",
    "    # Print initial information\n",
    "    print(f\"\\nStarting optimization with {len(X_init)} initial points in {n_dim} dimensions.\")\n",
    "    print(f\"\\nBest initial value: {optimizer.best_y} at {optimizer.best_x}\")\n",
    "    if feature_transformer is not None:\n",
    "        print(\"\\nFeature engineering enabled.\")\n",
    "    \n",
    "    # Override log transform setting if specified\n",
    "    if log_transform is not None:\n",
    "        optimizer.use_log_y = log_transform\n",
    "        if optimizer.use_log_y:\n",
    "            optimizer.y_log = np.log1p(optimizer.y)\n",
    "            print(\"\\nUsing log transformation for y values\")\n",
    "        else:\n",
    "            print(\"\\nNot using log transformation for y values\")\n",
    "    \n",
    "    print(\"\\nInitialising models and cross-validating to choose best kernel...\")\n",
    "    optimizer.init_models()\n",
    "\n",
    "    if optimizer.is_warped:\n",
    "        # Analyze the learned warping\n",
    "        params_analysis = optimizer.analyze_warping_parameters()\n",
    "        \n",
    "        # Visualize warping if 1D or 2D\n",
    "        if optimizer.n_dim_processed <= 2:\n",
    "            warp_fig = optimizer.visualize_warping()\n",
    "            warp_fig.savefig(\"warping_visualization.png\")\n",
    "            plt.show()\n",
    "    \n",
    "    # Run the optimization loop\n",
    "    for i in range(n_iterations):\n",
    "        print(f\"\\nIteration {i+1}/{n_iterations}\")\n",
    "        \n",
    "        # Suggest next candidate\n",
    "        try:\n",
    "            x_next, method, candidates_df = optimizer.suggest_next_candidate()\n",
    "            print(f\"Selected method: {method}\")\n",
    "            print(f\"Next candidate: {x_next}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error suggesting next candidate: {e}\")\n",
    "            x_next = optimizer.get_next_candidate_ei()  # Fall back to basic EI\n",
    "            method = \"fallback_ei\"\n",
    "            print(f\"Falling back to EI. Next candidate: {x_next}\")\n",
    "        \n",
    "        # This would be where you evaluate the real function\n",
    "        # For the purpose of this example, we'll use the GP model's prediction\n",
    "        X_processed = optimizer._preprocess_X(x_next.reshape(1, -1))\n",
    "        \n",
    "        # Use best GP for prediction\n",
    "        mu, sigma = optimizer.gp_best.predict(X_processed, return_std=True)\n",
    "        \n",
    "        # If using log transform, convert prediction back to original scale\n",
    "        if optimizer.use_log_y:\n",
    "            y_next = float(np.expm1(mu[0]))\n",
    "        else:\n",
    "            y_next = float(mu[0])\n",
    "        \n",
    "        # Add some noise to simulate real-world evaluation\n",
    "#        y_next = y_next * (1 + np.random.normal(0, 0.05))  # 5% noise\n",
    "        \n",
    "        print(f\"Predicted function value: {y_next:.6f}\")\n",
    "        \n",
    "        # Update optimizer with new observation\n",
    "        optimizer.update(x_next, y_next, method)\n",
    "        \n",
    "        # Print current best\n",
    "        print(f\"Current best value: {optimizer.best_y:.6f}\")\n",
    "        \n",
    "        # Visualize optimization progress\n",
    "        try:\n",
    "            optimizer.visualize_optimization()\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing optimization: {e}\")\n",
    "                \n",
    "        # Save state periodically\n",
    "        if (i + 1) % 5 == 0 or i == n_iterations - 1:\n",
    "            optimizer.save_state(f\"optimizer_state_iter_{i+1}.pkl\")\n",
    "    \n",
    "    # Get the final best candidate\n",
    "    final_candidate, _, _ = optimizer.suggest_next_candidate()\n",
    "    print(f\"\\nFinal suggested candidate:\",\"-\".join(f'{x:.6f}' for x in final_candidate))\n",
    "    print(f\"Best observed value: {optimizer.best_y:.6f} at {optimizer.best_x}\")\n",
    "    \n",
    "    # Generate visualizations\n",
    "    figures, output_dir = generate_all_visualizations(optimizer, output_dir=output_dir)\n",
    "    \n",
    "    # The function returns a dictionary of figures and the output directory\n",
    "#    print(f\"Available figures: {list(figures.keys())}\")\n",
    "    print(f\"All visualizations saved to: {output_dir}\")\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261cd253-577f-4595-a4b9-99c8404a827a",
   "metadata": {},
   "source": [
    "The next section covers straightforward helper functions to load the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ff5533-b6cb-4aef-97bf-25657a3ac17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to load the Imperial ML/AI dataset and inspect it\n",
    "\n",
    "def load_data(x_path, y_path):\n",
    "    \"\"\"Load data from .npy files.\"\"\"\n",
    "    X = np.load(x_path)\n",
    "    y = np.load(y_path)\n",
    "    return X, y\n",
    "\n",
    "def highlight_top_values(s):\n",
    "    \"\"\"\n",
    "    Highlight the top 5 values in a series.\n",
    "    Highest in green, next 4 in orange.\n",
    "    \"\"\"\n",
    "    # Get the sorted unique values in descending order\n",
    "    sorted_vals = s.nlargest(5)\n",
    "    \n",
    "    # Create styles list\n",
    "    styles = [''] * len(s)\n",
    "    \n",
    "    for i, val in enumerate(s):\n",
    "        if val == sorted_vals.iloc[0]:  # Highest value\n",
    "            styles[i] = 'background-color: green; color: white'\n",
    "        elif len(sorted_vals) > 1 and val in sorted_vals.iloc[1:5].values:  # Next 4 highest\n",
    "            styles[i] = 'background-color: orange; color: white'\n",
    "    \n",
    "    return styles\n",
    "\n",
    "def load_imperial_data(func_num, input_dir):\n",
    "    X_path = input_dir+'/function_'+str(func_num)+'_inputs.npy'\n",
    "    y_path = input_dir+'/function_'+str(func_num)+'_outputs.npy'\n",
    "    \n",
    "    X, y = load_data(X_path, y_path)\n",
    "    print(f\"Loaded data for function {func_num}: {X.shape[0]} observations, {X.shape[1]} dimensions\")\n",
    "\n",
    "    colnames = []\n",
    "    for i in range(X.shape[1]):\n",
    "        colnames.append('x'+str(i))\n",
    "    colnames.append('y')\n",
    "\n",
    "    df = pd.DataFrame(np.column_stack((X, y)),columns=colnames)\n",
    "    styled_df = (df.style\n",
    "                 .apply(highlight_top_values, subset=['y'])\n",
    "                 .format(precision=6))\n",
    "    display(styled_df)\n",
    "    \n",
    "#    X = X[:,0:1] # just analyse 1D for comparison, if there's a dominant dimension\n",
    "    \n",
    "    y = y.flatten()\n",
    "    \n",
    "    #get the input dimensions\n",
    "    dim_X = X.shape[-1]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81bb66-af30-499b-a51d-b71a2610012a",
   "metadata": {},
   "source": [
    "This is the high-level wrapper function to run the optimisation for a particular function number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f11571-7127-4b25-836c-db14a39b5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main method to run optimisation for a particular Imperial Capstone function\n",
    "\n",
    "def run_func(func_num, use_features=True, input_dir='Functions/Source_Data', output_dir='Functions/Visualisations'):\n",
    "    \"\"\"Run optimisation for Imperial Capstone function 1..8 with/without feature engineering\"\"\"\n",
    "    X_init, y_init = load_imperial_data(func_num, input_dir)\n",
    "\n",
    "    # Run optimization\n",
    "    optimizer = run_optimization(X_init, y_init, feature_transformer=TransformerFactory.create_transformer(func_num) if use_features else None, output_dir=output_dir)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cd08268-8837-43c6-ae44-65dd732ba1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for function 3: 49 observations, 3 dimensions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1d6c6_row16_col3, #T_1d6c6_row17_col3, #T_1d6c6_row18_col3, #T_1d6c6_row47_col3 {\n",
       "  background-color: orange;\n",
       "  color: white;\n",
       "}\n",
       "#T_1d6c6_row27_col3 {\n",
       "  background-color: green;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1d6c6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1d6c6_level0_col0\" class=\"col_heading level0 col0\" >x0</th>\n",
       "      <th id=\"T_1d6c6_level0_col1\" class=\"col_heading level0 col1\" >x1</th>\n",
       "      <th id=\"T_1d6c6_level0_col2\" class=\"col_heading level0 col2\" >x2</th>\n",
       "      <th id=\"T_1d6c6_level0_col3\" class=\"col_heading level0 col3\" >y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1d6c6_row0_col0\" class=\"data row0 col0\" >0.171525</td>\n",
       "      <td id=\"T_1d6c6_row0_col1\" class=\"data row0 col1\" >0.343917</td>\n",
       "      <td id=\"T_1d6c6_row0_col2\" class=\"data row0 col2\" >0.248737</td>\n",
       "      <td id=\"T_1d6c6_row0_col3\" class=\"data row0 col3\" >-0.112122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1d6c6_row1_col0\" class=\"data row1 col0\" >0.242114</td>\n",
       "      <td id=\"T_1d6c6_row1_col1\" class=\"data row1 col1\" >0.644074</td>\n",
       "      <td id=\"T_1d6c6_row1_col2\" class=\"data row1 col2\" >0.272433</td>\n",
       "      <td id=\"T_1d6c6_row1_col3\" class=\"data row1 col3\" >-0.087963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1d6c6_row2_col0\" class=\"data row2 col0\" >0.534906</td>\n",
       "      <td id=\"T_1d6c6_row2_col1\" class=\"data row2 col1\" >0.398501</td>\n",
       "      <td id=\"T_1d6c6_row2_col2\" class=\"data row2 col2\" >0.173389</td>\n",
       "      <td id=\"T_1d6c6_row2_col3\" class=\"data row2 col3\" >-0.111415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1d6c6_row3_col0\" class=\"data row3 col0\" >0.492581</td>\n",
       "      <td id=\"T_1d6c6_row3_col1\" class=\"data row3 col1\" >0.611593</td>\n",
       "      <td id=\"T_1d6c6_row3_col2\" class=\"data row3 col2\" >0.340176</td>\n",
       "      <td id=\"T_1d6c6_row3_col3\" class=\"data row3 col3\" >-0.034835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1d6c6_row4_col0\" class=\"data row4 col0\" >0.134622</td>\n",
       "      <td id=\"T_1d6c6_row4_col1\" class=\"data row4 col1\" >0.219917</td>\n",
       "      <td id=\"T_1d6c6_row4_col2\" class=\"data row4 col2\" >0.458206</td>\n",
       "      <td id=\"T_1d6c6_row4_col3\" class=\"data row4 col3\" >-0.048008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1d6c6_row5_col0\" class=\"data row5 col0\" >0.345523</td>\n",
       "      <td id=\"T_1d6c6_row5_col1\" class=\"data row5 col1\" >0.941360</td>\n",
       "      <td id=\"T_1d6c6_row5_col2\" class=\"data row5 col2\" >0.269363</td>\n",
       "      <td id=\"T_1d6c6_row5_col3\" class=\"data row5 col3\" >-0.110621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1d6c6_row6_col0\" class=\"data row6 col0\" >0.151837</td>\n",
       "      <td id=\"T_1d6c6_row6_col1\" class=\"data row6 col1\" >0.439991</td>\n",
       "      <td id=\"T_1d6c6_row6_col2\" class=\"data row6 col2\" >0.990882</td>\n",
       "      <td id=\"T_1d6c6_row6_col3\" class=\"data row6 col3\" >-0.398926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1d6c6_row7_col0\" class=\"data row7 col0\" >0.645503</td>\n",
       "      <td id=\"T_1d6c6_row7_col1\" class=\"data row7 col1\" >0.397143</td>\n",
       "      <td id=\"T_1d6c6_row7_col2\" class=\"data row7 col2\" >0.919771</td>\n",
       "      <td id=\"T_1d6c6_row7_col3\" class=\"data row7 col3\" >-0.113869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1d6c6_row8_col0\" class=\"data row8 col0\" >0.746912</td>\n",
       "      <td id=\"T_1d6c6_row8_col1\" class=\"data row8 col1\" >0.284196</td>\n",
       "      <td id=\"T_1d6c6_row8_col2\" class=\"data row8 col2\" >0.226300</td>\n",
       "      <td id=\"T_1d6c6_row8_col3\" class=\"data row8 col3\" >-0.131461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1d6c6_row9_col0\" class=\"data row9 col0\" >0.170477</td>\n",
       "      <td id=\"T_1d6c6_row9_col1\" class=\"data row9 col1\" >0.697032</td>\n",
       "      <td id=\"T_1d6c6_row9_col2\" class=\"data row9 col2\" >0.149169</td>\n",
       "      <td id=\"T_1d6c6_row9_col3\" class=\"data row9 col3\" >-0.094190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1d6c6_row10_col0\" class=\"data row10 col0\" >0.220549</td>\n",
       "      <td id=\"T_1d6c6_row10_col1\" class=\"data row10 col1\" >0.297825</td>\n",
       "      <td id=\"T_1d6c6_row10_col2\" class=\"data row10 col2\" >0.343555</td>\n",
       "      <td id=\"T_1d6c6_row10_col3\" class=\"data row10 col3\" >-0.046947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1d6c6_row11_col0\" class=\"data row11 col0\" >0.666014</td>\n",
       "      <td id=\"T_1d6c6_row11_col1\" class=\"data row11 col1\" >0.671985</td>\n",
       "      <td id=\"T_1d6c6_row11_col2\" class=\"data row11 col2\" >0.246295</td>\n",
       "      <td id=\"T_1d6c6_row11_col3\" class=\"data row11 col3\" >-0.105965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1d6c6_row12_col0\" class=\"data row12 col0\" >0.046809</td>\n",
       "      <td id=\"T_1d6c6_row12_col1\" class=\"data row12 col1\" >0.231360</td>\n",
       "      <td id=\"T_1d6c6_row12_col2\" class=\"data row12 col2\" >0.770618</td>\n",
       "      <td id=\"T_1d6c6_row12_col3\" class=\"data row12 col3\" >-0.118048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1d6c6_row13_col0\" class=\"data row13 col0\" >0.600097</td>\n",
       "      <td id=\"T_1d6c6_row13_col1\" class=\"data row13 col1\" >0.725136</td>\n",
       "      <td id=\"T_1d6c6_row13_col2\" class=\"data row13 col2\" >0.066089</td>\n",
       "      <td id=\"T_1d6c6_row13_col3\" class=\"data row13 col3\" >-0.036378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1d6c6_row14_col0\" class=\"data row14 col0\" >0.965995</td>\n",
       "      <td id=\"T_1d6c6_row14_col1\" class=\"data row14 col1\" >0.861120</td>\n",
       "      <td id=\"T_1d6c6_row14_col2\" class=\"data row14 col2\" >0.566829</td>\n",
       "      <td id=\"T_1d6c6_row14_col3\" class=\"data row14 col3\" >-0.056758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1d6c6_row15_col0\" class=\"data row15 col0\" >0.999999</td>\n",
       "      <td id=\"T_1d6c6_row15_col1\" class=\"data row15 col1\" >0.999999</td>\n",
       "      <td id=\"T_1d6c6_row15_col2\" class=\"data row15 col2\" >0.396517</td>\n",
       "      <td id=\"T_1d6c6_row15_col3\" class=\"data row15 col3\" >-0.058021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1d6c6_row16_col0\" class=\"data row16 col0\" >0.405086</td>\n",
       "      <td id=\"T_1d6c6_row16_col1\" class=\"data row16 col1\" >0.517313</td>\n",
       "      <td id=\"T_1d6c6_row16_col2\" class=\"data row16 col2\" >0.406218</td>\n",
       "      <td id=\"T_1d6c6_row16_col3\" class=\"data row16 col3\" >-0.008446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1d6c6_row17_col0\" class=\"data row17 col0\" >0.475566</td>\n",
       "      <td id=\"T_1d6c6_row17_col1\" class=\"data row17 col1\" >0.529357</td>\n",
       "      <td id=\"T_1d6c6_row17_col2\" class=\"data row17 col2\" >0.414437</td>\n",
       "      <td id=\"T_1d6c6_row17_col3\" class=\"data row17 col3\" >-0.003723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1d6c6_row18_col0\" class=\"data row18 col0\" >0.526346</td>\n",
       "      <td id=\"T_1d6c6_row18_col1\" class=\"data row18 col1\" >0.512826</td>\n",
       "      <td id=\"T_1d6c6_row18_col2\" class=\"data row18 col2\" >0.419945</td>\n",
       "      <td id=\"T_1d6c6_row18_col3\" class=\"data row18 col3\" >-0.004598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_1d6c6_row19_col0\" class=\"data row19 col0\" >0.445183</td>\n",
       "      <td id=\"T_1d6c6_row19_col1\" class=\"data row19 col1\" >0.496346</td>\n",
       "      <td id=\"T_1d6c6_row19_col2\" class=\"data row19 col2\" >0.525158</td>\n",
       "      <td id=\"T_1d6c6_row19_col3\" class=\"data row19 col3\" >-0.036488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_1d6c6_row20_col0\" class=\"data row20 col0\" >0.979377</td>\n",
       "      <td id=\"T_1d6c6_row20_col1\" class=\"data row20 col1\" >0.336098</td>\n",
       "      <td id=\"T_1d6c6_row20_col2\" class=\"data row20 col2\" >0.809156</td>\n",
       "      <td id=\"T_1d6c6_row20_col3\" class=\"data row20 col3\" >-0.058703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_1d6c6_row21_col0\" class=\"data row21 col0\" >0.366582</td>\n",
       "      <td id=\"T_1d6c6_row21_col1\" class=\"data row21 col1\" >0.382880</td>\n",
       "      <td id=\"T_1d6c6_row21_col2\" class=\"data row21 col2\" >0.402292</td>\n",
       "      <td id=\"T_1d6c6_row21_col3\" class=\"data row21 col3\" >-0.029129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_1d6c6_row22_col0\" class=\"data row22 col0\" >0.225879</td>\n",
       "      <td id=\"T_1d6c6_row22_col1\" class=\"data row22 col1\" >0.000000</td>\n",
       "      <td id=\"T_1d6c6_row22_col2\" class=\"data row22 col2\" >0.301942</td>\n",
       "      <td id=\"T_1d6c6_row22_col3\" class=\"data row22 col3\" >-0.145160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_1d6c6_row23_col0\" class=\"data row23 col0\" >0.592158</td>\n",
       "      <td id=\"T_1d6c6_row23_col1\" class=\"data row23 col1\" >0.662181</td>\n",
       "      <td id=\"T_1d6c6_row23_col2\" class=\"data row23 col2\" >0.429162</td>\n",
       "      <td id=\"T_1d6c6_row23_col3\" class=\"data row23 col3\" >-0.012445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_1d6c6_row24_col0\" class=\"data row24 col0\" >0.629127</td>\n",
       "      <td id=\"T_1d6c6_row24_col1\" class=\"data row24 col1\" >0.527232</td>\n",
       "      <td id=\"T_1d6c6_row24_col2\" class=\"data row24 col2\" >0.389118</td>\n",
       "      <td id=\"T_1d6c6_row24_col3\" class=\"data row24 col3\" >-0.009772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_1d6c6_row25_col0\" class=\"data row25 col0\" >0.000000</td>\n",
       "      <td id=\"T_1d6c6_row25_col1\" class=\"data row25 col1\" >0.640754</td>\n",
       "      <td id=\"T_1d6c6_row25_col2\" class=\"data row25 col2\" >0.358734</td>\n",
       "      <td id=\"T_1d6c6_row25_col3\" class=\"data row25 col3\" >-0.024282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_1d6c6_row26_col0\" class=\"data row26 col0\" >0.000000</td>\n",
       "      <td id=\"T_1d6c6_row26_col1\" class=\"data row26 col1\" >0.640754</td>\n",
       "      <td id=\"T_1d6c6_row26_col2\" class=\"data row26 col2\" >0.358734</td>\n",
       "      <td id=\"T_1d6c6_row26_col3\" class=\"data row26 col3\" >-0.051925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_1d6c6_row27_col0\" class=\"data row27 col0\" >0.407010</td>\n",
       "      <td id=\"T_1d6c6_row27_col1\" class=\"data row27 col1\" >0.573911</td>\n",
       "      <td id=\"T_1d6c6_row27_col2\" class=\"data row27 col2\" >0.428134</td>\n",
       "      <td id=\"T_1d6c6_row27_col3\" class=\"data row27 col3\" >-0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_1d6c6_row28_col0\" class=\"data row28 col0\" >0.114496</td>\n",
       "      <td id=\"T_1d6c6_row28_col1\" class=\"data row28 col1\" >0.934405</td>\n",
       "      <td id=\"T_1d6c6_row28_col2\" class=\"data row28 col2\" >0.999329</td>\n",
       "      <td id=\"T_1d6c6_row28_col3\" class=\"data row28 col3\" >-0.480436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_1d6c6_row29_col0\" class=\"data row29 col0\" >0.165700</td>\n",
       "      <td id=\"T_1d6c6_row29_col1\" class=\"data row29 col1\" >0.256856</td>\n",
       "      <td id=\"T_1d6c6_row29_col2\" class=\"data row29 col2\" >0.654690</td>\n",
       "      <td id=\"T_1d6c6_row29_col3\" class=\"data row29 col3\" >-0.128094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_1d6c6_row30_col0\" class=\"data row30 col0\" >0.650996</td>\n",
       "      <td id=\"T_1d6c6_row30_col1\" class=\"data row30 col1\" >0.424173</td>\n",
       "      <td id=\"T_1d6c6_row30_col2\" class=\"data row30 col2\" >0.526744</td>\n",
       "      <td id=\"T_1d6c6_row30_col3\" class=\"data row30 col3\" >-0.031039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_1d6c6_row31_col0\" class=\"data row31 col0\" >0.106013</td>\n",
       "      <td id=\"T_1d6c6_row31_col1\" class=\"data row31 col1\" >0.243332</td>\n",
       "      <td id=\"T_1d6c6_row31_col2\" class=\"data row31 col2\" >0.650257</td>\n",
       "      <td id=\"T_1d6c6_row31_col3\" class=\"data row31 col3\" >-0.117276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_1d6c6_row32_col0\" class=\"data row32 col0\" >0.352164</td>\n",
       "      <td id=\"T_1d6c6_row32_col1\" class=\"data row32 col1\" >0.105808</td>\n",
       "      <td id=\"T_1d6c6_row32_col2\" class=\"data row32 col2\" >0.065468</td>\n",
       "      <td id=\"T_1d6c6_row32_col3\" class=\"data row32 col3\" >-0.079444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_1d6c6_row33_col0\" class=\"data row33 col0\" >0.829086</td>\n",
       "      <td id=\"T_1d6c6_row33_col1\" class=\"data row33 col1\" >0.439369</td>\n",
       "      <td id=\"T_1d6c6_row33_col2\" class=\"data row33 col2\" >0.207134</td>\n",
       "      <td id=\"T_1d6c6_row33_col3\" class=\"data row33 col3\" >-0.142586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_1d6c6_row34_col0\" class=\"data row34 col0\" >0.804893</td>\n",
       "      <td id=\"T_1d6c6_row34_col1\" class=\"data row34 col1\" >0.312070</td>\n",
       "      <td id=\"T_1d6c6_row34_col2\" class=\"data row34 col2\" >0.243714</td>\n",
       "      <td id=\"T_1d6c6_row34_col3\" class=\"data row34 col3\" >-0.119621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_1d6c6_row35_col0\" class=\"data row35 col0\" >0.462041</td>\n",
       "      <td id=\"T_1d6c6_row35_col1\" class=\"data row35 col1\" >0.129396</td>\n",
       "      <td id=\"T_1d6c6_row35_col2\" class=\"data row35 col2\" >0.838586</td>\n",
       "      <td id=\"T_1d6c6_row35_col3\" class=\"data row35 col3\" >-0.061199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_1d6c6_row36_col0\" class=\"data row36 col0\" >0.822171</td>\n",
       "      <td id=\"T_1d6c6_row36_col1\" class=\"data row36 col1\" >0.466507</td>\n",
       "      <td id=\"T_1d6c6_row36_col2\" class=\"data row36 col2\" >0.549292</td>\n",
       "      <td id=\"T_1d6c6_row36_col3\" class=\"data row36 col3\" >-0.034359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_1d6c6_row37_col0\" class=\"data row37 col0\" >0.985148</td>\n",
       "      <td id=\"T_1d6c6_row37_col1\" class=\"data row37 col1\" >0.720883</td>\n",
       "      <td id=\"T_1d6c6_row37_col2\" class=\"data row37 col2\" >0.776440</td>\n",
       "      <td id=\"T_1d6c6_row37_col3\" class=\"data row37 col3\" >-0.087697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_1d6c6_row38_col0\" class=\"data row38 col0\" >0.186743</td>\n",
       "      <td id=\"T_1d6c6_row38_col1\" class=\"data row38 col1\" >0.606741</td>\n",
       "      <td id=\"T_1d6c6_row38_col2\" class=\"data row38 col2\" >0.669580</td>\n",
       "      <td id=\"T_1d6c6_row38_col3\" class=\"data row38 col3\" >-0.115022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_1d6c6_row39_col0\" class=\"data row39 col0\" >0.288103</td>\n",
       "      <td id=\"T_1d6c6_row39_col1\" class=\"data row39 col1\" >0.702974</td>\n",
       "      <td id=\"T_1d6c6_row39_col2\" class=\"data row39 col2\" >0.898496</td>\n",
       "      <td id=\"T_1d6c6_row39_col3\" class=\"data row39 col3\" >-0.074789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_1d6c6_row40_col0\" class=\"data row40 col0\" >0.087427</td>\n",
       "      <td id=\"T_1d6c6_row40_col1\" class=\"data row40 col1\" >0.266736</td>\n",
       "      <td id=\"T_1d6c6_row40_col2\" class=\"data row40 col2\" >0.301280</td>\n",
       "      <td id=\"T_1d6c6_row40_col3\" class=\"data row40 col3\" >-0.104416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_1d6c6_row41_col0\" class=\"data row41 col0\" >0.874361</td>\n",
       "      <td id=\"T_1d6c6_row41_col1\" class=\"data row41 col1\" >0.867538</td>\n",
       "      <td id=\"T_1d6c6_row41_col2\" class=\"data row41 col2\" >0.894363</td>\n",
       "      <td id=\"T_1d6c6_row41_col3\" class=\"data row41 col3\" >-0.089455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_1d6c6_row42_col0\" class=\"data row42 col0\" >0.703504</td>\n",
       "      <td id=\"T_1d6c6_row42_col1\" class=\"data row42 col1\" >0.185323</td>\n",
       "      <td id=\"T_1d6c6_row42_col2\" class=\"data row42 col2\" >0.819923</td>\n",
       "      <td id=\"T_1d6c6_row42_col3\" class=\"data row42 col3\" >-0.087600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_1d6c6_row43_col0\" class=\"data row43 col0\" >0.575798</td>\n",
       "      <td id=\"T_1d6c6_row43_col1\" class=\"data row43 col1\" >0.322853</td>\n",
       "      <td id=\"T_1d6c6_row43_col2\" class=\"data row43 col2\" >0.534177</td>\n",
       "      <td id=\"T_1d6c6_row43_col3\" class=\"data row43 col3\" >-0.025146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_1d6c6_row44_col0\" class=\"data row44 col0\" >0.926507</td>\n",
       "      <td id=\"T_1d6c6_row44_col1\" class=\"data row44 col1\" >0.411535</td>\n",
       "      <td id=\"T_1d6c6_row44_col2\" class=\"data row44 col2\" >0.867653</td>\n",
       "      <td id=\"T_1d6c6_row44_col3\" class=\"data row44 col3\" >-0.035129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_1d6c6_row45_col0\" class=\"data row45 col0\" >0.412938</td>\n",
       "      <td id=\"T_1d6c6_row45_col1\" class=\"data row45 col1\" >0.541894</td>\n",
       "      <td id=\"T_1d6c6_row45_col2\" class=\"data row45 col2\" >0.422209</td>\n",
       "      <td id=\"T_1d6c6_row45_col3\" class=\"data row45 col3\" >-0.017276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_1d6c6_row46_col0\" class=\"data row46 col0\" >0.337422</td>\n",
       "      <td id=\"T_1d6c6_row46_col1\" class=\"data row46 col1\" >0.682293</td>\n",
       "      <td id=\"T_1d6c6_row46_col2\" class=\"data row46 col2\" >0.439519</td>\n",
       "      <td id=\"T_1d6c6_row46_col3\" class=\"data row46 col3\" >-0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_1d6c6_row47_col0\" class=\"data row47 col0\" >0.520981</td>\n",
       "      <td id=\"T_1d6c6_row47_col1\" class=\"data row47 col1\" >0.633975</td>\n",
       "      <td id=\"T_1d6c6_row47_col2\" class=\"data row47 col2\" >0.475997</td>\n",
       "      <td id=\"T_1d6c6_row47_col3\" class=\"data row47 col3\" >-0.002382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1d6c6_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_1d6c6_row48_col0\" class=\"data row48 col0\" >0.468000</td>\n",
       "      <td id=\"T_1d6c6_row48_col1\" class=\"data row48 col1\" >0.555000</td>\n",
       "      <td id=\"T_1d6c6_row48_col2\" class=\"data row48 col2\" >0.430000</td>\n",
       "      <td id=\"T_1d6c6_row48_col3\" class=\"data row48 col3\" >-0.023815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x356845fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising Bayesian Optimiser\n",
      "\n",
      "Starting optimization with 49 initial points in 3 dimensions.\n",
      "\n",
      "Best initial value: -0.0017385151212864832 at [0.40701  0.573911 0.428134]\n",
      "\n",
      "Feature engineering enabled.\n",
      "\n",
      "Initialising models and cross-validating to choose best kernel...\n",
      "\n",
      "Cross-validating standard kernels\n",
      "\n",
      "Standard Kernel Cross-Validation Results:\n",
      "Noisy RBF: R = 0.7810  0.2406, RMSE = 0.0225  0.0054\n",
      "ARD Matern (short): R = 0.7122  0.2185, RMSE = 0.0274  0.0063\n",
      "Noisy Matern: R = 0.6779  0.2792, RMSE = 0.0266  0.0063\n",
      "ARD RBF (short): R = 0.6305  0.3796, RMSE = 0.0278  0.0083\n",
      "ARD Matern (default): R = 0.6136  0.3077, RMSE = 0.0434  0.0422\n",
      "ARD RBF (default): R = 0.3650  0.7414, RMSE = 0.0335  0.0098\n",
      "Noise: R = 0.0000  0.0000, RMSE = 0.0751  0.0413\n",
      "Combo (large): R = -0.0986  0.4996, RMSE = 0.0715  0.0347\n",
      "Combo: R = -0.0986  0.4996, RMSE = 0.0715  0.0347\n",
      "Matern (nu=0.5): R = -0.1454  0.5369, RMSE = 0.0683  0.0237\n",
      "With Linear Trend: R = -0.2045  0.5873, RMSE = 0.0697  0.0231\n",
      "Matern (nu=1.5): R = -0.4824  0.8422, RMSE = 0.0766  0.0260\n",
      "Matern (default): R = -0.5740  0.9982, RMSE = 0.0790  0.0285\n",
      "Matern (short): R = -0.5740  0.9982, RMSE = 0.0790  0.0285\n",
      "RationalQuadratic: R = -0.5776  0.9910, RMSE = 0.0797  0.0305\n",
      "RationalQuadratic (large): R = -0.5776  0.9910, RMSE = 0.0797  0.0305\n",
      "RationalQuadratic (alpha=1.0): R = -0.5776  0.9910, RMSE = 0.0797  0.0305\n",
      "With Noise: R = -0.6672  1.0325, RMSE = 0.0827  0.0313\n",
      "Simple: R = -0.6672  1.0325, RMSE = 0.0827  0.0313\n",
      "Periodic: R = -0.7465  1.2920, RMSE = 0.0829  0.0328\n",
      "RBF (default): R = -0.7807  1.3484, RMSE = 0.0835  0.0334\n",
      "RBF (short): R = -0.7807  1.3484, RMSE = 0.0835  0.0334\n",
      "RBF + Periodic: R = -0.7878  1.3546, RMSE = 0.0834  0.0332\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validating log kernels\n",
      "\n",
      "Standard Kernel Cross-Validation Results:\n",
      "Noisy RBF: R = 0.7690  0.3362, RMSE = 0.0194  0.0067\n",
      "Noisy Matern: R = 0.7219  0.3823, RMSE = 0.0218  0.0070\n",
      "ARD RBF (default): R = 0.6061  0.3342, RMSE = 0.0314  0.0069\n",
      "ARD RBF (short): R = 0.4654  0.4750, RMSE = 0.0322  0.0047\n",
      "ARD Matern (short): R = 0.4596  0.4465, RMSE = 0.0326  0.0035\n",
      "ARD Matern (default): R = 0.3710  0.6187, RMSE = 0.0469  0.0401\n",
      "Noise: R = -0.1349  0.1399, RMSE = 0.0755  0.0410\n",
      "Combo (large): R = -0.3235  0.7208, RMSE = 0.0728  0.0344\n",
      "Combo: R = -0.3235  0.7208, RMSE = 0.0728  0.0344\n",
      "Matern (nu=0.5): R = -0.4691  0.8801, RMSE = 0.0686  0.0218\n",
      "With Linear Trend: R = -0.6908  1.0429, RMSE = 0.0728  0.0200\n",
      "Matern (nu=1.5): R = -0.8687  1.1760, RMSE = 0.0772  0.0233\n",
      "Matern (default): R = -0.9657  1.3386, RMSE = 0.0798  0.0259\n",
      "Matern (short): R = -0.9657  1.3386, RMSE = 0.0798  0.0259\n",
      "RationalQuadratic (alpha=1.0): R = -1.0193  1.4041, RMSE = 0.0811  0.0285\n",
      "RationalQuadratic: R = -1.0193  1.4041, RMSE = 0.0811  0.0285\n",
      "RationalQuadratic (large): R = -1.0193  1.4041, RMSE = 0.0811  0.0285\n",
      "Periodic: R = -1.1226  1.6252, RMSE = 0.0836  0.0308\n",
      "With Noise: R = -1.1237  1.4030, RMSE = 0.0854  0.0295\n",
      "Simple: R = -1.1237  1.4030, RMSE = 0.0854  0.0295\n",
      "RBF (short): R = -1.2030  1.7428, RMSE = 0.0846  0.0312\n",
      "RBF (default): R = -1.2030  1.7428, RMSE = 0.0846  0.0312\n",
      "RBF + Periodic: R = -1.2090  1.7325, RMSE = 0.0846  0.0309\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validating warped kernels\n",
      "\n",
      "Warped Kernel Cross-Validation Results:\n",
      "Warped Matern (Tanh): R = 0.7154  0.2702, RMSE = 0.0244  0.0061\n",
      "Warped Matern 1.5 (Kumaraswamy): R = 0.7040  0.1778, RMSE = 0.0300  0.0068\n",
      "Warped Matern (Kumaraswamy): R = 0.4417  0.5190, RMSE = 0.0355  0.0057\n",
      "Warped RBF (Kumaraswamy): R = 0.4366  0.5272, RMSE = 0.0371  0.0073\n",
      "Warped RQ (Kumaraswamy): R = 0.4198  0.5124, RMSE = 0.0362  0.0070\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validating warped kernels with log transform\n",
      "\n",
      "Warped Kernel Cross-Validation Results:\n",
      "Warped Matern 1.5 (Kumaraswamy): R = 0.7314  0.2099, RMSE = 0.0349  0.0164\n",
      "Warped Matern (Kumaraswamy): R = 0.6032  0.3475, RMSE = 0.0387  0.0128\n",
      "Warped RQ (Kumaraswamy): R = 0.5683  0.4158, RMSE = 0.0396  0.0128\n",
      "Warped RBF (Kumaraswamy): R = 0.5399  0.3887, RMSE = 0.0403  0.0112\n",
      "Warped Matern (Tanh): R = 0.4139  0.7151, RMSE = 0.0436  0.0167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected best model: Noisy RBF\n",
      "Using standard kernel: Noisy RBF\n",
      "Initialising blend of acquisition functions:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c143cafe11443d6882396ebaeece41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods and candidate points:\n",
      "              bo_mes : 0.000000-0.999999-0.002429\n",
      "                  ei : 0.000000-0.575114-0.000218\n",
      "              log_ei : 0.000000-0.575114-0.000218\n",
      "             ucb_0.2 : 0.000000-0.609411-0.008821\n",
      "               ucb_2 : 0.000000-0.568443-0.000000\n",
      "               ucb_5 : 0.000000-0.999999-0.000000\n",
      "                pi_0 : 0.000000-0.615111-0.010416\n",
      "            pi_0.001 : 0.000000-0.613545-0.009971\n",
      "             pi_0.01 : 0.000000-0.598961-0.006041\n",
      "              pi_0.1 : 0.000000-0.561100-0.000000\n",
      "               bo_ei : 0.000000-0.999999-0.000000\n",
      "            bo_ei_fe : 0.843561-0.602660-0.001265\n",
      "           bo_log_ei : 0.000000-0.999999-0.000000\n",
      "        bo_log_ei_fe : 0.654994-0.670361-0.002888\n",
      "              bo_ucb : 0.999999-0.599552-0.458514\n",
      "           bo_ucb_fe : 0.700015-0.546311-0.000597\n",
      "               bo_pi : 0.999999-0.590758-0.440943\n",
      "            bo_pi_fe : 0.474544-0.558663-0.475740\n",
      "            bo_mc_ei : 0.000000-0.999999-0.000000\n",
      "         bo_noisy_ei : 0.999999-0.579169-0.439068\n",
      "               bo_kg : 0.979550-0.988614-0.487581\n",
      "         bo_thompson : 0.984405-0.522939-0.442461\n",
      "            hyperopt : 0.002538-0.588696-0.000630\n",
      "           bootstrap : 0.675315-0.409713-0.509470\n",
      "                  cv : 0.018867-0.782022-0.003577\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method Comparison:\n",
      "          Method  Pred. Mean  Pred. Std        EI\n",
      "2         log_ei   -0.005561   0.031800  0.010867\n",
      "1             ei   -0.005561   0.031800  0.010867\n",
      "4          ucb_2   -0.005644   0.031889  0.010864\n",
      "9         pi_0.1   -0.005671   0.031899  0.010856\n",
      "22      hyperopt   -0.005436   0.031621  0.010853\n",
      "8        pi_0.01   -0.004177   0.029669  0.010657\n",
      "3        ucb_0.2   -0.003873   0.028688  0.010409\n",
      "7       pi_0.001   -0.003811   0.028290  0.010280\n",
      "6           pi_0   -0.003798   0.028138  0.010226\n",
      "15     bo_ucb_fe   -0.006630   0.030515  0.009884\n",
      "11      bo_ei_fe   -0.006963   0.030387  0.009689\n",
      "13  bo_log_ei_fe   -0.006816   0.029559  0.009427\n",
      "24            cv   -0.009369   0.031013  0.008930\n",
      "0         bo_mes   -0.025747   0.036322  0.005541\n",
      "10         bo_ei   -0.027293   0.037047  0.005385\n",
      "18      bo_mc_ei   -0.027293   0.037047  0.005385\n",
      "5          ucb_5   -0.027293   0.037047  0.005385\n",
      "12     bo_log_ei   -0.027293   0.037047  0.005385\n",
      "17      bo_pi_fe   -0.004131   0.012186  0.003759\n",
      "14        bo_ucb   -0.009860   0.014596  0.002641\n",
      "21   bo_thompson   -0.012271   0.015269  0.002219\n",
      "19   bo_noisy_ei   -0.012225   0.015151  0.002194\n",
      "16         bo_pi   -0.012210   0.015087  0.002177\n",
      "23     bootstrap   -0.020750   0.011656  0.000252\n",
      "20         bo_kg   -0.047190   0.015385  0.000007\n",
      "\n",
      "Final suggested candidate: 0.000000-0.575114-0.000218\n",
      "Best observed value: -0.001739 at [0.40701  0.573911 0.428134]\n",
      "Saving all visualizations to: Functions/Visualisations/run_20250531_202902\n",
      "  Creating parallel coordinate plots...\n",
      "  Creating prediction surface...\n",
      "  Creating acquisition landscapes...\n",
      "  Creating dimension importance plot...\n",
      "  Creating PCA plots...\n",
      "Generating visualizations using scikit-learn GP model...\n",
      "  Creating partial dependence plots...\n",
      "  Creating EI landscapes...\n",
      "  Creating decision boundary plots...\n",
      "  Creating SHAP plots...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8017c63362d3490993084fa2bf9dfad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating visualizations using BoTorch model...\n",
      "  Creating partial dependence plots...\n",
      "  Creating EI landscapes...\n",
      "  Creating decision boundary plots...\n",
      "  Creating SHAP plots...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48be85b85dc84f569a992f8b3b7366f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating model-independent visualizations...\n",
      "  Creating t-SNE plots...\n",
      "  Creating UMAP plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating MDS plots...\n",
      "  Creating feature importance plot...\n",
      "  Creating interaction heatmap...\n",
      "  Creating model fit plots...\n",
      "HTML index generated: Functions/Visualisations/run_20250531_202902/index.html\n",
      "All visualizations saved to: Functions/Visualisations/run_20250531_202902\n"
     ]
    }
   ],
   "source": [
    "optimizer = run_func(3,use_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3296d-8ec6-423d-92a3-f76c44d05ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
